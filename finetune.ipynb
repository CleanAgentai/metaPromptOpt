{"cells":[{"cell_type":"markdown","metadata":{"id":"header"},"source":["# GPT-4o Fine-tuning for Interview Scoring\n","\n","This notebook fine-tunes GPT-4o on human-scored interview evaluations.\n","\n","**Dataset**: 250 interviews with human scores across 6 metrics\n","\n","**Process**:\n","1. Data quality assessment and cleaning\n","2. 80-20 train-test split\n","3. Format data for OpenAI fine-tuning API\n","4. Upload and initiate fine-tuning job\n","5. Monitor training progress\n","6. Evaluate fine-tuned model"]},{"cell_type":"markdown","metadata":{"id":"1UHssDBQuyAG"},"source":["## Setup & Installation"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"PJCU_WymuyAG","executionInfo":{"status":"ok","timestamp":1764529370691,"user_tz":480,"elapsed":4521,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}}},"outputs":[],"source":["# Install required packages\n","!pip install openai pandas numpy scikit-learn -q"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"88HtxS5puyAH","executionInfo":{"status":"ok","timestamp":1764529393151,"user_tz":480,"elapsed":21102,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"8495f5d2-90b0-429b-b150-6508b6e512cd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive (for Colab)\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_tBOIMA2uyAI","executionInfo":{"status":"ok","timestamp":1764529402339,"user_tz":480,"elapsed":9185,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"a758b3c5-4b75-4161-a2a8-c672e02a10b4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Paste your OpenAI API key: ··········\n"]}],"source":["import os\n","from getpass import getpass\n","\n","# Set OpenAI API key\n","if \"OPENAI_API_KEY\" not in os.environ or not os.environ[\"OPENAI_API_KEY\"]:\n","    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI API key: \")"]},{"cell_type":"markdown","metadata":{"id":"rOO7bj0JuyAI"},"source":["## Imports"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CbYiAvMduyAI","executionInfo":{"status":"ok","timestamp":1764529407553,"user_tz":480,"elapsed":2737,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"2a1d354d-79ea-4bfe-f0a3-4d1bfcb5a10f"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Libraries loaded\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import json\n","import time\n","from datetime import datetime\n","from typing import Dict, List\n","from sklearn.model_selection import train_test_split\n","from openai import OpenAI\n","\n","# Initialize OpenAI client\n","client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n","\n","print(\"✓ Libraries loaded\")"]},{"cell_type":"markdown","metadata":{"id":"aMoq3nYauyAJ"},"source":["## Configuration"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9rvDxNB0uyAJ","executionInfo":{"status":"ok","timestamp":1764529411562,"user_tz":480,"elapsed":381,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"e11699f7-f93d-4aea-cbc7-7a6e926d1042"},"outputs":[{"output_type":"stream","name":"stdout","text":["Configuration loaded\n","Data path: /content/drive/MyDrive/hiring_evaluations.csv\n","Output directory: /content/drive/MyDrive/finetuning_output\n","Model: gpt-4o-2024-08-06\n"]}],"source":["# File paths - UPDATE THESE FOR YOUR ENVIRONMENT\n","DATA_PATH = \"/content/drive/MyDrive/hiring_evaluations.csv\"  # Update this path\n","OUTPUT_DIR = \"/content/drive/MyDrive/finetuning_output\"  # Where to save outputs\n","\n","# Create output directory\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# Metrics configuration\n","METRICS = [\n","    \"cognitive_ability\",\n","    \"experience\",\n","    \"problem_solving\",\n","    \"reliability\",\n","    \"professionalism\",\n","    \"communication\"\n","]\n","\n","# Fine-tuning configuration\n","MODEL_TO_FINETUNE = \"gpt-4o-2024-08-06\"  # Only this model supports fine-tuning\n","TRAIN_TEST_SPLIT = 0.8  # 80% train, 20% test\n","RANDOM_SEED = 42\n","\n","print(f\"Configuration loaded\")\n","print(f\"Data path: {DATA_PATH}\")\n","print(f\"Output directory: {OUTPUT_DIR}\")\n","print(f\"Model: {MODEL_TO_FINETUNE}\")"]},{"cell_type":"markdown","metadata":{"id":"nzR2vmqtuyAK"},"source":["## 1. Load and Inspect Data"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":854},"id":"QH0yRbtruyAK","executionInfo":{"status":"ok","timestamp":1764529415077,"user_tz":480,"elapsed":1692,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"1fe4156c-25a4-490c-9de3-200a08d88ed6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset Overview:\n","Total samples: 250\n","\n","Columns: ['interview_id', 'role', 'qa_text', 'cognitive_ability', 'experience', 'problem_solving', 'reliability', 'professionalism', 'communication']\n","\n","First few rows:\n"]},{"output_type":"execute_result","data":{"text/plain":["                          interview_id                             role  \\\n","0  customer_service_representative_001  Customer Service Representative   \n","1  customer_service_representative_002  Customer Service Representative   \n","2  customer_service_representative_003  Customer Service Representative   \n","3  customer_service_representative_004  Customer Service Representative   \n","4  customer_service_representative_005  Customer Service Representative   \n","\n","                                             qa_text  cognitive_ability  \\\n","0  Q: Have you worked in a customer-facing role f...                  6   \n","1  Q: Have you worked in a customer-facing role f...                  6   \n","2  Q: Have you worked in a customer-facing role f...                  6   \n","3  Q: Have you worked in a customer-facing role f...                  6   \n","4  Q: Have you worked in a customer-facing role f...                  6   \n","\n","   experience  problem_solving  reliability  professionalism  communication  \n","0           1                6            5                4              1  \n","1           5                9            5                4              1  \n","2           5                9            5                4              1  \n","3           5                6            5                4              2  \n","4           4                9            5                4              3  "],"text/html":["\n","  <div id=\"df-8f36a5ac-6014-46ee-a138-954b41b976da\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>interview_id</th>\n","      <th>role</th>\n","      <th>qa_text</th>\n","      <th>cognitive_ability</th>\n","      <th>experience</th>\n","      <th>problem_solving</th>\n","      <th>reliability</th>\n","      <th>professionalism</th>\n","      <th>communication</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>customer_service_representative_001</td>\n","      <td>Customer Service Representative</td>\n","      <td>Q: Have you worked in a customer-facing role f...</td>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>customer_service_representative_002</td>\n","      <td>Customer Service Representative</td>\n","      <td>Q: Have you worked in a customer-facing role f...</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>customer_service_representative_003</td>\n","      <td>Customer Service Representative</td>\n","      <td>Q: Have you worked in a customer-facing role f...</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>customer_service_representative_004</td>\n","      <td>Customer Service Representative</td>\n","      <td>Q: Have you worked in a customer-facing role f...</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>customer_service_representative_005</td>\n","      <td>Customer Service Representative</td>\n","      <td>Q: Have you worked in a customer-facing role f...</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>9</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f36a5ac-6014-46ee-a138-954b41b976da')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8f36a5ac-6014-46ee-a138-954b41b976da button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8f36a5ac-6014-46ee-a138-954b41b976da');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-689d7491-12eb-42db-a6c7-2e1fcf729c8c\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-689d7491-12eb-42db-a6c7-2e1fcf729c8c')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-689d7491-12eb-42db-a6c7-2e1fcf729c8c button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 250,\n  \"fields\": [\n    {\n      \"column\": \"interview_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          \"field_technician_043\",\n          \"customer_service_representative_007\",\n          \"sales_representative_048\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"role\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Sales Representative\",\n          \"General Manager (Franchise)\",\n          \"Field Technician\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"qa_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 250,\n        \"samples\": [\n          \"Q: Are you currently certified in CPR and First Aid?\\nA: Yes, I am currently certified in CPR and First Aid. I obtained my certification through an online course and I'm sure it's still valid for another year or so.\\n\\nQ: Describe a situation where you had to troubleshoot a complex technical issue on a previous job. How did you approach it and what was the outcome?\\nA: I recall a situation at my previous company where I was working on a project involving high-speed internet deployment. We had a customer reporting a consistent disconnection issue, and I was tasked with troubleshooting the problem.\\n\\nAt first, I tried to identify the root cause by checking the physical connections, ensuring that the equipment was properly configured, and verifying that the network settings were correct. I also referred to the technical documentation and consulted with my team leader to get a better understanding of the issue.\\n\\nHowever, after exploring the simpler solutions, I realized that the problem was more complex and required a more in-depth approach. I decided to set up a network analyzer to capture the traffic and analyze the data to pinpoint the exact cause of the disconnection. With the help of the analyzer, I was able to identify a faulty router that was causing the issue.\\n\\nTo resolve the problem, I replaced the faulty router, reconfigured the settings, and tested the connection. The outcome was a successful deployment of the high-speed internet, and the customer was satisfied with the resolution. I learned that sometimes, complex technical issues require a more structured approach and the right tools to identify the root cause.\\n\\nQ: Do you have a valid driver's license with a good driving record?\\nA: Yes, I do have a valid driver's license with a good driving record. I've had a license for over 10 years and have never had any significant issues with my insurance or any traffic citations.\\n\\nQ: Tell me about a project you managed from start to finish where you were responsible for installing and testing new equipment. What were some of the challenges you faced and how did you overcome them?\\nA: So one project that comes to mind is when I was part of a team that installed a new fiber-optic network for a rural area. My role was to oversee the installation and testing of the equipment. \\n\\nFrom what I remember, the biggest challenge we faced was the remote location and limited accessibility to the sites. We had to bring in specialized equipment and personnel to get the job done, and that added to the logistical headaches. \\n\\nWe managed to overcome these issues by establishing a clear communication plan with our team and the customer. I also made sure to have a backup plan in place in case of any unexpected setbacks. \\n\\nIn terms of technical challenges, we encountered some issues with the equipment itself, but I was able to troubleshoot and resolve them with the help of our technical support team. \\n\\nOverall, it was a learning experience, but I feel that I was able to apply my skills and knowledge effectively to deliver a successful project.\\n\\nQ: Are you comfortable working in a fast-paced environment with tight deadlines and multiple priorities?\\nA: Yes, I've worked in environments with quick turnaround times before and I'm comfortable managing multiple priorities simultaneously. I've had experience handling shifting deadlines, but I've also learned the importance of communication with my team and stakeholders to ensure everyone's on the same page.\\n\\nQ: How do you stay organized and manage your time effectively while on a job site with multiple tasks and responsibilities?\\nA: To stay organized and manage my time effectively on a job site, I use a combination of tools and a structured approach. I make a list of all the tasks and priorities before starting the job, and then break them down into smaller, manageable chunks. This helps me focus on one task at a time and ensure that I'm spending the right amount of time on each one. I also try to set aside dedicated time for inspections, maintenance, and other routine tasks, so I'm not scrambling to fit them in when they come up. And, I always keep my supervisor informed of any issues or changes that may affect the schedule or priorities.\\n\\nQ: Describe a situation where you had to communicate complex technical information to a non-technical client. How did you approach the situation and what strategies did you use to ensure the client understood the information?\\nA: I recall a situation where I had to explain a fiber optic installation to a homeowner who was concerned about the impact on her garden. She wasn't familiar with technical terms like signal loss and latency. I approached the situation by starting with the benefits of the installation, explaining how it would improve her internet connection and increase her property value. \\n\\nI used simple language to explain the process, avoiding technical jargon, and related it to things she was familiar with, like how a water pipe works. I also offered to draw a diagram to help visualize the installation. I found that by taking the time to understand her concerns and explaining things in a way that made sense to her, I was able to alleviate her worries and ensure she understood the information.\\n\\nQ: Tell me about a time when you identified a safety hazard on a job site and took initiative to correct it. What actions did you take and what was the outcome?\\nA: I recall a job site where we were doing some electrical work, and I noticed that the supplier had brought in a whole pallet of materials without any clear labeling of what was in each box. It was a huge box, and it was being stacked up kind of high. The general contractor was getting agitated because, you know, time is money. \\n\\nI stepped in and told him that I thought it was a good idea to get the contents of the box checked, just to be safe. So, we managed to get the supplier to confirm what was inside, and it turned out that one of the crates had hazardous materials. We got it safely stored, but it did hold us back for a bit. The outcome was good; safety first, right?\\n\\nQ: How do you handle a situation where a client is not satisfied with the work you have completed and is asking for a refund or rework?\\nA: Well, I've had situations like this before, and I think it's really important to listen to the client's concerns and understand where they're coming from. Sometimes, we might have missed something or there might have been a miscommunication. So, I would first ask them to explain what specifically wasn't up to their expectations and try to empathize with their perspective. If they're asking for a refund, I would explain our policy and offer alternatives, like a credit towards another service or a rework of the specific issue. I would also make sure to document the conversation and any agreements or outcomes to prevent similar issues in the future.\\n\\nQ: Can you describe your process for documenting and tracking work orders and customer interactions?\\nA: I've been documenting and tracking work orders and customer interactions through our company's CRM system, mainly focusing on the service request module. I create a new ticket for every work order and assign a priority level based on the customer's urgency. As I perform the job, I update the ticket with notes on the issues I encountered, the steps I took to resolve them, and the outcomes. \\n\\nI also take photos and attach them to the ticket to provide visual evidence of the repairs or installations. For customer interactions, I make sure to capture all relevant details in the notes section, including their concerns, questions, and any agreements we made. I update the ticket regularly, usually after each interaction or when the job is completed. \\n\\nTo keep track of outstanding tickets and customer interactions, I set reminders and prioritize my tasks based on the due dates and urgency levels. This way, I ensure I stay on top of my workload and provide timely updates to our customers.\",\n          \"Q: Have you worked in a customer-facing role for at least 6 months?\\nA: No, I don't think I have exactly 6 months of customer-facing experience. I've worked at a few part-time jobs, like helping out at my family's shop during holidays and summer breaks, but it's not something I've done full-time or regularly.\\n\\nQ: Tell me about a time when you had to handle a high volume of customer calls or queries within a tight timeframe, and how you managed your workload.\\nA: Um, so I was like working at a call center, it was a while back, and, yeah, we got slammed one day. I mean, a lot of customers were calling in, and my manager was all stressed out because we were supposed to meet some, uh, numbers, right? Anyway, I just... I don't know, I kind of just did my thing, answered the calls, helped them, and, you know, got them taken care of. I tried to, like, prioritize the calls, but it was hard because there were just so many. I don't think we ended up meeting those numbers, but, hey, we got through the day, right?\\n\\nQ: Are you available to work a standard 8-hour shift, 5 days a week?\\nA: No, I'm not really sure about that. My work schedule is kinda irregular because I have school in the mornings and then classes... um, at night, but they can vary. So, I'm not sure if I could commit to five days a week, but I'd try my best.\\n\\nQ: Walk me through your process for resolving a customer complaint that involves a complex issue or multiple stakeholders.\\nA: So the customer is like, really mad, right? And it's a complex issue, meaning there are like, a lot of people involved. I would, um, talk to the customer first and try to understand their problem. Then, I would like, probably, need to research the issue to see what's going on and stuff. Maybe I would need to involve a manager or something, but I'm not really sure how that would work. I've never really had to do that before.\\n\\nQ: Can you describe a situation where you had to communicate a difficult message or bad news to a customer?\\nA: Um, I think so, I mean, I've had to tell customers that we're out of stock on some stuff before. Like, one time I was working at this retail store and we were having a sale and this customer was really excited about a specific item, but we were sold out. And I had to tell him that we wouldn't be getting any more in stock for a while. I just, uh, told him that we were sorry and that he could check back later and maybe we would have some in stock then.\\n\\nQ: Have you received any formal training in customer service, conflict resolution, or communication skills?\\nA: No, I don't think I have. I mean, I've had to deal with customers at my previous job, but it wasn't exactly a customer service role. And I didn't really get any special training for that. I just kinda figured it out as I went along, you know?\\n\\nQ: How do you prioritize tasks and manage your time when dealing with multiple customer issues or emergencies?\\nA: Uh, so, I guess I'd, um, prioritize tasks based on how urgent they are, like, if a customer is yelling at me, I'd try to help them right away. And then, I'd, uh, try to work on the other issues, like the emails and phone calls, as quickly as I can. But, to be honest, I've never really had to handle more than one issue at a time before, so I'm not really sure what to do in that situation. I'd just kinda, you know, go with the flow, I guess.\\n\\nQ: Describe a time when you went above and beyond to meet a customer's request or resolve an issue.\\nA: Well, I think I once got a good rating from a friend's family member at the store I worked at part time. They were trying to return a shirt and it didn't fit right, but they had lost the receipt. I guess I helped them out or something, and they were happy, but I'm not really sure what I did. Um, I think I just let them return it or something.\\n\\nQ: Are you familiar with any relevant software or systems used in customer service roles?\\nA: No, I mean, not really familiar with any specific software. I've used like, email and phone to communicate with customers before, but I don't know if that's what you're looking for.\\n\\nQ: Tell me about a time when you had to think creatively to resolve a customer issue or find a solution to a problem.\\nA: Um, so I think, um, one time I was, you know, working at this one store and, uh, a customer came in and they were, like, really upset about something. Can't really remember what it was, but, uh, I tried my best to, you know, help them. I think I offered them a discount or something, but I don't know if that was the right thing to do. It was kind of a weird situation and, uh, I'm not really sure if I handled it the best way, but I tried my best, you know?\",\n          \"Q: Question 1 for Sales Representative\\nA: Yes, I've worked in sales previously. Like, I was selling stuff on eBay a while back, it was pretty casual but I think it helped me develop some basic sales skills, you know.\\n\\nQ: Question 2 for Sales Representative\\nA: Yes, I like meeting new people and talking about products, so I think I would be good at sales.\\n\\nQ: Question 3 for Sales Representative\\nA: Yes, I think that's a good idea to be willing to travel for sales meetings.\\n\\nQ: Question 4 for Sales Representative\\nA: You know, sales, it's like, I guess, you gotta know a lot of stuff about a product and then, like, you gotta sell it to people. But it's not just about selling, it's about... uh, building relationships, I think. Yeah, you gotta be friendly and stuff, and then you gotta convince people to buy your product. I don't know, I've only had a few sales jobs before, but I think I'd be pretty good at it 'cause I'm, like, really enthusiastic and all.\\n\\nQ: Question 5 for Sales Representative\\nA: So um, for a question five about, you know, a sales rep position... I think it's, like, really important to have good communication skills and be able to work well with people. I mean, I'm a people person, so that's no problem for me. I'm pretty outgoing and I get along with most people. So if I were in a sales role, I'd make sure to, you know, listen to what customers want and then try to sell 'em stuff that they need, or something.\\n\\nQ: Question 6 for Sales Representative\\nA: Um, I think to be a good sales representative, you have to, like, be able to talk to people and stuff, and try to get them to buy your products. You know, understand their needs and try to help them out. And sales, it's not just about selling something, it's about building relationships and stuff, you know? \\n\\nI guess, um, at this company I could use, like, my friendly personality to help people feel comfortable when they're talking to me, and then try to figure out what they're looking for in a product. And then I can, you know, try to show them how our product is the best fit for them.\\n\\nQ: Question 7 for Sales Representative\\nA: So, like, the question is about how I'd approach selling to a customer. Um, I'd just, you know, be friendly and stuff, and try to understand what they're looking for. Maybe ask them some questions to figure out what they want, and then I'd, uh, show them our products and see if they're interested. It's kinda like, I don't know, shopping, right? I'd just try to help them find what they need.\\n\\nQ: Question 8 for Sales Representative\\nA: So you want to know, like, what it takes to be a good sales rep, right? Well, I think it's about being a people person, you know? You gotta be able to connect with customers and stuff. I mean, you gotta understand what they need and provide for them, right? I'm pretty good at that, I think.\\n\\nQ: Question 9 for Sales Representative\\nA: Honestly, I don't really know what um, what the sales strategy would be for this position. I think it would just be about, you know, selling stuff to people. And then like getting more people to buy stuff and that would be, that would be my goal, I guess.\\n\\nQ: Question 10 for Sales Representative\\nA: I think to be successful in the Sales Representative role, you need to be able to, um, sell stuff, right? Like, figure out what people want to buy and then try to sell that to them. I mean, it's not always easy but it's like, I've done it in college when I sold stuff to my friends, um, you know, like concert tickets or something. So, yeah, I'm pretty sure I can do it here too.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cognitive_ability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 4,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6,\n          8,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"experience\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5,\n          8,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"problem_solving\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 9,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          6,\n          9,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reliability\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 7,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          7,\n          1,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"professionalism\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 7,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          7,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"communication\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 7,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}],"source":["# Load dataset\n","df = pd.read_csv(DATA_PATH)\n","\n","print(\"Dataset Overview:\")\n","print(f\"Total samples: {len(df)}\")\n","print(f\"\\nColumns: {df.columns.tolist()}\")\n","print(f\"\\nFirst few rows:\")\n","df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0RbCRrRKuyAK","executionInfo":{"status":"ok","timestamp":1764529416074,"user_tz":480,"elapsed":26,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"196d96b1-c29d-4b12-81cc-468f20cfaf1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data Quality Checks:\n","======================================================================\n","✓ No missing values\n","✓ No duplicate interview_ids\n","\n","Score Range Validation (expected: 1-10):\n","✓ cognitive_ability: All scores in range [1-10] (actual range: 4-8)\n","✓ experience: All scores in range [1-10] (actual range: 1-8)\n","✓ problem_solving: All scores in range [1-10] (actual range: 2-9)\n","✓ reliability: All scores in range [1-10] (actual range: 1-7)\n","✓ professionalism: All scores in range [1-10] (actual range: 2-7)\n","✓ communication: All scores in range [1-10] (actual range: 1-7)\n"]}],"source":["# Check data quality\n","print(\"Data Quality Checks:\")\n","print(\"=\" * 70)\n","\n","# Missing values\n","missing = df.isnull().sum()\n","if missing.any():\n","    print(\"⚠️  Missing values found:\")\n","    print(missing[missing > 0])\n","else:\n","    print(\"✓ No missing values\")\n","\n","# Duplicate interview IDs\n","duplicates = df[df.duplicated(subset=['interview_id'], keep=False)]\n","if len(duplicates) > 0:\n","    print(f\"\\n⚠️  {len(duplicates)} duplicate interview_ids found\")\n","    print(duplicates[['interview_id', 'role']].head())\n","else:\n","    print(\"✓ No duplicate interview_ids\")\n","\n","# Score range validation (should be 1-10)\n","print(\"\\nScore Range Validation (expected: 1-10):\")\n","for metric in METRICS:\n","    min_val = df[metric].min()\n","    max_val = df[metric].max()\n","    out_of_range = df[(df[metric] < 1) | (df[metric] > 10)]\n","\n","    if len(out_of_range) > 0:\n","        print(f\"⚠️  {metric}: {len(out_of_range)} scores out of range (min={min_val}, max={max_val})\")\n","    else:\n","        print(f\"✓ {metric}: All scores in range [1-10] (actual range: {min_val}-{max_val})\")"]},{"cell_type":"markdown","metadata":{"id":"BeEnbGDiuyAL"},"source":["## 2. Data Analysis"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mXndskvmuyAL","executionInfo":{"status":"ok","timestamp":1764529417661,"user_tz":480,"elapsed":16,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"5d1785b1-1e16-42eb-8c3b-738dfb37b0f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Score Distributions:\n","======================================================================\n","\n","COGNITIVE ABILITY:\n","  Mean: 6.98\n","  Median: 8\n","  Std Dev: 1.19\n","  Distribution: {4: 13, 6: 102, 8: 135}\n","\n","EXPERIENCE:\n","  Mean: 7.03\n","  Median: 8\n","  Std Dev: 1.53\n","  Distribution: {1: 3, 4: 2, 5: 71, 8: 174}\n","\n","PROBLEM SOLVING:\n","  Mean: 8.00\n","  Median: 9\n","  Std Dev: 1.58\n","  Distribution: {2: 4, 4: 3, 5: 5, 6: 49, 7: 20, 9: 169}\n","\n","RELIABILITY:\n","  Mean: 5.02\n","  Median: 5\n","  Std Dev: 1.53\n","  Distribution: {1: 2, 3: 65, 5: 111, 7: 72}\n","\n","PROFESSIONALISM:\n","  Mean: 4.63\n","  Median: 5\n","  Std Dev: 2.05\n","  Distribution: {2: 82, 4: 30, 5: 20, 6: 52, 7: 66}\n","\n","COMMUNICATION:\n","  Mean: 3.51\n","  Median: 4\n","  Std Dev: 2.09\n","  Distribution: {1: 77, 2: 23, 3: 11, 4: 49, 5: 31, 6: 42, 7: 17}\n"]}],"source":["# Score distributions\n","print(\"Score Distributions:\")\n","print(\"=\" * 70)\n","\n","for metric in METRICS:\n","    print(f\"\\n{metric.upper().replace('_', ' ')}:\")\n","    print(f\"  Mean: {df[metric].mean():.2f}\")\n","    print(f\"  Median: {df[metric].median():.0f}\")\n","    print(f\"  Std Dev: {df[metric].std():.2f}\")\n","    print(f\"  Distribution: {df[metric].value_counts().sort_index().to_dict()}\")"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lh2UWZZOuyAL","executionInfo":{"status":"ok","timestamp":1764529418096,"user_tz":480,"elapsed":25,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"39020f0f-bdfa-4f7c-cba1-38f944560550"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Role Distribution:\n","======================================================================\n","role\n","Customer Service Representative    50\n","Sales Representative               50\n","Field Technician                   50\n","Home Service Technician            50\n","General Manager (Franchise)        50\n","Name: count, dtype: int64\n","\n","Total roles: 5\n","Samples per role: 50 - 50\n"]}],"source":["# Role distribution\n","print(\"\\nRole Distribution:\")\n","print(\"=\" * 70)\n","role_counts = df['role'].value_counts()\n","print(role_counts)\n","\n","print(f\"\\nTotal roles: {len(role_counts)}\")\n","print(f\"Samples per role: {role_counts.min()} - {role_counts.max()}\")"]},{"cell_type":"markdown","metadata":{"id":"5Nx9mjYOuyAL"},"source":["## 3. Data Cleaning (if needed)\n","\n","Based on the analysis above, we'll clean any issues found."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ppA9jmYBuyAL","executionInfo":{"status":"ok","timestamp":1764529419389,"user_tz":480,"elapsed":7,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"22296291-53d4-4275-e28a-db914a5eb9b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Data Cleaning Steps:\n","======================================================================\n","✓ No duplicates to remove\n","✓ All scores already in [1-10] range\n","✓ No missing data in critical columns\n","\n","Final dataset size: 250 samples\n","Reduction: 0 samples (0.0%)\n"]}],"source":["# Create cleaned dataset\n","df_clean = df.copy()\n","\n","print(\"Data Cleaning Steps:\")\n","print(\"=\" * 70)\n","\n","# Remove duplicates if any\n","initial_count = len(df_clean)\n","df_clean = df_clean.drop_duplicates(subset=['interview_id'], keep='first')\n","removed_dupes = initial_count - len(df_clean)\n","if removed_dupes > 0:\n","    print(f\"✓ Removed {removed_dupes} duplicate rows\")\n","else:\n","    print(\"✓ No duplicates to remove\")\n","\n","# Clamp scores to 1-10 range (if needed)\n","scores_clamped = 0\n","for metric in METRICS:\n","    before = df_clean[metric].copy()\n","    df_clean[metric] = df_clean[metric].clip(lower=1, upper=10)\n","    scores_clamped += (df_clean[metric] != before).sum()\n","\n","if scores_clamped > 0:\n","    print(f\"✓ Clamped {scores_clamped} scores to [1-10] range\")\n","else:\n","    print(\"✓ All scores already in [1-10] range\")\n","\n","# Remove rows with missing critical data\n","critical_cols = ['interview_id', 'role', 'qa_text'] + METRICS\n","before_drop = len(df_clean)\n","df_clean = df_clean.dropna(subset=critical_cols)\n","removed_na = before_drop - len(df_clean)\n","if removed_na > 0:\n","    print(f\"✓ Removed {removed_na} rows with missing data\")\n","else:\n","    print(\"✓ No missing data in critical columns\")\n","\n","print(f\"\\nFinal dataset size: {len(df_clean)} samples\")\n","print(f\"Reduction: {len(df) - len(df_clean)} samples ({((len(df) - len(df_clean))/len(df)*100):.1f}%)\")"]},{"cell_type":"markdown","metadata":{"id":"4H9hGYROuyAM"},"source":["## 4. Train-Test Split (80-20)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IEGufkJguyAM","executionInfo":{"status":"ok","timestamp":1764529421568,"user_tz":480,"elapsed":4,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"cb442031-cac1-45db-d723-848b4ca06c61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train-Test Split:\n","======================================================================\n","Total samples: 250\n","Training samples: 200 (80.0%)\n","Test samples: 50 (20.0%)\n","\n","Role distribution in train set:\n","role\n","Field Technician                   40\n","Customer Service Representative    40\n","General Manager (Franchise)        40\n","Sales Representative               40\n","Home Service Technician            40\n","Name: count, dtype: int64\n","\n","Role distribution in test set:\n","role\n","Home Service Technician            10\n","Customer Service Representative    10\n","Field Technician                   10\n","Sales Representative               10\n","General Manager (Franchise)        10\n","Name: count, dtype: int64\n"]}],"source":["# Perform stratified split by role to maintain distribution\n","train_df, test_df = train_test_split(\n","    df_clean,\n","    test_size=1-TRAIN_TEST_SPLIT,\n","    random_state=RANDOM_SEED,\n","    stratify=df_clean['role']\n",")\n","\n","print(\"Train-Test Split:\")\n","print(\"=\" * 70)\n","print(f\"Total samples: {len(df_clean)}\")\n","print(f\"Training samples: {len(train_df)} ({len(train_df)/len(df_clean)*100:.1f}%)\")\n","print(f\"Test samples: {len(test_df)} ({len(test_df)/len(df_clean)*100:.1f}%)\")\n","\n","print(\"\\nRole distribution in train set:\")\n","print(train_df['role'].value_counts())\n","\n","print(\"\\nRole distribution in test set:\")\n","print(test_df['role'].value_counts())"]},{"cell_type":"markdown","metadata":{"id":"JN3UMvAXuyAM"},"source":["## 5. Format Data for Fine-tuning\n","\n","OpenAI fine-tuning requires JSONL format with specific structure:\n","```json\n","{\"messages\": [{\"role\": \"system\", \"content\": \"...\"}, {\"role\": \"user\", \"content\": \"...\"}, {\"role\": \"assistant\", \"content\": \"...\"}]}\n","```"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Egxm4P3uyAM","executionInfo":{"status":"ok","timestamp":1764529423093,"user_tz":480,"elapsed":13,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"020f0a0a-f6e0-4462-b2b8-dce2dc7a0d8c"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Formatting functions defined\n"]}],"source":["def build_scoring_prompt(qa_text: str, role: str) -> str:\n","    \"\"\"Build the scoring prompt matching the inference prompt from kRuns.ipynb\"\"\"\n","    prompt = f\"\"\"You are evaluating a candidate interview for the role: {role}\n","\n","Analyze the candidate's responses using these six metrics (each scored 1-10):\n","\n","1. **Cognitive Ability (35%)**: Structured thinking, planning, logic, analytical reasoning\n","2. **Experience (35%)**: Relevant work history (last 10 years), demonstrated skills, accomplishments\n","3. **Problem Solving (15%)**: Resourcefulness, creative solutions, handling constraints\n","4. **Reliability (5%)**: Punctuality, follow-through, dependability signals\n","5. **Professionalism (5%)**: Respect for clients/rules, composure under stress\n","6. **Communication (5%)**: Clarity and tone (ignore filler words like um, uh, like)\n","\n","CRITICAL INSTRUCTIONS:\n","- Return ONLY a valid JSON object\n","- Use these exact keys: cognitive_ability, experience, problem_solving, reliability, professionalism, communication\n","- Each value must be an integer from 1 to 10\n","- Do not include any explanations, just the JSON\n","\n","Interview Transcript:\n","--- START TRANSCRIPT ---\n","{qa_text}\n","--- END TRANSCRIPT ---\n","\n","Return your scores in this format:\n","{{\"cognitive_ability\":7,\"experience\":6,\"problem_solving\":7,\"reliability\":6,\"professionalism\":7,\"communication\":8}}\"\"\"\n","    return prompt\n","\n","def format_scores_as_json(row: pd.Series) -> str:\n","    \"\"\"Format scores as JSON string for assistant response\"\"\"\n","    scores = {\n","        \"cognitive_ability\": int(row['cognitive_ability']),\n","        \"experience\": int(row['experience']),\n","        \"problem_solving\": int(row['problem_solving']),\n","        \"reliability\": int(row['reliability']),\n","        \"professionalism\": int(row['professionalism']),\n","        \"communication\": int(row['communication'])\n","    }\n","    return json.dumps(scores)\n","\n","def create_training_example(row: pd.Series) -> dict:\n","    \"\"\"Create a single training example in OpenAI format\"\"\"\n","    system_message = \"You are an expert interviewer evaluating candidates. You provide accurate, consistent scoring based on interview transcripts.\"\n","    user_message = build_scoring_prompt(row['qa_text'], row['role'])\n","    assistant_message = format_scores_as_json(row)\n","\n","    return {\n","        \"messages\": [\n","            {\"role\": \"system\", \"content\": system_message},\n","            {\"role\": \"user\", \"content\": user_message},\n","            {\"role\": \"assistant\", \"content\": assistant_message}\n","        ]\n","    }\n","\n","print(\"✓ Formatting functions defined\")"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KNiX5by1uyAM","executionInfo":{"status":"ok","timestamp":1764529426285,"user_tz":480,"elapsed":1659,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"7de84066-39a6-4bfa-ed1d-17c4878626dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Converting training data to JSONL format...\n","✓ Training file saved: /content/drive/MyDrive/finetuning_output/train.jsonl\n","  Total examples: 200\n","\n","Sample training example:\n","{\n","  \"messages\": [\n","    {\n","      \"role\": \"system\",\n","      \"content\": \"You are an expert interviewer evaluating candidates. You provide accurate, consistent scoring based on interview transcripts.\"\n","    },\n","    {\n","      \"role\": \"user\",\n","      \"content\": \"You are evaluating a candidate interview for the role: Field Technician\\n\\nAnalyze the candidate's responses using these six metrics (each scored 1-10):\\n\\n1. **Cognitive Ability (35%)**: Structured thinking, planning, logic, analytical reasoning\\n2. **Experience (35%)**: Relevant work history (last 10 years), demonstrated skills, accomplishments\\n3. **Problem Solving (15%)**: Resourcefulness, creative solutions, handling constraints\\n4. **Reliability (5%)**: Punctuality, follow-through, dependability signals\\n5. **Professionalism (5%)**: Respect for clients/rules, composure under stress\\n6. **Communication (5%)**: Clarity and tone (ignore filler words like um, uh, like)\\n\\nCRITICAL INSTRUCTIONS:\\n- Return ONLY a valid JSON object\\n- Use these ...\n"]}],"source":["# Convert training data to JSONL format\n","print(\"Converting training data to JSONL format...\")\n","\n","train_examples = []\n","for idx, row in train_df.iterrows():\n","    train_examples.append(create_training_example(row))\n","\n","# Save training file\n","train_file_path = os.path.join(OUTPUT_DIR, \"train.jsonl\")\n","with open(train_file_path, 'w') as f:\n","    for example in train_examples:\n","        f.write(json.dumps(example) + '\\n')\n","\n","print(f\"✓ Training file saved: {train_file_path}\")\n","print(f\"  Total examples: {len(train_examples)}\")\n","\n","# Show sample\n","print(\"\\nSample training example:\")\n","print(json.dumps(train_examples[0], indent=2)[:1000] + \"...\")"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ktk5_aV4uyAM","executionInfo":{"status":"ok","timestamp":1764529428987,"user_tz":480,"elapsed":1534,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"30f52db1-4f79-4bae-8778-291c99e85e18"},"outputs":[{"output_type":"stream","name":"stdout","text":["Converting test data to JSONL format...\n","✓ Test file saved: /content/drive/MyDrive/finetuning_output/test.jsonl\n","  Total examples: 50\n","✓ Test CSV saved: /content/drive/MyDrive/finetuning_output/test_set.csv\n"]}],"source":["# Convert test data to JSONL format (for later evaluation)\n","print(\"Converting test data to JSONL format...\")\n","\n","test_examples = []\n","for idx, row in test_df.iterrows():\n","    test_examples.append(create_training_example(row))\n","\n","# Save test file\n","test_file_path = os.path.join(OUTPUT_DIR, \"test.jsonl\")\n","with open(test_file_path, 'w') as f:\n","    for example in test_examples:\n","        f.write(json.dumps(example) + '\\n')\n","\n","print(f\"✓ Test file saved: {test_file_path}\")\n","print(f\"  Total examples: {len(test_examples)}\")\n","\n","# Also save test data as CSV for easier evaluation later\n","test_csv_path = os.path.join(OUTPUT_DIR, \"test_set.csv\")\n","test_df.to_csv(test_csv_path, index=False)\n","print(f\"✓ Test CSV saved: {test_csv_path}\")"]},{"cell_type":"markdown","metadata":{"id":"7GsIG4szuyAN"},"source":["## 6. Validate Training Data\n","\n","OpenAI provides validation tools to check data format before uploading."]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sCTCP-unuyAN","executionInfo":{"status":"ok","timestamp":1764529431469,"user_tz":480,"elapsed":4,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"42aa7e18-d2f9-49fe-8b0f-895622ae67cc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Validating training data format...\n","======================================================================\n","✓ All validation checks passed!\n","\n","Samples validated: 10\n","Total training samples: 200\n"]}],"source":["# Basic validation checks\n","print(\"Validating training data format...\")\n","print(\"=\" * 70)\n","\n","validation_errors = []\n","\n","for i, example in enumerate(train_examples[:10]):  # Check first 10\n","    # Check structure\n","    if \"messages\" not in example:\n","        validation_errors.append(f\"Example {i}: Missing 'messages' key\")\n","        continue\n","\n","    messages = example[\"messages\"]\n","\n","    # Check message count (should be 3: system, user, assistant)\n","    if len(messages) != 3:\n","        validation_errors.append(f\"Example {i}: Expected 3 messages, got {len(messages)}\")\n","\n","    # Check roles\n","    expected_roles = [\"system\", \"user\", \"assistant\"]\n","    actual_roles = [msg[\"role\"] for msg in messages]\n","    if actual_roles != expected_roles:\n","        validation_errors.append(f\"Example {i}: Role sequence mismatch. Expected {expected_roles}, got {actual_roles}\")\n","\n","    # Check content exists\n","    for j, msg in enumerate(messages):\n","        if \"content\" not in msg or not msg[\"content\"]:\n","            validation_errors.append(f\"Example {i}, message {j}: Missing or empty content\")\n","\n","    # Validate assistant response is valid JSON\n","    try:\n","        assistant_content = messages[2][\"content\"]\n","        scores = json.loads(assistant_content)\n","\n","        # Check all required keys present\n","        required_keys = set(METRICS)\n","        actual_keys = set(scores.keys())\n","        if required_keys != actual_keys:\n","            validation_errors.append(f\"Example {i}: Score keys mismatch. Expected {required_keys}, got {actual_keys}\")\n","\n","        # Check score ranges\n","        for key, value in scores.items():\n","            if not isinstance(value, int) or value < 1 or value > 10:\n","                validation_errors.append(f\"Example {i}: Score '{key}' = {value} is invalid (must be int 1-10)\")\n","\n","    except json.JSONDecodeError:\n","        validation_errors.append(f\"Example {i}: Assistant response is not valid JSON\")\n","\n","if validation_errors:\n","    print(\"⚠️  Validation errors found:\")\n","    for error in validation_errors[:10]:  # Show first 10 errors\n","        print(f\"  - {error}\")\n","    if len(validation_errors) > 10:\n","        print(f\"  ... and {len(validation_errors) - 10} more errors\")\n","else:\n","    print(\"✓ All validation checks passed!\")\n","\n","print(f\"\\nSamples validated: {min(10, len(train_examples))}\")\n","print(f\"Total training samples: {len(train_examples)}\")"]},{"cell_type":"markdown","metadata":{"id":"t3uQ9FjEuyAN"},"source":["## 7. Upload Training File to OpenAI"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dnEqTV17uyAN","executionInfo":{"status":"ok","timestamp":1764529438173,"user_tz":480,"elapsed":5055,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"dfaaaed0-c57d-409c-f3c9-45c8f99a6a7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Uploading training file to OpenAI...\n","======================================================================\n","✓ Training file uploaded successfully!\n","  File ID: file-9AY2fj4MCN9kJtnYMzZUeh\n","  Filename: train.jsonl\n","  Bytes: 1,708,822\n","  Status: processed\n","\n","✓ File info saved: /content/drive/MyDrive/finetuning_output/file_info.json\n"]}],"source":["# Upload training file\n","print(\"Uploading training file to OpenAI...\")\n","print(\"=\" * 70)\n","\n","try:\n","    with open(train_file_path, 'rb') as f:\n","        train_file = client.files.create(\n","            file=f,\n","            purpose='fine-tune'\n","        )\n","\n","    print(f\"✓ Training file uploaded successfully!\")\n","    print(f\"  File ID: {train_file.id}\")\n","    print(f\"  Filename: {train_file.filename}\")\n","    print(f\"  Bytes: {train_file.bytes:,}\")\n","    print(f\"  Status: {train_file.status}\")\n","\n","    # Save file ID for later reference\n","    file_info = {\n","        \"train_file_id\": train_file.id,\n","        \"filename\": train_file.filename,\n","        \"bytes\": train_file.bytes,\n","        \"upload_timestamp\": datetime.now().isoformat(),\n","        \"num_examples\": len(train_examples)\n","    }\n","\n","    file_info_path = os.path.join(OUTPUT_DIR, \"file_info.json\")\n","    with open(file_info_path, 'w') as f:\n","        json.dump(file_info, f, indent=2)\n","\n","    print(f\"\\n✓ File info saved: {file_info_path}\")\n","\n","except Exception as e:\n","    print(f\"❌ Error uploading file: {e}\")\n","    raise"]},{"cell_type":"markdown","metadata":{"id":"yUhFpemBuyAN"},"source":["## 8. Create Fine-tuning Job"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zjDqJYneuyAN","executionInfo":{"status":"ok","timestamp":1764529445376,"user_tz":480,"elapsed":3073,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"0f3291da-93eb-45d1-83ac-9fba09b3db38"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating fine-tuning job...\n","======================================================================\n","✓ Fine-tuning job created successfully!\n","  Job ID: ftjob-t9Yi16FKGtHzeZsY7zAPq7KU\n","  Model: gpt-4o-2024-08-06\n","  Status: validating_files\n","  Created at: 2025-11-30 19:04:04\n","\n","✓ Job info saved: /content/drive/MyDrive/finetuning_output/job_info.json\n","\n","⏳ Fine-tuning is now in progress. This may take 10-30 minutes.\n","   You can monitor progress in the next cell or at:\n","   https://platform.openai.com/finetune/ftjob-t9Yi16FKGtHzeZsY7zAPq7KU\n"]}],"source":["# Create fine-tuning job\n","print(\"Creating fine-tuning job...\")\n","print(\"=\" * 70)\n","\n","try:\n","    job = client.fine_tuning.jobs.create(\n","        training_file=train_file.id,\n","        model=MODEL_TO_FINETUNE,\n","        suffix=\"interview-scorer\",  # Will be appended to model name\n","        hyperparameters={\n","            \"n_epochs\": \"auto\"  # Let OpenAI determine optimal epochs\n","        }\n","    )\n","\n","    print(f\"✓ Fine-tuning job created successfully!\")\n","    print(f\"  Job ID: {job.id}\")\n","    print(f\"  Model: {job.model}\")\n","    print(f\"  Status: {job.status}\")\n","    print(f\"  Created at: {datetime.fromtimestamp(job.created_at)}\")\n","\n","    # Save job info\n","    job_info = {\n","        \"job_id\": job.id,\n","        \"model\": job.model,\n","        \"status\": job.status,\n","        \"created_at\": job.created_at,\n","        \"training_file\": job.training_file,\n","        \"hyperparameters\": job.hyperparameters.to_dict() if hasattr(job.hyperparameters, 'to_dict') else {}\n","    }\n","\n","    job_info_path = os.path.join(OUTPUT_DIR, \"job_info.json\")\n","    with open(job_info_path, 'w') as f:\n","        json.dump(job_info, f, indent=2)\n","\n","    print(f\"\\n✓ Job info saved: {job_info_path}\")\n","    print(f\"\\n⏳ Fine-tuning is now in progress. This may take 10-30 minutes.\")\n","    print(f\"   You can monitor progress in the next cell or at:\")\n","    print(f\"   https://platform.openai.com/finetune/{job.id}\")\n","\n","except Exception as e:\n","    print(f\"❌ Error creating fine-tuning job: {e}\")\n","    raise"]},{"cell_type":"markdown","metadata":{"id":"Q7IV80nZuyAN"},"source":["## 9. Monitor Fine-tuning Progress\n","\n","This cell will check the job status periodically until completion."]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s4iPgnlmuyAN","executionInfo":{"status":"ok","timestamp":1764531744712,"user_tz":480,"elapsed":2294960,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"f1968c7b-3de0-4842-9dd5-ade59a11a04b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fine-tuning Job Status\n","======================================================================\n","Job ID: ftjob-t9Yi16FKGtHzeZsY7zAPq7KU\n","Status: succeeded\n","Model: gpt-4o-2024-08-06\n","Created: 2025-11-30 19:04:04\n","Finished: 2025-11-30 19:29:03\n","Duration: 24 minutes 59 seconds\n","\n","✓ Fine-tuned Model: ft:gpt-4o-2024-08-06:cleanagent:interview-scorer:ChhOUzkh\n","\n","❌ Error: Error(code=None, message=None, param=None)\n","\n","Result files: ['file-PmthLM9WcYswwgCeTJvPcn']\n","\n","======================================================================\n","✓ Fine-tuning completed successfully!\n","\n","Your fine-tuned model: ft:gpt-4o-2024-08-06:cleanagent:interview-scorer:ChhOUzkh\n","\n","You can now use this model for inference in the next section.\n","\n","Final job info saved: /content/drive/MyDrive/finetuning_output/final_job_info.json\n"]}],"source":["# Monitor fine-tuning progress\n","print(\"Monitoring fine-tuning job...\")\n","print(\"=\" * 70)\n","print(f\"Job ID: {job.id}\")\n","print(\"This will check status every 60 seconds.\\n\")\n","\n","import time\n","from IPython.display import clear_output\n","\n","while True:\n","    try:\n","        # Retrieve current job status\n","        current_job = client.fine_tuning.jobs.retrieve(job.id)\n","\n","        clear_output(wait=True)\n","\n","        print(\"Fine-tuning Job Status\")\n","        print(\"=\" * 70)\n","        print(f\"Job ID: {current_job.id}\")\n","        print(f\"Status: {current_job.status}\")\n","        print(f\"Model: {current_job.model}\")\n","        print(f\"Created: {datetime.fromtimestamp(current_job.created_at)}\")\n","\n","        if current_job.finished_at:\n","            print(f\"Finished: {datetime.fromtimestamp(current_job.finished_at)}\")\n","            duration = current_job.finished_at - current_job.created_at\n","            print(f\"Duration: {duration // 60} minutes {duration % 60} seconds\")\n","\n","        if current_job.fine_tuned_model:\n","            print(f\"\\n✓ Fine-tuned Model: {current_job.fine_tuned_model}\")\n","\n","        if current_job.error:\n","            print(f\"\\n❌ Error: {current_job.error}\")\n","\n","        # Get training metrics if available\n","        if hasattr(current_job, 'result_files') and current_job.result_files:\n","            print(f\"\\nResult files: {current_job.result_files}\")\n","\n","        # Check if job is complete\n","        if current_job.status in ['succeeded', 'failed', 'cancelled']:\n","            print(\"\\n\" + \"=\" * 70)\n","            if current_job.status == 'succeeded':\n","                print(\"✓ Fine-tuning completed successfully!\")\n","                print(f\"\\nYour fine-tuned model: {current_job.fine_tuned_model}\")\n","                print(\"\\nYou can now use this model for inference in the next section.\")\n","\n","                # Save final job info\n","                final_job_info = {\n","                    \"job_id\": current_job.id,\n","                    \"status\": current_job.status,\n","                    \"fine_tuned_model\": current_job.fine_tuned_model,\n","                    \"created_at\": current_job.created_at,\n","                    \"finished_at\": current_job.finished_at,\n","                    \"trained_tokens\": getattr(current_job, 'trained_tokens', None),\n","                    \"hyperparameters\": current_job.hyperparameters.to_dict() if hasattr(current_job.hyperparameters, 'to_dict') else {}\n","                }\n","\n","                final_job_path = os.path.join(OUTPUT_DIR, \"final_job_info.json\")\n","                with open(final_job_path, 'w') as f:\n","                    json.dump(final_job_info, f, indent=2)\n","                print(f\"\\nFinal job info saved: {final_job_path}\")\n","\n","            else:\n","                print(f\"❌ Fine-tuning {current_job.status}\")\n","            break\n","\n","        print(\"\\nNext check in 60 seconds...\")\n","        time.sleep(60)\n","\n","    except KeyboardInterrupt:\n","        print(\"\\n\\nMonitoring stopped by user.\")\n","        print(f\"Job is still running. Check status at: https://platform.openai.com/finetune/{job.id}\")\n","        break\n","    except Exception as e:\n","        print(f\"\\n❌ Error checking job status: {e}\")\n","        print(\"Retrying in 60 seconds...\")\n","        time.sleep(60)"]},{"cell_type":"markdown","metadata":{"id":"PSyz8t8QuyAO"},"source":["## 10. Test Fine-tuned Model (Single Inference)\n","\n","Run a single test inference to verify the model works."]},{"cell_type":"code","execution_count":22,"metadata":{"id":"-ZIcr91duyAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764537226097,"user_tz":480,"elapsed":52,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"75586865-68e3-4c80-fec5-86b76039137b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Testing fine-tuned model: ft:gpt-4o-2024-08-06:cleanagent:interview-scorer:ChhOUzkh\n","======================================================================\n"]}],"source":["# Load the fine-tuned model name\n","# If you're running this cell separately, update this with your model name\n","FINE_TUNED_MODEL = current_job.fine_tuned_model  # From previous cell\n","# Or manually set it: FINE_TUNED_MODEL = \"ft:gpt-4o-2024-08-06:...:...:...\"\n","\n","print(f\"Testing fine-tuned model: {FINE_TUNED_MODEL}\")\n","print(\"=\" * 70)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"MKjna6M4uyAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764533435444,"user_tz":480,"elapsed":14,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"7c77dc99-cb8d-439b-fd54-56e3077d6552"},"outputs":[{"output_type":"stream","name":"stdout","text":["Test Sample:\n","Interview ID: home_service_technician_002\n","Role: Home Service Technician\n","\n","Transcript (first 500 chars):\n","Q: Do you have a valid driver's license?\n","A: Yes, I do have a valid driver's license. I've had it for over five years since I got my first job doing deliveries for a home appliance store.\n","\n","Q: Have you worked with HVAC systems for at least 2 years?\n","A: Yes, I've been working with HVAC systems for about 3 years. I started as an apprentice and have since worked on various types of systems, including residential and commercial units.\n","\n","Q: Are you available to work on weekends?\n","A: Yes, I'm available to ...\n","\n","======================================================================\n","Ground Truth Scores:\n","  cognitive_ability: 8\n","  experience: 8\n","  problem_solving: 9\n","  reliability: 7\n","  professionalism: 7\n","  communication: 6\n"]}],"source":["# Select a test sample\n","test_sample = test_df.iloc[0]\n","\n","print(\"Test Sample:\")\n","print(f\"Interview ID: {test_sample['interview_id']}\")\n","print(f\"Role: {test_sample['role']}\")\n","print(f\"\\nTranscript (first 500 chars):\")\n","print(test_sample['qa_text'][:500] + \"...\")\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"Ground Truth Scores:\")\n","for metric in METRICS:\n","    print(f\"  {metric}: {test_sample[metric]}\")"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"YLMwl0I_uyAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764533448042,"user_tz":480,"elapsed":8914,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"b3ed54c7-4ab9-4c0f-edf6-bb158a9cee0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Running inference with fine-tuned model...\n","\n","Model Response:\n","{\"cognitive_ability\": 8, \"experience\": 8, \"problem_solving\": 9, \"reliability\": 7, \"professionalism\": 6, \"communication\": 4}\n","\n","======================================================================\n","Comparison (Ground Truth vs Predicted):\n","======================================================================\n","Metric                Truth  Predicted   Diff\n","----------------------------------------------------------------------\n","cognitive_ability         8          8     +0\n","experience                8          8     +0\n","problem_solving           9          9     +0\n","reliability               7          7     +0\n","professionalism           7          6     -1\n","communication             6          4     -2\n","----------------------------------------------------------------------\n","Mean Absolute Error: 0.50\n"]}],"source":["# Run inference\n","print(\"\\nRunning inference with fine-tuned model...\\n\")\n","\n","system_message = \"You are an expert interviewer evaluating candidates. You provide accurate, consistent scoring based on interview transcripts.\"\n","user_message = build_scoring_prompt(test_sample['qa_text'], test_sample['role'])\n","\n","try:\n","    response = client.chat.completions.create(\n","        model=FINE_TUNED_MODEL,\n","        messages=[\n","            {\"role\": \"system\", \"content\": system_message},\n","            {\"role\": \"user\", \"content\": user_message}\n","        ],\n","        temperature=0.0,\n","        max_tokens=512\n","    )\n","\n","    predicted_response = response.choices[0].message.content\n","    print(\"Model Response:\")\n","    print(predicted_response)\n","\n","    # Parse and compare\n","    try:\n","        predicted_scores = json.loads(predicted_response)\n","\n","        print(\"\\n\" + \"=\" * 70)\n","        print(\"Comparison (Ground Truth vs Predicted):\")\n","        print(\"=\" * 70)\n","        print(f\"{'Metric':<20} {'Truth':>6} {'Predicted':>10} {'Diff':>6}\")\n","        print(\"-\" * 70)\n","\n","        total_diff = 0\n","        for metric in METRICS:\n","            truth = test_sample[metric]\n","            pred = predicted_scores.get(metric, 0)\n","            diff = pred - truth\n","            total_diff += abs(diff)\n","            print(f\"{metric:<20} {truth:>6} {pred:>10} {diff:>+6}\")\n","\n","        print(\"-\" * 70)\n","        print(f\"Mean Absolute Error: {total_diff / len(METRICS):.2f}\")\n","\n","    except json.JSONDecodeError:\n","        print(\"\\n⚠️  Response is not valid JSON\")\n","\n","except Exception as e:\n","    print(f\"❌ Error during inference: {e}\")"]},{"cell_type":"markdown","source":["## 11. Evaluation on Test Set"],"metadata":{"id":"PrOApoxrniWN"}},{"cell_type":"code","source":["# Helper function for inference with latency tracking\n","def run_single_inference(qa_text: str, role: str, model_name: str) -> tuple[Dict[str, int], float]:\n","    \"\"\"Run inference on a single sample and return (scores, latency_ms)\"\"\"\n","    system_message = \"You are an expert interviewer evaluating candidates. You provide accurate, consistent scoring based on interview transcripts.\"\n","    user_message = build_scoring_prompt(qa_text, role)\n","\n","    try:\n","        start_time = time.time()\n","\n","        response = client.chat.completions.create(\n","            model=model_name,\n","            messages=[\n","                {\"role\": \"system\", \"content\": system_message},\n","                {\"role\": \"user\", \"content\": user_message}\n","            ],\n","            temperature=0.0,\n","            max_tokens=512\n","        )\n","\n","        latency_ms = (time.time() - start_time) * 1000\n","\n","        response_text = response.choices[0].message.content.strip()\n","\n","        # Clean response (remove markdown code blocks if present)\n","        if response_text.startswith(\"```\"):\n","            response_text = response_text.split(\"```\")[1]\n","            if response_text.startswith(\"json\"):\n","                response_text = response_text[4:]\n","            response_text = response_text.strip()\n","\n","        scores = json.loads(response_text)\n","\n","        # Validate and clamp scores\n","        validated_scores = {}\n","        for metric in METRICS:\n","            if metric in scores:\n","                validated_scores[metric] = max(1, min(10, int(scores[metric])))\n","            else:\n","                print(f\"⚠️  Missing metric '{metric}', defaulting to 5\")\n","                validated_scores[metric] = 5\n","\n","        return validated_scores, latency_ms\n","\n","    except json.JSONDecodeError as e:\n","        latency_ms = (time.time() - start_time) * 1000 if 'start_time' in locals() else 0\n","        print(f\"❌ JSON decode error: {e}\")\n","        return {metric: 5 for metric in METRICS}, latency_ms\n","    except Exception as e:\n","        latency_ms = (time.time() - start_time) * 1000 if 'start_time' in locals() else 0\n","        print(f\"❌ Error: {e}\")\n","        return {metric: 5 for metric in METRICS}, latency_ms\n","\n","print(\"✓ Inference function loaded\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0xVc8gdKna3x","executionInfo":{"status":"ok","timestamp":1764537487244,"user_tz":480,"elapsed":11,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"e9d76241-de08-411f-c2b7-3ec12e3c10d7"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Inference function loaded\n"]}]},{"cell_type":"code","source":["# Run inference on all test samples\n","print(\"=\" * 70)\n","print(f\"Running inference on {len(test_df)} test samples...\")\n","print(\"=\" * 70)\n","print(\"This will take approximately 1-2 minutes\\n\")\n","\n","predictions = []\n","latencies = []\n","start_time = time.time()\n","\n","for idx, row in test_df.iterrows():\n","    print(f\"Processing {idx + 1}/{len(test_df)}: {row['interview_id']}\", end=\"\\r\")\n","\n","    pred_scores, latency = run_single_inference(row['qa_text'], row['role'], FINE_TUNED_MODEL)\n","    predictions.append(pred_scores)\n","    latencies.append(latency)\n","\n","    # Small delay to avoid rate limits\n","    time.sleep(0.1)\n","\n","elapsed_time = time.time() - start_time\n","print(f\"\\n\\n✓ Completed in {elapsed_time:.1f} seconds ({elapsed_time/len(test_df):.2f}s per sample)\")\n","\n","# Latency statistics\n","avg_latency = np.mean(latencies)\n","p50_latency = np.percentile(latencies, 50)\n","p95_latency = np.percentile(latencies, 95)\n","p99_latency = np.percentile(latencies, 99)\n","\n","print(\"\\nLatency Statistics:\")\n","print(\"-\" * 70)\n","print(f\"Mean:   {avg_latency:.0f} ms\")\n","print(f\"Median: {p50_latency:.0f} ms\")\n","print(f\"P95:    {p95_latency:.0f} ms\")\n","print(f\"P99:    {p99_latency:.0f} ms\")\n","print(f\"Min:    {min(latencies):.0f} ms\")\n","print(f\"Max:    {max(latencies):.0f} ms\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cnRBYxjBbtvL","executionInfo":{"status":"ok","timestamp":1764537603483,"user_tz":480,"elapsed":107077,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"03df79ad-a474-4694-9a9b-19c04d8fec02"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["======================================================================\n","Running inference on 50 test samples...\n","======================================================================\n","This will take approximately 1-2 minutes\n","\n","\n","\n","✓ Completed in 107.1 seconds (2.14s per sample)\n","\n","Latency Statistics:\n","----------------------------------------------------------------------\n","Mean:   2041 ms\n","Median: 1686 ms\n","P95:    3859 ms\n","P99:    4360 ms\n","Min:    949 ms\n","Max:    4475 ms\n"]}]},{"cell_type":"code","source":["# Calculate evaluation metrics\n","print(\"\\n\" + \"=\" * 70)\n","print(\"EVALUATION METRICS\")\n","print(\"=\" * 70)\n","\n","# Per-metric metrics\n","results = {}\n","for metric in METRICS:\n","    true_values = test_df[metric].values\n","    pred_values = np.array([p[metric] for p in predictions])\n","\n","    mae = np.mean(np.abs(true_values - pred_values))\n","    rmse = np.sqrt(np.mean((true_values - pred_values) ** 2))\n","    exact_match = np.mean(true_values == pred_values)\n","    within_1 = np.mean(np.abs(true_values - pred_values) <= 1)\n","    within_2 = np.mean(np.abs(true_values - pred_values) <= 2)\n","\n","    results[metric] = {\n","        'mae': mae,\n","        'rmse': rmse,\n","        'exact_match': exact_match,\n","        'within_1': within_1,\n","        'within_2': within_2\n","    }\n","\n","# Display per-metric results\n","print(\"\\nPer-Metric Performance:\")\n","print(\"-\" * 70)\n","print(f\"{'Metric':<20} {'MAE':>8} {'RMSE':>8} {'Exact':>8} {'±1':>8} {'±2':>8}\")\n","print(\"-\" * 70)\n","\n","for metric in METRICS:\n","    m = results[metric]\n","    print(f\"{metric:<20} {m['mae']:>8.2f} {m['rmse']:>8.2f} \"\n","          f\"{m['exact_match']*100:>7.1f}% {m['within_1']*100:>7.1f}% {m['within_2']*100:>7.1f}%\")\n","\n","# Overall metrics\n","all_true = test_df[METRICS].values.flatten()\n","all_pred = np.array([[p[m] for m in METRICS] for p in predictions]).flatten()\n","\n","overall_mae = np.mean(np.abs(all_true - all_pred))\n","overall_rmse = np.sqrt(np.mean((all_true - all_pred) ** 2))\n","overall_exact = np.mean(all_true == all_pred)\n","overall_within_1 = np.mean(np.abs(all_true - all_pred) <= 1)\n","overall_within_2 = np.mean(np.abs(all_true - all_pred) <= 2)\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"Overall Performance (all metrics combined):\")\n","print(\"-\" * 70)\n","print(f\"Mean Absolute Error (MAE):  {overall_mae:.3f}\")\n","print(f\"Root Mean Squared Error:     {overall_rmse:.3f}\")\n","print(f\"Exact Match Accuracy:        {overall_exact*100:.1f}%\")\n","print(f\"Within ±1 Accuracy:          {overall_within_1*100:.1f}%\")\n","print(f\"Within ±2 Accuracy:          {overall_within_2*100:.1f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3T-EtIR5nu4D","executionInfo":{"status":"ok","timestamp":1764537603509,"user_tz":480,"elapsed":19,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"24b27913-3186-4529-8160-afb6ce5497eb"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","EVALUATION METRICS\n","======================================================================\n","\n","Per-Metric Performance:\n","----------------------------------------------------------------------\n","Metric                    MAE     RMSE    Exact       ±1       ±2\n","----------------------------------------------------------------------\n","cognitive_ability        0.20     0.63    90.0%    90.0%   100.0%\n","experience               0.18     0.73    94.0%    94.0%    94.0%\n","problem_solving          0.88     1.55    66.0%    68.0%    78.0%\n","reliability              0.72     1.26    66.0%    66.0%    98.0%\n","professionalism          0.50     0.88    64.0%    86.0%   100.0%\n","communication            0.78     1.19    50.0%    76.0%    96.0%\n","\n","======================================================================\n","Overall Performance (all metrics combined):\n","----------------------------------------------------------------------\n","Mean Absolute Error (MAE):  0.543\n","Root Mean Squared Error:     1.091\n","Exact Match Accuracy:        71.7%\n","Within ±1 Accuracy:          80.0%\n","Within ±2 Accuracy:          94.3%\n"]}]},{"cell_type":"code","source":["# Create detailed results dataframe\n","results_df = test_df.copy()\n","\n","# Add predictions and errors\n","for metric in METRICS:\n","    results_df[f'predicted_{metric}'] = [p[metric] for p in predictions]\n","    results_df[f'error_{metric}'] = results_df[f'predicted_{metric}'] - results_df[metric]\n","\n","results_df['total_abs_error'] = sum(abs(results_df[f'error_{m}']) for m in METRICS)\n","\n","# Add latency data\n","results_df['latency_ms'] = latencies\n","\n","# Save predictions\n","predictions_path = os.path.join(OUTPUT_DIR, \"test_predictions.csv\")\n","results_df.to_csv(predictions_path, index=False)\n","print(f\"\\n✓ Detailed predictions saved: {predictions_path}\")\n","\n","# Save metrics as JSON\n","metrics_data = {\n","    'model': FINE_TUNED_MODEL,\n","    'test_samples': len(test_df),\n","    'timestamp': datetime.now().isoformat(),\n","    'per_metric': results,\n","    'overall': {\n","        'mae': overall_mae,\n","        'rmse': overall_rmse,\n","        'exact_match': overall_exact,\n","        'within_1': overall_within_1,\n","        'within_2': overall_within_2\n","    },\n","    'latency': {\n","        'mean_ms': float(np.mean(latencies)),\n","        'median_ms': float(np.median(latencies)),\n","        'p95_ms': float(np.percentile(latencies, 95)),\n","        'p99_ms': float(np.percentile(latencies, 99)),\n","        'min_ms': float(min(latencies)),\n","        'max_ms': float(max(latencies))\n","    }\n","}\n","\n","metrics_path = os.path.join(OUTPUT_DIR, \"evaluation_metrics.json\")\n","with open(metrics_path, 'w') as f:\n","    json.dump(metrics_data, f, indent=2)\n","print(f\"✓ Metrics saved: {metrics_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11CmmheRoZ6w","executionInfo":{"status":"ok","timestamp":1764537603533,"user_tz":480,"elapsed":22,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"4b563917-b74c-4fe2-a173-fb3e504fc1e7"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","✓ Detailed predictions saved: /content/drive/MyDrive/finetuning_output/test_predictions.csv\n","✓ Metrics saved: /content/drive/MyDrive/finetuning_output/evaluation_metrics.json\n"]}]},{"cell_type":"code","source":["# Error Analysis\n","print(\"\\n\" + \"=\" * 70)\n","print(\"ERROR ANALYSIS\")\n","print(\"=\" * 70)\n","\n","# Find worst predictions\n","worst_5 = results_df.nlargest(5, 'total_abs_error')\n","\n","print(\"\\nTop 5 Worst Predictions (by total absolute error):\")\n","print(\"-\" * 70)\n","\n","for idx, row in worst_5.iterrows():\n","    print(f\"\\n#{list(worst_5.index).index(idx) + 1}. Interview ID: {row['interview_id']}\")\n","    print(f\"   Role: {row['role']}\")\n","    print(f\"   Total Absolute Error: {row['total_abs_error']:.0f}\")\n","    print(\"   Scores (Truth → Predicted):\")\n","    for metric in METRICS:\n","        error_indicator = \"✓\" if abs(row[f'error_{metric}']) <= 1 else \"✗\"\n","        print(f\"     {error_indicator} {metric:<20}: {row[metric]:>2} → {row[f'predicted_{metric}']:>2} (error: {row[f'error_{metric}']:+3.0f})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3WVJpXOeogeb","executionInfo":{"status":"ok","timestamp":1764537603547,"user_tz":480,"elapsed":9,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"c0b20d5c-f512-40e8-93f8-d0f05b54ed24"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","ERROR ANALYSIS\n","======================================================================\n","\n","Top 5 Worst Predictions (by total absolute error):\n","----------------------------------------------------------------------\n","\n","#1. Interview ID: customer_service_representative_015\n","   Role: Customer Service Representative\n","   Total Absolute Error: 8\n","   Scores (Truth → Predicted):\n","     ✓ cognitive_ability   :  6 →  6 (error:  +0)\n","     ✓ experience          :  5 →  5 (error:  +0)\n","     ✗ problem_solving     :  9 →  6 (error:  -3)\n","     ✗ reliability         :  3 →  5 (error:  +2)\n","     ✓ professionalism     :  4 →  4 (error:  +0)\n","     ✗ communication       :  4 →  1 (error:  -3)\n","\n","#2. Interview ID: general_manager_(franchise)_028\n","   Role: General Manager (Franchise)\n","   Total Absolute Error: 8\n","   Scores (Truth → Predicted):\n","     ✗ cognitive_ability   :  4 →  6 (error:  +2)\n","     ✓ experience          :  8 →  8 (error:  +0)\n","     ✗ problem_solving     :  9 →  6 (error:  -3)\n","     ✓ reliability         :  5 →  5 (error:  +0)\n","     ✗ professionalism     :  4 →  2 (error:  -2)\n","     ✓ communication       :  2 →  1 (error:  -1)\n","\n","#3. Interview ID: general_manager_(franchise)_039\n","   Role: General Manager (Franchise)\n","   Total Absolute Error: 7\n","   Scores (Truth → Predicted):\n","     ✓ cognitive_ability   :  6 →  6 (error:  +0)\n","     ✓ experience          :  8 →  8 (error:  +0)\n","     ✗ problem_solving     :  9 →  6 (error:  -3)\n","     ✓ reliability         :  5 →  5 (error:  +0)\n","     ✗ professionalism     :  4 →  2 (error:  -2)\n","     ✗ communication       :  3 →  1 (error:  -2)\n","\n","#4. Interview ID: customer_service_representative_019\n","   Role: Customer Service Representative\n","   Total Absolute Error: 7\n","   Scores (Truth → Predicted):\n","     ✓ cognitive_ability   :  6 →  6 (error:  +0)\n","     ✓ experience          :  5 →  5 (error:  +0)\n","     ✗ problem_solving     :  9 →  6 (error:  -3)\n","     ✗ reliability         :  5 →  3 (error:  -2)\n","     ✗ professionalism     :  4 →  2 (error:  -2)\n","     ✓ communication       :  1 →  1 (error:  +0)\n","\n","#5. Interview ID: field_technician_026\n","   Role: Field Technician\n","   Total Absolute Error: 6\n","   Scores (Truth → Predicted):\n","     ✓ cognitive_ability   :  6 →  6 (error:  +0)\n","     ✗ experience          :  8 →  5 (error:  -3)\n","     ✗ problem_solving     :  9 →  6 (error:  -3)\n","     ✓ reliability         :  3 →  3 (error:  +0)\n","     ✓ professionalism     :  2 →  2 (error:  +0)\n","     ✓ communication       :  1 →  1 (error:  +0)\n"]}]},{"cell_type":"code","source":["# Show some examples of good predictions\n","best_5 = results_df.nsmallest(5, 'total_abs_error')\n","\n","print(\"\\n\" + \"=\" * 70)\n","print(\"Top 5 Best Predictions (by total absolute error):\")\n","print(\"-\" * 70)\n","\n","for idx, row in best_5.iterrows():\n","    print(f\"\\n#{list(best_5.index).index(idx) + 1}. Interview ID: {row['interview_id']}\")\n","    print(f\"   Role: {row['role']}\")\n","    print(f\"   Total Absolute Error: {row['total_abs_error']:.0f}\")\n","    print(\"   Scores (Truth → Predicted):\")\n","    for metric in METRICS:\n","        error_indicator = \"✓\" if abs(row[f'error_{metric}']) == 0 else \"~\"\n","        print(f\"     {error_indicator} {metric:<20}: {row[metric]:>2} → {row[f'predicted_{metric}']:>2} (error: {row[f'error_{metric}']:+3.0f})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JuGvHNnxohap","executionInfo":{"status":"ok","timestamp":1764537603558,"user_tz":480,"elapsed":9,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"2ad69fec-454f-449a-f873-b6380f1af411"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","======================================================================\n","Top 5 Best Predictions (by total absolute error):\n","----------------------------------------------------------------------\n","\n","#1. Interview ID: field_technician_002\n","   Role: Field Technician\n","   Total Absolute Error: 0\n","   Scores (Truth → Predicted):\n","     ✓ cognitive_ability   :  6 →  6 (error:  +0)\n","     ✓ experience          :  5 →  5 (error:  +0)\n","     ✓ problem_solving     :  6 →  6 (error:  +0)\n","     ✓ reliability         :  3 →  3 (error:  +0)\n","     ✓ professionalism     :  2 →  2 (error:  +0)\n","     ✓ communication       :  1 →  1 (error:  +0)\n","\n","#2. Interview ID: field_technician_008\n","   Role: Field Technician\n","   Total Absolute Error: 0\n","   Scores (Truth → Predicted):\n","     ✓ cognitive_ability   :  6 →  6 (error:  +0)\n","     ✓ experience          :  5 →  5 (error:  +0)\n","     ✓ problem_solving     :  9 →  9 (error:  +0)\n","     ✓ reliability         :  3 →  3 (error:  +0)\n","     ✓ professionalism     :  2 →  2 (error:  +0)\n","     ✓ communication       :  1 →  1 (error:  +0)\n","\n","#3. Interview ID: general_manager_(franchise)_005\n","   Role: General Manager (Franchise)\n","   Total Absolute Error: 0\n","   Scores (Truth → Predicted):\n","     ✓ cognitive_ability   :  6 →  6 (error:  +0)\n","     ✓ experience          :  8 →  8 (error:  +0)\n","     ✓ problem_solving     :  6 →  6 (error:  +0)\n","     ✓ reliability         :  5 →  5 (error:  +0)\n","     ✓ professionalism     :  2 →  2 (error:  +0)\n","     ✓ communication       :  1 →  1 (error:  +0)\n","\n","#4. Interview ID: home_service_technician_043\n","   Role: Home Service Technician\n","   Total Absolute Error: 0\n","   Scores (Truth → Predicted):\n","     ✓ cognitive_ability   :  8 →  8 (error:  +0)\n","     ✓ experience          :  8 →  8 (error:  +0)\n","     ✓ problem_solving     :  9 →  9 (error:  +0)\n","     ✓ reliability         :  7 →  7 (error:  +0)\n","     ✓ professionalism     :  6 →  6 (error:  +0)\n","     ✓ communication       :  6 →  6 (error:  +0)\n","\n","#5. Interview ID: home_service_technician_022\n","   Role: Home Service Technician\n","   Total Absolute Error: 0\n","   Scores (Truth → Predicted):\n","     ✓ cognitive_ability   :  8 →  8 (error:  +0)\n","     ✓ experience          :  8 →  8 (error:  +0)\n","     ✓ problem_solving     :  9 →  9 (error:  +0)\n","     ✓ reliability         :  7 →  7 (error:  +0)\n","     ✓ professionalism     :  6 →  6 (error:  +0)\n","     ✓ communication       :  6 →  6 (error:  +0)\n"]}]},{"cell_type":"markdown","metadata":{"id":"0E5oUISMuyAO"},"source":["## 12. Summary & Next Steps"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"Dq5VQi4ruyAO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764537661049,"user_tz":480,"elapsed":43,"user":{"displayName":"ServiceAgent Admin","userId":"13349337931342866618"}},"outputId":"d7e589bd-92c1-4177-a7d3-852cf7e24c54"},"outputs":[{"output_type":"stream","name":"stdout","text":["Fine-tuning Summary\n","======================================================================\n","\n","Dataset:\n","  Total samples: 250\n","  Training samples: 200\n","  Test samples: 50\n","\n","Files created:\n","  Train JSONL: /content/drive/MyDrive/finetuning_output/train.jsonl\n","  Test JSONL: /content/drive/MyDrive/finetuning_output/test.jsonl\n","  Test CSV: /content/drive/MyDrive/finetuning_output/test_set.csv\n","\n","OpenAI Resources:\n","  Training file ID: file-9AY2fj4MCN9kJtnYMzZUeh\n","  Job ID: ftjob-t9Yi16FKGtHzeZsY7zAPq7KU\n","  Fine-tuned model: ft:gpt-4o-2024-08-06:cleanagent:interview-scorer:ChhOUzkh\n","\n","Output directory: /content/drive/MyDrive/finetuning_output\n","\n","======================================================================\n","Next Steps:\n","  1. For full evaluation, use the kRuns.ipynb notebook with your fine-tuned model\n","  2. Update CURRENT_MODEL in kRuns.ipynb to your fine-tuned model name\n","  3. Run inference ONCE per test sample (no self-consistency needed for fine-tuned)\n","  4. Compare performance against base GPT-4o\n","======================================================================\n"]}],"source":["print(\"Fine-tuning Summary\")\n","print(\"=\" * 70)\n","print(f\"\\nDataset:\")\n","print(f\"  Total samples: {len(df_clean)}\")\n","print(f\"  Training samples: {len(train_df)}\")\n","print(f\"  Test samples: {len(test_df)}\")\n","print(f\"\\nFiles created:\")\n","print(f\"  Train JSONL: {train_file_path}\")\n","print(f\"  Test JSONL: {test_file_path}\")\n","print(f\"  Test CSV: {test_csv_path}\")\n","print(f\"\\nOpenAI Resources:\")\n","print(f\"  Training file ID: {train_file.id}\")\n","print(f\"  Job ID: {job.id}\")\n","if hasattr(current_job, 'fine_tuned_model') and current_job.fine_tuned_model:\n","    print(f\"  Fine-tuned model: {current_job.fine_tuned_model}\")\n","print(f\"\\nOutput directory: {OUTPUT_DIR}\")\n","print(\"\\n\" + \"=\" * 70)\n","print(\"Next Steps:\")\n","print(\"  1. For full evaluation, use the kRuns.ipynb notebook with your fine-tuned model\")\n","print(\"  2. Update CURRENT_MODEL in kRuns.ipynb to your fine-tuned model name\")\n","print(\"  3. Run inference ONCE per test sample (no self-consistency needed for fine-tuned)\")\n","print(\"  4. Compare performance against base GPT-4o\")\n","print(\"=\" * 70)"]},{"cell_type":"code","source":[],"metadata":{"id":"Bd42hQwAo_Vk"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}