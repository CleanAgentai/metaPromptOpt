{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Self-Consistency Scoring with OpenAI Models\n",
        "This notebook runs self-consistency evaluation using GPT-4o and GPT-3.5-turbo models."
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install openai pandas numpy pyyaml -q"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Set your OpenAI API key\n",
        "if \"OPENAI_API_KEY\" not in os.environ or not os.environ[\"OPENAI_API_KEY\"]:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "api_key",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e93c0e8b-fa3a-4fb8-ff80-2b8d963e4749"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # follow the auth prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq57y07OBu36",
        "outputId": "5e6ff97e-736a-40e1-9903-3763b46d8ed4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yaml\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import statistics as stats\n",
        "import re\n",
        "from typing import Dict, Any, List\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "imports"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "id": "config_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    \"role_title\": \"Field Technician\",\n",
        "    \"question_set_id\": \"qs_v1\",\n",
        "    \"question_set\": [\n",
        "        \"Tell me about a time you handled an urgent service call. What steps did you take?\",\n",
        "        \"How do you plan your route and prioritize jobs when schedules change during the day?\",\n",
        "        \"Describe a tricky diagnostic you solved. What tools or methods did you use?\",\n",
        "        \"How do you keep customers calm when they are upset or stressed?\",\n",
        "        \"Walk me through your process for documenting work and updating tickets.\",\n",
        "        \"What does reliability at work mean to you, and how do you demonstrate it?\",\n",
        "        \"How do you stay safe on the job and follow site-specific rules?\",\n",
        "        \"How do you collaborate with teammates or escalate when blocked?\"\n",
        "    ],\n",
        "    \"num_candidates\": 50,\n",
        "    \"k_samples\": 3,  # self-consistency K\n",
        "    \"generation_temperature\": 0.8,\n",
        "    \"generation_max_tokens\": 1200,\n",
        "    \"timeout_s\": 60,\n",
        "    \"gen_prompt_version\": \"gen_v1\",\n",
        "    \"score_prompt_version\": \"score_v1\",\n",
        "    \"rewrite_prompt_version\": \"rewrite_v1\",\n",
        "}\n",
        "\n",
        "# Choose your OpenAI model\n",
        "# Options: \"gpt-4o\", \"gpt-4o-mini\", \"gpt-3.5-turbo\", \"gpt-4-turbo\"\n",
        "# MODEL_ID = \"gpt-4o\"  # Change to \"gpt-3.5-turbo\" for GPT-3.5\n",
        "MODEL_ID = \"gpt-3.5-turbo\"\n",
        "\n",
        "# Scoring weights and metrics\n",
        "WEIGHTS = {\"ca\":0.35, \"exp\":0.35, \"ps\":0.15, \"rel\":0.05, \"prof\":0.05, \"comm\":0.05}\n",
        "METRICS = [\"ca\", \"exp\", \"ps\", \"rel\", \"prof\", \"comm\"]\n",
        "FILLERS_RE = re.compile(r\"\\b(?:um+|uh+|erm|like|you know|sort of|kinda|i mean|ya know)\\b\", re.IGNORECASE)"
      ],
      "metadata": {
        "id": "config"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "helpers_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_int(x, lo=1, hi=10):\n",
        "    try:\n",
        "        xi = int(round(float(x)))\n",
        "    except Exception:\n",
        "        xi = 5\n",
        "    return max(lo, min(hi, xi))\n",
        "\n",
        "def canonicalize_qa_text(text: str) -> str:\n",
        "    \"\"\"Clean and standardize QA text.\"\"\"\n",
        "    return text.strip()\n",
        "\n",
        "def compute_overall_weighted(scores: Dict[str, int]) -> float:\n",
        "    \"\"\"Compute weighted overall score.\"\"\"\n",
        "    total = sum(WEIGHTS.get(m, 0) * scores.get(m, 5) for m in METRICS)\n",
        "    return round(total, 2)\n",
        "\n",
        "def iqr_confidence(vals: List[int]) -> str:\n",
        "    \"\"\"Calculate confidence based on IQR.\"\"\"\n",
        "    if len(vals) < 2:\n",
        "        return \"low\"\n",
        "    q1, q3 = np.percentile(vals, [25, 75])\n",
        "    iqr = q3 - q1\n",
        "    if iqr <= 1:\n",
        "        return \"high\"\n",
        "    elif iqr <= 2:\n",
        "        return \"medium\"\n",
        "    else:\n",
        "        return \"low\""
      ],
      "metadata": {
        "id": "helpers"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Building Functions"
      ],
      "metadata": {
        "id": "prompts_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generation_prompt(role: str, question_set: List[str], persona: Dict[str, Any]) -> str:\n",
        "    \"\"\"Build prompt for generating candidate interview responses.\"\"\"\n",
        "    q_block = \"\\n\".join([f\"Question {i+1}: {q}\" for i, q in enumerate(question_set)])\n",
        "    lines = [\n",
        "        f\"You are the candidate interviewing for the role: {role}.\",\n",
        "        f\"Persona hints: title={persona['persona_title']}; years_experience={persona['yrs_experience']}; \"\n",
        "        f\"keywords={persona['domain_keywords']}; reliability={persona['reliability_flags']}; notes={persona['notes']}.\",\n",
        "        \"\",\n",
        "        \"Answer each question clearly (2–4 sentences per answer).\",\n",
        "        \"\",\n",
        "        q_block,\n",
        "        \"\",\n",
        "        \"Return responses in this pattern:\",\n",
        "        \"Question 1: <repeat question>\",\n",
        "        \"Answer: <answer>\",\n",
        "        \"\",\n",
        "        \"Question 2: <repeat question>\",\n",
        "        \"Answer: <answer>\",\n",
        "    ]\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def build_scoring_prompt(qa_text: str) -> str:\n",
        "    \"\"\"Build prompt for scoring candidate responses.\"\"\"\n",
        "    metrics_def = \"\\n\".join([\n",
        "        \"- Cognitive Ability (35%): Structured thinking, planning, logic.\",\n",
        "        \"- Experience (35%): Relevant work (last 10 years), skills, accomplishments in similar service jobs.\",\n",
        "        \"- Problem Solving (15%): Resourcefulness, safe tradeoffs under constraints.\",\n",
        "        \"- Reliability (5%): Punctuality, follow-through, transport reliability.\",\n",
        "        \"- Professionalism (5%): Respect for clients/rules, composure under stress.\",\n",
        "        \"- Communication (5%): Clarity and tone; IGNORE filler words.\",\n",
        "    ])\n",
        "    lines = [\n",
        "        \"Analyze the candidate responses using the six metrics below.\",\n",
        "        \"Return ONLY a JSON object with keys: ca, exp, ps, rel, prof, comm (each 1–10).\",\n",
        "        \"\",\n",
        "        \"Definitions (approximate weighting):\",\n",
        "        metrics_def,\n",
        "        \"\",\n",
        "        \"Candidate Responses:\",\n",
        "        \"--- START RESPONSES ---\",\n",
        "        qa_text,\n",
        "        \"--- END RESPONSES ---\",\n",
        "        \"\",\n",
        "        '{\"ca\":8,\"exp\":7,\"ps\":7,\"rel\":7,\"prof\":6,\"comm\":6}',\n",
        "    ]\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def build_rewrite_prompt_locked(qa_text: str, s: Dict[str, int]) -> str:\n",
        "    \"\"\"Build prompt for generating justifications with locked scores.\"\"\"\n",
        "    lines = [\n",
        "        \"Use FIXED scores; DO NOT change them. Generate justifications + bullets + summary.\",\n",
        "        \"\",\n",
        "        f\"- Cognitive Ability: {s['ca']}\",\n",
        "        f\"- Experience: {s['exp']}\",\n",
        "        f\"- Problem Solving: {s['ps']}\",\n",
        "        f\"- Reliability: {s['rel']}\",\n",
        "        f\"- Professionalism: {s['prof']}\",\n",
        "        f\"- Communication: {s['comm']}\",\n",
        "        \"\",\n",
        "        \"Return ONLY this JSON:\",\n",
        "        \"{\",\n",
        "        f'  \"cognitive_ability_score\": {s[\"ca\"]},',\n",
        "        '  \"cognitive_ability_justification\": \"...\",',\n",
        "        f'  \"experience_score\": {s[\"exp\"]},',\n",
        "        '  \"experience_justification\": \"...\",',\n",
        "        f'  \"reliability_score\": {s[\"rel\"]},',\n",
        "        '  \"reliability_justification\": \"...\",',\n",
        "        f'  \"professionalism_score\": {s[\"prof\"]},',\n",
        "        '  \"professionalism_justification\": \"...\",',\n",
        "        f'  \"problem_solving_score\": {s[\"ps\"]},',\n",
        "        '  \"problem_solving_justification\": \"...\",',\n",
        "        f'  \"communication_score\": {s[\"comm\"]},',\n",
        "        '  \"communication_justification\": \"...\",',\n",
        "        '  \"general_strengths\": \"- ...\\\\n- ...\\\\n- ...\",',\n",
        "        '  \"general_weaknesses\": \"- ...\\\\n- ...\\\\n- ...\",',\n",
        "        '  \"general_summary\": \"...\"',\n",
        "        \"}\",\n",
        "        \"\",\n",
        "        \"Candidate Responses:\",\n",
        "        \"--- START ---\",\n",
        "        qa_text,\n",
        "        \"--- END ---\",\n",
        "    ]\n",
        "    return \"\\n\".join(lines)"
      ],
      "metadata": {
        "id": "prompt_builders"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OpenAI API Client Functions"
      ],
      "metadata": {
        "id": "api_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize OpenAI client\n",
        "openai_client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "\n",
        "def openai_chat_once(prompt: str, model: str, temperature: float = 0.7,\n",
        "                     max_tokens: int = 512, json_mode: bool = False) -> str:\n",
        "    \"\"\"Call OpenAI chat completion API.\"\"\"\n",
        "    kwargs = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": temperature,\n",
        "        \"max_tokens\": max_tokens,\n",
        "        \"top_p\": 1.0,\n",
        "    }\n",
        "\n",
        "    if json_mode:\n",
        "        # Use JSON mode for structured outputs\n",
        "        kwargs[\"response_format\"] = {\"type\": \"json_object\"}\n",
        "\n",
        "    try:\n",
        "        resp = openai_client.chat.completions.create(**kwargs)\n",
        "        return resp.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling OpenAI API: {e}\")\n",
        "        raise\n",
        "\n",
        "def openai_chat_json(prompt: str, model: str, temperature: float,\n",
        "                     max_tokens: int = 512) -> tuple:\n",
        "    \"\"\"Call OpenAI API and parse JSON response.\"\"\"\n",
        "    txt = openai_chat_once(prompt, model=model, temperature=temperature,\n",
        "                          max_tokens=max_tokens, json_mode=True)\n",
        "    try:\n",
        "        return json.loads(txt), txt\n",
        "    except Exception:\n",
        "        # Fallback: try to extract JSON from text\n",
        "        try:\n",
        "            start = txt.index(\"{\")\n",
        "            end = txt.rindex(\"}\") + 1\n",
        "            return json.loads(txt[start:end]), txt\n",
        "        except Exception:\n",
        "            return {}, txt"
      ],
      "metadata": {
        "id": "api_functions"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Generate Synthetic Interview Responses"
      ],
      "metadata": {
        "id": "step1_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(123)\n",
        "\n",
        "role = CONFIG[\"role_title\"]\n",
        "questions = CONFIG[\"question_set\"]\n",
        "N = CONFIG[\"num_candidates\"]\n",
        "\n",
        "interviews = []\n",
        "for i in range(N):\n",
        "    persona = {\n",
        "        \"candidate_id\": f\"cand_{i+1:04d}\",\n",
        "        \"persona_title\": random.choice([\n",
        "            \"Veteran field tech\", \"Career switcher\", \"Recent grad\",\n",
        "            \"Retail service rep\", \"HVAC junior\"\n",
        "        ]),\n",
        "        \"yrs_experience\": random.choice([0, 1, 2, 3, 5, 7, 10]),\n",
        "        \"domain_keywords\": random.choice([\n",
        "            \"preventive maintenance, HVAC, route planning\",\n",
        "            \"customer empathy, troubleshooting basics\",\n",
        "            \"inventory, parts ordering, safety protocols\",\n",
        "            \"ticket triage, escalation, SLA awareness\",\n",
        "        ]),\n",
        "        \"reliability_flags\": random.choice([\n",
        "            \"has_car; weekend_ok\", \"public_transit\", \"night_shift_ok\"\n",
        "        ]),\n",
        "        \"notes\": random.choice([\n",
        "            \"calm under pressure\", \"fast learner\", \"detail-oriented\"\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    prompt = build_generation_prompt(role, questions, persona)\n",
        "    out = openai_chat_once(\n",
        "        prompt,\n",
        "        model=MODEL_ID,\n",
        "        temperature=CONFIG[\"generation_temperature\"],\n",
        "        max_tokens=CONFIG[\"generation_max_tokens\"]\n",
        "    )\n",
        "\n",
        "    interviews.append({\n",
        "        \"interview_id\": f\"intv_{i+1:04d}\",\n",
        "        \"candidate_id\": persona[\"candidate_id\"],\n",
        "        \"role_title\": role,\n",
        "        \"question_set_id\": CONFIG[\"question_set_id\"],\n",
        "        \"num_questions\": len(questions),\n",
        "        \"qa_text\": canonicalize_qa_text(out),\n",
        "        \"source\": \"synthetic\",\n",
        "        \"gen_model\": MODEL_ID,\n",
        "        \"gen_prompt_version\": CONFIG[\"gen_prompt_version\"],\n",
        "        \"gen_temperature\": CONFIG[\"generation_temperature\"],\n",
        "        \"gen_top_p\": 1.0,\n",
        "        \"gen_seed\": 123,\n",
        "        \"created_at\": pd.Timestamp.utcnow().isoformat(),\n",
        "    })\n",
        "\n",
        "    if (i + 1) % 10 == 0:\n",
        "        print(f\"Generated {i + 1}/{N} interviews...\")\n",
        "\n",
        "interviews_df = pd.DataFrame(interviews)\n",
        "print(f\"\\nGenerated {len(interviews_df)} interviews\")\n",
        "display(interviews_df.head(2))"
      ],
      "metadata": {
        "id": "generate_interviews"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interviews_df = pd.read_csv(\"/content/drive/MyDrive/mvp/synthInterviews20251009-234435.csv\")"
      ],
      "metadata": {
        "id": "_q8lbkcjCN02"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Generate K Self-Consistency Samples (Scoring)"
      ],
      "metadata": {
        "id": "step2_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = CONFIG[\"k_samples\"]\n",
        "records = interviews_df[[\"interview_id\", \"qa_text\"]].to_dict(\"records\")\n",
        "\n",
        "samples = []\n",
        "for idx, iv in enumerate(records):\n",
        "    qa = iv[\"qa_text\"] or \"\"\n",
        "    sprompt = build_scoring_prompt(qa)\n",
        "\n",
        "    for k in range(K):\n",
        "        t0 = time.time()\n",
        "        js, raw = openai_chat_json(\n",
        "            sprompt,\n",
        "            model=MODEL_ID,\n",
        "            temperature=0.7,\n",
        "            max_tokens=256\n",
        "        )\n",
        "        latency = int((time.time() - t0) * 1000)\n",
        "\n",
        "        row = {\n",
        "            \"interview_id\": iv[\"interview_id\"],\n",
        "            \"run_idx\": k,\n",
        "            \"model_name\": MODEL_ID,\n",
        "            \"latency_ms\": latency,\n",
        "        }\n",
        "        for m in METRICS:\n",
        "            row[m] = clamp_int(js.get(m, 5))\n",
        "        samples.append(row)\n",
        "\n",
        "    if (idx + 1) % 10 == 0:\n",
        "        print(f\"Scored {idx + 1}/{len(records)} interviews (K={K} each)...\")\n",
        "\n",
        "samples_df = pd.DataFrame(samples)\n",
        "print(f\"\\nGenerated {len(samples_df)} scoring samples\")\n",
        "display(samples_df.head(9))  # Show 3 samples for 3 interviews"
      ],
      "metadata": {
        "id": "score_samples",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "5b7db5f8-1571-439d-f0a6-4685f34472fa"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scored 10/50 interviews (K=3 each)...\n",
            "Scored 20/50 interviews (K=3 each)...\n",
            "Scored 30/50 interviews (K=3 each)...\n",
            "Scored 40/50 interviews (K=3 each)...\n",
            "Scored 50/50 interviews (K=3 each)...\n",
            "\n",
            "Generated 150 scoring samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  interview_id  run_idx     model_name  latency_ms  ca  exp  ps  rel  prof  \\\n",
              "0    intv_0001        0  gpt-3.5-turbo        1495   8    7   7    7     6   \n",
              "1    intv_0001        1  gpt-3.5-turbo         962   8    7   7    7     6   \n",
              "2    intv_0001        2  gpt-3.5-turbo        1104   8    7   7    7     6   \n",
              "3    intv_0002        0  gpt-3.5-turbo        1416   8    7   7    7     6   \n",
              "4    intv_0002        1  gpt-3.5-turbo        1170   8    7   7    7     6   \n",
              "5    intv_0002        2  gpt-3.5-turbo        1102   8    7   7    7     6   \n",
              "6    intv_0003        0  gpt-3.5-turbo        1219   8    7   7    7     6   \n",
              "7    intv_0003        1  gpt-3.5-turbo         776   8    7   7    7     6   \n",
              "8    intv_0003        2  gpt-3.5-turbo        1041   8    7   7    7     6   \n",
              "\n",
              "   comm  \n",
              "0     6  \n",
              "1     6  \n",
              "2     6  \n",
              "3     6  \n",
              "4     6  \n",
              "5     6  \n",
              "6     6  \n",
              "7     6  \n",
              "8     6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6d5929c-d05c-495d-b3de-1541524383bb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>interview_id</th>\n",
              "      <th>run_idx</th>\n",
              "      <th>model_name</th>\n",
              "      <th>latency_ms</th>\n",
              "      <th>ca</th>\n",
              "      <th>exp</th>\n",
              "      <th>ps</th>\n",
              "      <th>rel</th>\n",
              "      <th>prof</th>\n",
              "      <th>comm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>intv_0001</td>\n",
              "      <td>0</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "      <td>1495</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>intv_0001</td>\n",
              "      <td>1</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "      <td>962</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intv_0001</td>\n",
              "      <td>2</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "      <td>1104</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intv_0002</td>\n",
              "      <td>0</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "      <td>1416</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>intv_0002</td>\n",
              "      <td>1</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "      <td>1170</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>intv_0002</td>\n",
              "      <td>2</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "      <td>1102</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>intv_0003</td>\n",
              "      <td>0</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "      <td>1219</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>intv_0003</td>\n",
              "      <td>1</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "      <td>776</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>intv_0003</td>\n",
              "      <td>2</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "      <td>1041</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6d5929c-d05c-495d-b3de-1541524383bb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6d5929c-d05c-495d-b3de-1541524383bb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6d5929c-d05c-495d-b3de-1541524383bb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b4369c13-117f-4f1f-8120-04c2f58ae1ad\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4369c13-117f-4f1f-8120-04c2f58ae1ad')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b4369c13-117f-4f1f-8120-04c2f58ae1ad button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(samples_df\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"interview_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"intv_0001\",\n          \"intv_0002\",\n          \"intv_0003\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"gpt-3.5-turbo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latency_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 219,\n        \"min\": 776,\n        \"max\": 1495,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          776\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rel\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prof\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Aggregate Scores (Self-Consistency)"
      ],
      "metadata": {
        "id": "step3_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aggs = []\n",
        "for intv_id, g in samples_df.groupby(\"interview_id\"):\n",
        "    row = {\"interview_id\": intv_id}\n",
        "    latencies = g[\"latency_ms\"].tolist()\n",
        "\n",
        "    for m in METRICS:\n",
        "        vals = [int(v) for v in g[m].tolist()]\n",
        "        row[f\"{m}_score_agg\"] = clamp_int(stats.median(vals))\n",
        "        row[f\"{m}_confidence\"] = iqr_confidence(vals)\n",
        "\n",
        "    row[\"overall_weighted_agg\"] = compute_overall_weighted(\n",
        "        {m: row[f\"{m}_score_agg\"] for m in METRICS}\n",
        "    )\n",
        "    row[\"p95_latency_ms\"] = float(np.percentile(latencies, 95)) if latencies else 0\n",
        "    aggs.append(row)\n",
        "\n",
        "aggregated_df = pd.DataFrame(aggs)\n",
        "print(f\"Aggregated {len(aggregated_df)} interview scores\")\n",
        "display(aggregated_df.head())"
      ],
      "metadata": {
        "id": "aggregate",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "ae5ba31c-4c8b-4598-bd63-6bfedd9a0660"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated 50 interview scores\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  interview_id  ca_score_agg ca_confidence  exp_score_agg exp_confidence  \\\n",
              "0    intv_0001             8          high              7           high   \n",
              "1    intv_0002             8          high              7           high   \n",
              "2    intv_0003             8          high              7           high   \n",
              "3    intv_0004             8          high              7           high   \n",
              "4    intv_0005             8          high              7           high   \n",
              "\n",
              "   ps_score_agg ps_confidence  rel_score_agg rel_confidence  prof_score_agg  \\\n",
              "0             7          high              7           high               6   \n",
              "1             7          high              7           high               6   \n",
              "2             7          high              7           high               6   \n",
              "3             7          high              7           high               6   \n",
              "4             7          high              7           high               6   \n",
              "\n",
              "  prof_confidence  comm_score_agg comm_confidence  overall_weighted_agg  \\\n",
              "0            high               6            high                  7.25   \n",
              "1            high               6            high                  7.25   \n",
              "2            high               6            high                  7.25   \n",
              "3            high               6            high                  7.25   \n",
              "4            high               6            high                  7.25   \n",
              "\n",
              "   p95_latency_ms  \n",
              "0          1455.9  \n",
              "1          1391.4  \n",
              "2          1201.2  \n",
              "3          3427.5  \n",
              "4          1182.6  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52efe45b-0dcc-48f1-8d00-2b1bfa62a57a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>interview_id</th>\n",
              "      <th>ca_score_agg</th>\n",
              "      <th>ca_confidence</th>\n",
              "      <th>exp_score_agg</th>\n",
              "      <th>exp_confidence</th>\n",
              "      <th>ps_score_agg</th>\n",
              "      <th>ps_confidence</th>\n",
              "      <th>rel_score_agg</th>\n",
              "      <th>rel_confidence</th>\n",
              "      <th>prof_score_agg</th>\n",
              "      <th>prof_confidence</th>\n",
              "      <th>comm_score_agg</th>\n",
              "      <th>comm_confidence</th>\n",
              "      <th>overall_weighted_agg</th>\n",
              "      <th>p95_latency_ms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>intv_0001</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>6</td>\n",
              "      <td>high</td>\n",
              "      <td>6</td>\n",
              "      <td>high</td>\n",
              "      <td>7.25</td>\n",
              "      <td>1455.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>intv_0002</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>6</td>\n",
              "      <td>high</td>\n",
              "      <td>6</td>\n",
              "      <td>high</td>\n",
              "      <td>7.25</td>\n",
              "      <td>1391.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intv_0003</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>6</td>\n",
              "      <td>high</td>\n",
              "      <td>6</td>\n",
              "      <td>high</td>\n",
              "      <td>7.25</td>\n",
              "      <td>1201.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intv_0004</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>6</td>\n",
              "      <td>high</td>\n",
              "      <td>6</td>\n",
              "      <td>high</td>\n",
              "      <td>7.25</td>\n",
              "      <td>3427.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>intv_0005</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>6</td>\n",
              "      <td>high</td>\n",
              "      <td>6</td>\n",
              "      <td>high</td>\n",
              "      <td>7.25</td>\n",
              "      <td>1182.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52efe45b-0dcc-48f1-8d00-2b1bfa62a57a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-52efe45b-0dcc-48f1-8d00-2b1bfa62a57a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-52efe45b-0dcc-48f1-8d00-2b1bfa62a57a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-be1725c0-2557-44f9-ad82-ca9559e4bfbf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-be1725c0-2557-44f9-ad82-ca9559e4bfbf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-be1725c0-2557-44f9-ad82-ca9559e4bfbf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(aggregated_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"interview_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"intv_0002\",\n          \"intv_0005\",\n          \"intv_0003\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca_confidence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exp_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exp_confidence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ps_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ps_confidence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rel_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rel_confidence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prof_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prof_confidence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comm_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comm_confidence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overall_weighted_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 7.25,\n        \"max\": 7.25,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p95_latency_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 955.320421115345,\n        \"min\": 1182.6,\n        \"max\": 3427.5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1391.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Generate Final Outputs with Justifications"
      ],
      "metadata": {
        "id": "step4_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_map = dict(zip(interviews_df[\"interview_id\"], interviews_df[\"qa_text\"]))\n",
        "\n",
        "def rewrite_once_chat(qa_text: str, scores_locked: Dict[str, int],\n",
        "                     model: str, max_tokens: int = 1200) -> tuple:\n",
        "    \"\"\"Generate justifications for locked scores.\"\"\"\n",
        "    prompt = (\n",
        "        \"Respond with exactly ONE JSON object, no code fences, no prose, no markdown. \"\n",
        "        \"Do not include any keys that are not requested.\\n\\n\"\n",
        "        + build_rewrite_prompt_locked(qa_text, scores_locked)\n",
        "    )\n",
        "    t0 = time.time()\n",
        "    js, raw = openai_chat_json(prompt, model=model, temperature=0.0, max_tokens=max_tokens)\n",
        "    latency = int((time.time() - t0) * 1000)\n",
        "    return js, raw, latency\n",
        "\n",
        "final_rows = []\n",
        "invalid_count = 0\n",
        "\n",
        "for _, agg_row in aggregated_df.iterrows():\n",
        "    iid = agg_row[\"interview_id\"]\n",
        "    qa_text = qa_map.get(iid, \"\")\n",
        "    if not qa_text:\n",
        "        invalid_count += 1\n",
        "        continue\n",
        "\n",
        "    scores_locked = {m: agg_row[f\"{m}_score_agg\"] for m in METRICS}\n",
        "    js, raw_text, lat = rewrite_once_chat(qa_text, scores_locked, model=MODEL_ID)\n",
        "\n",
        "    # Validate scores match\n",
        "    score_keys = [\n",
        "        \"cognitive_ability_score\", \"experience_score\", \"reliability_score\",\n",
        "        \"professionalism_score\", \"problem_solving_score\", \"communication_score\"\n",
        "    ]\n",
        "    if all(k in js for k in score_keys):\n",
        "        out_row = {\n",
        "            \"interview_id\": iid,\n",
        "            \"cognitive_ability_score\": js.get(\"cognitive_ability_score\"),\n",
        "            \"cognitive_ability_justification\": js.get(\"cognitive_ability_justification\", \"\"),\n",
        "            \"experience_score\": js.get(\"experience_score\"),\n",
        "            \"experience_justification\": js.get(\"experience_justification\", \"\"),\n",
        "            \"reliability_score\": js.get(\"reliability_score\"),\n",
        "            \"reliability_justification\": js.get(\"reliability_justification\", \"\"),\n",
        "            \"professionalism_score\": js.get(\"professionalism_score\"),\n",
        "            \"professionalism_justification\": js.get(\"professionalism_justification\", \"\"),\n",
        "            \"problem_solving_score\": js.get(\"problem_solving_score\"),\n",
        "            \"problem_solving_justification\": js.get(\"problem_solving_justification\", \"\"),\n",
        "            \"communication_score\": js.get(\"communication_score\"),\n",
        "            \"communication_justification\": js.get(\"communication_justification\", \"\"),\n",
        "            \"general_strengths\": js.get(\"general_strengths\", \"\"),\n",
        "            \"general_weaknesses\": js.get(\"general_weaknesses\", \"\"),\n",
        "            \"general_summary\": js.get(\"general_summary\", \"\"),\n",
        "            \"overall_weighted_score\": agg_row[\"overall_weighted_agg\"],\n",
        "            \"rewrite_latency_ms\": lat,\n",
        "            \"rewrite_model\": MODEL_ID,\n",
        "        }\n",
        "        final_rows.append(out_row)\n",
        "    else:\n",
        "        invalid_count += 1\n",
        "\n",
        "final_df = pd.DataFrame(final_rows)\n",
        "print(f\"Final rows: {len(final_df)} | Invalid rewrites: {invalid_count}\")\n",
        "display(final_df.head())"
      ],
      "metadata": {
        "id": "rewrite",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "767e107d-cc95-4010-9f09-5ba592659a99"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final rows: 50 | Invalid rewrites: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  interview_id  cognitive_ability_score  \\\n",
              "0    intv_0001                        8   \n",
              "1    intv_0002                        8   \n",
              "2    intv_0003                        8   \n",
              "3    intv_0004                        8   \n",
              "4    intv_0005                        8   \n",
              "\n",
              "                     cognitive_ability_justification  experience_score  \\\n",
              "0  Demonstrated strong problem-solving skills in ...                 7   \n",
              "1  Demonstrated ability to analyze complex issues...                 7   \n",
              "2  The candidate demonstrates strong problem-solv...                 7   \n",
              "3  The candidate demonstrated strong problem-solv...                 7   \n",
              "4  The candidate demonstrates strong cognitive ab...                 7   \n",
              "\n",
              "                            experience_justification  reliability_score  \\\n",
              "0  Seasoned field technician with a proven track ...                  7   \n",
              "1  Seasoned field technician with a track record ...                  7   \n",
              "2  The candidate has relevant experience as an HV...                  7   \n",
              "3  The candidate has relevant experience as a Fie...                  7   \n",
              "4  Although the candidate lacks direct experience...                  7   \n",
              "\n",
              "                           reliability_justification  professionalism_score  \\\n",
              "0  Prioritizes safety, follows site-specific rule...                      6   \n",
              "1  Dependable, responsible, and consistent in act...                      6   \n",
              "2  The candidate emphasizes the importance of rel...                      6   \n",
              "3  The candidate emphasized the importance of rel...                      6   \n",
              "4  The candidate emphasizes the importance of rel...                      6   \n",
              "\n",
              "                       professionalism_justification  problem_solving_score  \\\n",
              "0  Maintains a calm and professional demeanor whe...                      7   \n",
              "1  Maintains a calm and professional demeanor whe...                      7   \n",
              "2  The candidate exhibits professionalism in deal...                      7   \n",
              "3  The candidate maintained a professional demean...                      7   \n",
              "4  While the candidate maintains a professional a...                      7   \n",
              "\n",
              "                       problem_solving_justification  communication_score  \\\n",
              "0  Successfully resolved tricky diagnostics using...                    6   \n",
              "1  Utilizes a combination of tools and methods to...                    6   \n",
              "2  The candidate demonstrates strong problem-solv...                    6   \n",
              "3  The candidate showcased strong problem-solving...                    6   \n",
              "4  The candidate shows an understanding of proble...                    6   \n",
              "\n",
              "                         communication_justification  \\\n",
              "0  Effectively collaborates with teammates, escal...   \n",
              "1  Clear and concise communication with customers...   \n",
              "2  The candidate effectively communicates with cu...   \n",
              "3  The candidate demonstrated effective communica...   \n",
              "4  The candidate exhibits clear communication ski...   \n",
              "\n",
              "                                   general_strengths  \\\n",
              "0  - Strong problem-solving skills\\n- Seasoned fi...   \n",
              "1  - Strong problem-solving skills\\n- Excellent e...   \n",
              "2  - Strong problem-solving skills\\n- Relevant ex...   \n",
              "3  - Strong problem-solving skills\\n- Relevant ex...   \n",
              "4  - Strong cognitive abilities\\n- Transferable s...   \n",
              "\n",
              "                                  general_weaknesses  \\\n",
              "0  - Communication skills can be further improved...   \n",
              "1  - Communication skills could be further improv...   \n",
              "2  - Room for improvement in professionalism\\n- C...   \n",
              "3  - Room for improvement in professionalism\\n- O...   \n",
              "4  - Room for improvement in professionalism\\n- P...   \n",
              "\n",
              "                                     general_summary  overall_weighted_score  \\\n",
              "0  Overall, the candidate demonstrates a high lev...                    7.25   \n",
              "1  The candidate demonstrates strong cognitive ab...                    7.25   \n",
              "2  Overall, the candidate shows promise with soli...                    7.25   \n",
              "3  The candidate excels in cognitive ability, pro...                    7.25   \n",
              "4  Overall, the candidate shows promise with thei...                    7.25   \n",
              "\n",
              "   rewrite_latency_ms  rewrite_model  \n",
              "0                5862  gpt-3.5-turbo  \n",
              "1                3291  gpt-3.5-turbo  \n",
              "2                3599  gpt-3.5-turbo  \n",
              "3                3504  gpt-3.5-turbo  \n",
              "4                5841  gpt-3.5-turbo  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a32e5c7b-b7ff-44b5-acae-2a4eafdd11cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>interview_id</th>\n",
              "      <th>cognitive_ability_score</th>\n",
              "      <th>cognitive_ability_justification</th>\n",
              "      <th>experience_score</th>\n",
              "      <th>experience_justification</th>\n",
              "      <th>reliability_score</th>\n",
              "      <th>reliability_justification</th>\n",
              "      <th>professionalism_score</th>\n",
              "      <th>professionalism_justification</th>\n",
              "      <th>problem_solving_score</th>\n",
              "      <th>problem_solving_justification</th>\n",
              "      <th>communication_score</th>\n",
              "      <th>communication_justification</th>\n",
              "      <th>general_strengths</th>\n",
              "      <th>general_weaknesses</th>\n",
              "      <th>general_summary</th>\n",
              "      <th>overall_weighted_score</th>\n",
              "      <th>rewrite_latency_ms</th>\n",
              "      <th>rewrite_model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>intv_0001</td>\n",
              "      <td>8</td>\n",
              "      <td>Demonstrated strong problem-solving skills in ...</td>\n",
              "      <td>7</td>\n",
              "      <td>Seasoned field technician with a proven track ...</td>\n",
              "      <td>7</td>\n",
              "      <td>Prioritizes safety, follows site-specific rule...</td>\n",
              "      <td>6</td>\n",
              "      <td>Maintains a calm and professional demeanor whe...</td>\n",
              "      <td>7</td>\n",
              "      <td>Successfully resolved tricky diagnostics using...</td>\n",
              "      <td>6</td>\n",
              "      <td>Effectively collaborates with teammates, escal...</td>\n",
              "      <td>- Strong problem-solving skills\\n- Seasoned fi...</td>\n",
              "      <td>- Communication skills can be further improved...</td>\n",
              "      <td>Overall, the candidate demonstrates a high lev...</td>\n",
              "      <td>7.25</td>\n",
              "      <td>5862</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>intv_0002</td>\n",
              "      <td>8</td>\n",
              "      <td>Demonstrated ability to analyze complex issues...</td>\n",
              "      <td>7</td>\n",
              "      <td>Seasoned field technician with a track record ...</td>\n",
              "      <td>7</td>\n",
              "      <td>Dependable, responsible, and consistent in act...</td>\n",
              "      <td>6</td>\n",
              "      <td>Maintains a calm and professional demeanor whe...</td>\n",
              "      <td>7</td>\n",
              "      <td>Utilizes a combination of tools and methods to...</td>\n",
              "      <td>6</td>\n",
              "      <td>Clear and concise communication with customers...</td>\n",
              "      <td>- Strong problem-solving skills\\n- Excellent e...</td>\n",
              "      <td>- Communication skills could be further improv...</td>\n",
              "      <td>The candidate demonstrates strong cognitive ab...</td>\n",
              "      <td>7.25</td>\n",
              "      <td>3291</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intv_0003</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate demonstrates strong problem-solv...</td>\n",
              "      <td>7</td>\n",
              "      <td>The candidate has relevant experience as an HV...</td>\n",
              "      <td>7</td>\n",
              "      <td>The candidate emphasizes the importance of rel...</td>\n",
              "      <td>6</td>\n",
              "      <td>The candidate exhibits professionalism in deal...</td>\n",
              "      <td>7</td>\n",
              "      <td>The candidate demonstrates strong problem-solv...</td>\n",
              "      <td>6</td>\n",
              "      <td>The candidate effectively communicates with cu...</td>\n",
              "      <td>- Strong problem-solving skills\\n- Relevant ex...</td>\n",
              "      <td>- Room for improvement in professionalism\\n- C...</td>\n",
              "      <td>Overall, the candidate shows promise with soli...</td>\n",
              "      <td>7.25</td>\n",
              "      <td>3599</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intv_0004</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate demonstrated strong problem-solv...</td>\n",
              "      <td>7</td>\n",
              "      <td>The candidate has relevant experience as a Fie...</td>\n",
              "      <td>7</td>\n",
              "      <td>The candidate emphasized the importance of rel...</td>\n",
              "      <td>6</td>\n",
              "      <td>The candidate maintained a professional demean...</td>\n",
              "      <td>7</td>\n",
              "      <td>The candidate showcased strong problem-solving...</td>\n",
              "      <td>6</td>\n",
              "      <td>The candidate demonstrated effective communica...</td>\n",
              "      <td>- Strong problem-solving skills\\n- Relevant ex...</td>\n",
              "      <td>- Room for improvement in professionalism\\n- O...</td>\n",
              "      <td>The candidate excels in cognitive ability, pro...</td>\n",
              "      <td>7.25</td>\n",
              "      <td>3504</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>intv_0005</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate demonstrates strong cognitive ab...</td>\n",
              "      <td>7</td>\n",
              "      <td>Although the candidate lacks direct experience...</td>\n",
              "      <td>7</td>\n",
              "      <td>The candidate emphasizes the importance of rel...</td>\n",
              "      <td>6</td>\n",
              "      <td>While the candidate maintains a professional a...</td>\n",
              "      <td>7</td>\n",
              "      <td>The candidate shows an understanding of proble...</td>\n",
              "      <td>6</td>\n",
              "      <td>The candidate exhibits clear communication ski...</td>\n",
              "      <td>- Strong cognitive abilities\\n- Transferable s...</td>\n",
              "      <td>- Room for improvement in professionalism\\n- P...</td>\n",
              "      <td>Overall, the candidate shows promise with thei...</td>\n",
              "      <td>7.25</td>\n",
              "      <td>5841</td>\n",
              "      <td>gpt-3.5-turbo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a32e5c7b-b7ff-44b5-acae-2a4eafdd11cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a32e5c7b-b7ff-44b5-acae-2a4eafdd11cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a32e5c7b-b7ff-44b5-acae-2a4eafdd11cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8a4945ee-f6cc-4625-baba-23156af915ad\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a4945ee-f6cc-4625-baba-23156af915ad')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8a4945ee-f6cc-4625-baba-23156af915ad button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(final_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"interview_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"intv_0002\",\n          \"intv_0005\",\n          \"intv_0003\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cognitive_ability_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cognitive_ability_justification\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Demonstrated ability to analyze complex issues and make informed decisions under pressure.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"experience_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"experience_justification\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Seasoned field technician with a track record of successfully handling various service calls and diagnostic challenges.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reliability_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reliability_justification\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Dependable, responsible, and consistent in actions, prioritizing preventive maintenance and proactive troubleshooting.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"professionalism_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"professionalism_justification\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Maintains a calm and professional demeanor when dealing with upset or stressed customers.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"problem_solving_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 7,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"problem_solving_justification\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Utilizes a combination of tools and methods to diagnose and solve tricky technical issues efficiently.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"communication_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 6,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"communication_justification\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Clear and concise communication with customers, team members, and management to ensure effective collaboration and issue resolution.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"general_strengths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"- Strong problem-solving skills\\n- Excellent experience in field service\\n- Reliable and consistent in work ethic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"general_weaknesses\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"- Communication skills could be further improved\\n- Professionalism can be enhanced in certain situations\\n- Limited room for growth in cognitive ability\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"general_summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The candidate demonstrates strong cognitive ability, experience, and problem-solving skills, with areas for improvement in communication and professionalism. Overall, a reliable and skilled field technician with potential for growth.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overall_weighted_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 7.25,\n        \"max\": 7.25,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rewrite_latency_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1312,\n        \"min\": 3291,\n        \"max\": 5862,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3291\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rewrite_model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"gpt-3.5-turbo\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Results"
      ],
      "metadata": {
        "id": "save_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save all dataframes\n",
        "ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
        "model_safe = MODEL_ID.replace(\"/\", \"_\").replace(\":\", \"_\")\n",
        "\n",
        "interviews_df.to_csv(f\"interviews_{model_safe}_{ts}.csv\", index=False)\n",
        "samples_df.to_csv(f\"samples_{model_safe}_{ts}.csv\", index=False)\n",
        "aggregated_df.to_csv(f\"aggregated_{model_safe}_{ts}.csv\", index=False)\n",
        "final_df.to_csv(f\"final_{model_safe}_{ts}.csv\", index=False)\n",
        "\n",
        "print(f\"Saved all results with timestamp: {ts}\")\n",
        "print(f\"Model used: {MODEL_ID}\")\n",
        "print(f\"\\nFiles saved:\")\n",
        "print(f\"- interviews_{model_safe}_{ts}.csv\")\n",
        "print(f\"- samples_{model_safe}_{ts}.csv\")\n",
        "print(f\"- aggregated_{model_safe}_{ts}.csv\")\n",
        "print(f\"- final_{model_safe}_{ts}.csv\")"
      ],
      "metadata": {
        "id": "save",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb170da-8832-4c77-e2c0-caad1e8330fa"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved all results with timestamp: 20251104-231014\n",
            "Model used: gpt-3.5-turbo\n",
            "\n",
            "Files saved:\n",
            "- interviews_gpt-3.5-turbo_20251104-231014.csv\n",
            "- samples_gpt-3.5-turbo_20251104-231014.csv\n",
            "- aggregated_gpt-3.5-turbo_20251104-231014.csv\n",
            "- final_gpt-3.5-turbo_20251104-231014.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3613257516.py:2: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary Statistics"
      ],
      "metadata": {
        "id": "summary_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(f\"SELF-CONSISTENCY SCORING SUMMARY ({MODEL_ID})\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTotal Interviews: {len(interviews_df)}\")\n",
        "print(f\"K Samples per Interview: {K}\")\n",
        "print(f\"Total Scoring Samples: {len(samples_df)}\")\n",
        "print(f\"Final Valid Outputs: {len(final_df)}\")\n",
        "print(f\"\\nScore Statistics:\")\n",
        "print(f\"  Overall Weighted Score: {final_df['overall_weighted_score'].mean():.2f} ± {final_df['overall_weighted_score'].std():.2f}\")\n",
        "print(f\"\\nMetric Averages:\")\n",
        "for m in METRICS:\n",
        "    col = f\"{m}_score_agg\"\n",
        "    if col in aggregated_df.columns:\n",
        "        print(f\"  {m.upper()}: {aggregated_df[col].mean():.2f}\")\n",
        "print(f\"\\nLatency Statistics:\")\n",
        "print(f\"  Scoring P95 Latency: {samples_df['latency_ms'].quantile(0.95):.0f}ms\")\n",
        "print(f\"  Rewrite P95 Latency: {final_df['rewrite_latency_ms'].quantile(0.95):.0f}ms\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "summary",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8276d31b-7e56-4b71-cd66-c146f809f36c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "SELF-CONSISTENCY SCORING SUMMARY (gpt-4o)\n",
            "============================================================\n",
            "\n",
            "Total Interviews: 50\n",
            "K Samples per Interview: 3\n",
            "Total Scoring Samples: 150\n",
            "Final Valid Outputs: 50\n",
            "\n",
            "Score Statistics:\n",
            "  Overall Weighted Score: 7.37 ± 0.93\n",
            "\n",
            "Metric Averages:\n",
            "  CA: 7.78\n",
            "  EXP: 7.10\n",
            "  PS: 7.24\n",
            "  REL: 7.42\n",
            "  PROF: 7.08\n",
            "  COMM: 7.10\n",
            "\n",
            "Latency Statistics:\n",
            "  Scoring P95 Latency: 3136ms\n",
            "  Rewrite P95 Latency: 16108ms\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 60)\n",
        "print(f\"SELF-CONSISTENCY SCORING SUMMARY ({MODEL_ID})\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nTotal Interviews: {len(interviews_df)}\")\n",
        "print(f\"K Samples per Interview: {K}\")\n",
        "print(f\"Total Scoring Samples: {len(samples_df)}\")\n",
        "print(f\"Final Valid Outputs: {len(final_df)}\")\n",
        "print(f\"\\nScore Statistics:\")\n",
        "print(f\"  Overall Weighted Score: {final_df['overall_weighted_score'].mean():.2f} ± {final_df['overall_weighted_score'].std():.2f}\")\n",
        "print(f\"\\nMetric Averages:\")\n",
        "for m in METRICS:\n",
        "    col = f\"{m}_score_agg\"\n",
        "    if col in aggregated_df.columns:\n",
        "        print(f\"  {m.upper()}: {aggregated_df[col].mean():.2f}\")\n",
        "print(f\"\\nLatency Statistics:\")\n",
        "print(f\"  Scoring P95 Latency: {samples_df['latency_ms'].quantile(0.95):.0f}ms\")\n",
        "print(f\"  Rewrite P95 Latency: {final_df['rewrite_latency_ms'].quantile(0.95):.0f}ms\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSd3vLpMFrQm",
        "outputId": "1b370cd6-2d49-438d-bf13-3cc2539b9e03"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "SELF-CONSISTENCY SCORING SUMMARY (gpt-3.5-turbo)\n",
            "============================================================\n",
            "\n",
            "Total Interviews: 50\n",
            "K Samples per Interview: 3\n",
            "Total Scoring Samples: 150\n",
            "Final Valid Outputs: 50\n",
            "\n",
            "Score Statistics:\n",
            "  Overall Weighted Score: 7.25 ± 0.00\n",
            "\n",
            "Metric Averages:\n",
            "  CA: 8.00\n",
            "  EXP: 7.00\n",
            "  PS: 7.00\n",
            "  REL: 7.00\n",
            "  PROF: 6.00\n",
            "  COMM: 6.00\n",
            "\n",
            "Latency Statistics:\n",
            "  Scoring P95 Latency: 1516ms\n",
            "  Rewrite P95 Latency: 7224ms\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gQcZl3ybIteA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}