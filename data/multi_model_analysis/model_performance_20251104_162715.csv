model,mean_score,std_score,avg_icc_human,avg_agree_human,median_latency_ms,est_cost_50_candidates,quality_score,cost_score,speed_score,overall_score
GPT-4o,7.286666666666667,0.9080137052318588,0.01613305784962254,39.833333333333336,7926.5,825.0,1.613305784962254,0.012121065199209708,1.26000126000126,1.062289464041142
GPT-3.5-turbo,6.833333333333333,0.6871842709362768,2.0141117161300373e-16,49.33333333333333,3908.0,142.5,2.0141117161300372e-14,0.07017051434987018,2.5523226135783568,0.5315156770206425
Llama-3.1-8B,7.850340136054422,0.8152771032328601,0.031133191514320542,27.38095238095238,7649.0,24.0,3.113319151432054,0.4164931278633902,1.3056534795665231,1.9427382099883488
