{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "303f8dfb18894241954e0d0d83d933bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_f61ae69eb3864aed8968592e185f79cc"
          }
        },
        "5d956f34a73245c4aac18c29bb2c64b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9823a7782ea420a809c248510d99968",
            "placeholder": "​",
            "style": "IPY_MODEL_331ba6eb35604717ae313058db7b91a4",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "3c0b73eb71fb4730a9530ac4812b3c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e57a520ed1504a10a56230c6a29ae802",
            "placeholder": "​",
            "style": "IPY_MODEL_d4491c7f722b4bc59c0199c8fd554a84",
            "value": ""
          }
        },
        "65436fddcf5841709047e548ad48b7d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_cc5fb6dd4d9e4ef6bf72642faad53a0c",
            "style": "IPY_MODEL_0e5ab8ffe26341ef94540986eea2179e",
            "value": true
          }
        },
        "16548a1071a945ee9cec1b43c0500e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9794d17c5aac4c288e85f28e18a94038",
            "style": "IPY_MODEL_e89cec80a3b24e7983cde629aac124ef",
            "tooltip": ""
          }
        },
        "306f28dd6df24d3b8bc292c0694151c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f89eb1fc4c54fe8a4e2d80386251e1c",
            "placeholder": "​",
            "style": "IPY_MODEL_48a861636e114dddbd27eaaab396a3ef",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "f61ae69eb3864aed8968592e185f79cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "b9823a7782ea420a809c248510d99968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "331ba6eb35604717ae313058db7b91a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e57a520ed1504a10a56230c6a29ae802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4491c7f722b4bc59c0199c8fd554a84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc5fb6dd4d9e4ef6bf72642faad53a0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e5ab8ffe26341ef94540986eea2179e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9794d17c5aac4c288e85f28e18a94038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e89cec80a3b24e7983cde629aac124ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "7f89eb1fc4c54fe8a4e2d80386251e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48a861636e114dddbd27eaaab396a3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a190f9dec3a4c4dac15b90f00ca2022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27952e6085b245b9b031227d94f31a4a",
            "placeholder": "​",
            "style": "IPY_MODEL_1d9fa3c2c4364be5b1a90a48cc6d0722",
            "value": "Connecting..."
          }
        },
        "27952e6085b245b9b031227d94f31a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d9fa3c2c4364be5b1a90a48cc6d0722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Self-Consistency Prompting Algorithm"
      ],
      "metadata": {
        "id": "HSqQPKu5BhdF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Install + Auth\n",
        "\n",
        "* Config (edit these)\n",
        "\n",
        "* Imports, Weights, Small Helpers\n",
        "\n",
        "* Prompt Builders\n",
        "\n",
        "* HF Client + Retry Wrapper\n",
        "\n",
        "* Generate Synthetic Interviews\n",
        "\n",
        "* K Scoring Runs (Self-Consistency @ 0.7)\n",
        "\n",
        "* Aggregate Medians + IQR Confidence + Overall Weighted\n",
        "\n",
        "* Deterministic Rewrite (Locked Scores @ 0.0)\n",
        "\n",
        "* Save CSVs (Workspace or Drive)"
      ],
      "metadata": {
        "id": "58ie5UCmCKu2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install + Auth\n",
        "**Purpose**: Install dependencies (`huggingface_hub`, `pandas`, `pyyaml`) and authenticate to Hugging Face so you can call hosted models.\n",
        "\n",
        "**Inputs**: None (you’ll paste your HF token when prompted).\n",
        "\n",
        "**Outputs**: Session-level auth; packages available for the rest of the notebook."
      ],
      "metadata": {
        "id": "7zC840ZaCeIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install huggingface_hub pandas pyyaml"
      ],
      "metadata": {
        "id": "oLbQ_vTSPB-Y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# If not already set in the environment, paste your HF token here\n",
        "if \"HF_TOKEN\" not in os.environ or not os.environ[\"HF_TOKEN\"]:\n",
        "    os.environ[\"HF_TOKEN\"] = getpass(\"Paste your Hugging Face token (starts with hf_...): \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3X72MYDGPxf",
        "outputId": "5c953ef0-a961-4197-9579-db5c11cb3f3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your Hugging Face token (starts with hf_...): ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-SjHkZRiNwQ-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yaml\n",
        "from huggingface_hub import login"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "303f8dfb18894241954e0d0d83d933bd",
            "5d956f34a73245c4aac18c29bb2c64b8",
            "3c0b73eb71fb4730a9530ac4812b3c53",
            "65436fddcf5841709047e548ad48b7d4",
            "16548a1071a945ee9cec1b43c0500e46",
            "306f28dd6df24d3b8bc292c0694151c3",
            "f61ae69eb3864aed8968592e185f79cc",
            "b9823a7782ea420a809c248510d99968",
            "331ba6eb35604717ae313058db7b91a4",
            "e57a520ed1504a10a56230c6a29ae802",
            "d4491c7f722b4bc59c0199c8fd554a84",
            "cc5fb6dd4d9e4ef6bf72642faad53a0c",
            "0e5ab8ffe26341ef94540986eea2179e",
            "9794d17c5aac4c288e85f28e18a94038",
            "e89cec80a3b24e7983cde629aac124ef",
            "7f89eb1fc4c54fe8a4e2d80386251e1c",
            "48a861636e114dddbd27eaaab396a3ef",
            "0a190f9dec3a4c4dac15b90f00ca2022",
            "27952e6085b245b9b031227d94f31a4a",
            "1d9fa3c2c4364be5b1a90a48cc6d0722"
          ]
        },
        "id": "EeiRzzrGN3Em",
        "outputId": "64ec0462-e65c-43b6-8432-b4fc8b11737a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "303f8dfb18894241954e0d0d83d933bd"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration\n",
        "**Purpose**: Central place to set role, question set, dataset size (`N`), self-consistency samples (`K`), model IDs, and generation params.\n",
        "\n",
        "**Inputs**: You edit the `CONFIG` dict values.\n",
        "\n",
        "**Outputs**: `CONFIG` used by all later cells."
      ],
      "metadata": {
        "id": "uEkWFIEjCzUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    \"role_title\": \"Field Technician\",\n",
        "    \"question_set_id\": \"qs_v1\",\n",
        "    \"question_set\": [\n",
        "        \"Tell me about a time you handled an urgent service call. What steps did you take?\",\n",
        "        \"How do you plan your route and prioritize jobs when schedules change during the day?\",\n",
        "        \"Describe a tricky diagnostic you solved. What tools or methods did you use?\",\n",
        "        \"How do you keep customers calm when they are upset or stressed?\",\n",
        "        \"Walk me through your process for documenting work and updating tickets.\",\n",
        "        \"What does reliability at work mean to you, and how do you demonstrate it?\",\n",
        "        \"How do you stay safe on the job and follow site-specific rules?\",\n",
        "        \"How do you collaborate with teammates or escalate when blocked?\"\n",
        "    ],\n",
        "    \"num_candidates\": 50,          # bump later if needed\n",
        "    \"k_samples\": 3,                # self-consistency K\n",
        "    \"generation_temperature\": 0.8,\n",
        "    \"generation_max_tokens\": 1200,\n",
        "    \"timeout_s\": 60,\n",
        "    \"gen_prompt_version\": \"gen_v1\",\n",
        "    \"score_prompt_version\": \"score_v1\",\n",
        "    \"rewrite_prompt_version\": \"rewrite_v1\",\n",
        "}\n",
        "# Choose ONE routed chat model (provider suffix matters for billing/availability)\n",
        "# Examples:\n",
        "# MODEL_ID = \"meta-llama/Llama-3.1-8B-Instruct:novita\"\n",
        "# MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3:together\"\n",
        "# MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct:novita\"\n",
        "MODEL_ID = \"meta-llama/Llama-3.1-8B-Instruct:novita\"\n"
      ],
      "metadata": {
        "id": "0FzVMj56PJnZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports, Weights, Small Helpers\n",
        "**Purpose**: Define utility functions and constants used everywhere.\n",
        "\n",
        "**Includes**:\n",
        "\n",
        "* `WEIGHTS`, `METRICS`\n",
        "\n",
        "* `canonicalize_qa_text()` (cleans timestamps/fillers)\n",
        "\n",
        "* `clamp_int()`, `iqr_confidence()`\n",
        "\n",
        "* `compute_overall_weighted()`\n",
        "\n",
        "* `safe_json_parse()`\n",
        "\n",
        "**Outputs**: Helper functions in memory.\n"
      ],
      "metadata": {
        "id": "WRn0zvlPDJCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re, json, time, random, statistics as stats\n",
        "from typing import Dict, Any, List\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "WEIGHTS = {\"ca\":0.35,\"exp\":0.35,\"ps\":0.15,\"rel\":0.05,\"prof\":0.05,\"comm\":0.05}\n",
        "METRICS = [\"ca\",\"exp\",\"ps\",\"rel\",\"prof\",\"comm\"]\n",
        "FILLERS_RE = re.compile(r\"\\b(?:um+|uh+|erm|like|you know|sort of|kinda|i mean|ya know)\\b\", re.IGNORECASE)\n",
        "\n",
        "def clamp_int(x, lo=1, hi=10):\n",
        "    try:\n",
        "        xi = int(round(float(x)))\n",
        "    except Exception:\n",
        "        xi = 5\n",
        "    return max(lo, min(hi, xi))\n",
        "\n",
        "def canonicalize_qa_text(text: str) -> str:\n",
        "    if not isinstance(text, str): return \"\"\n",
        "    t = text\n",
        "    t = re.sub(r\"\\[\\d{1,2}:\\d{2}(?::\\d{2})?\\]\", \" \", t)\n",
        "    t = re.sub(r\"\\(\\d{1,2}:\\d{2}(?::\\d{2})?\\)\", \" \", t)\n",
        "    t = re.sub(r\"(?m)^\\s*\\d{1,2}:\\d{2}(?::\\d{2})?\\s+\", \" \", t)\n",
        "    t = FILLERS_RE.sub(\"\", t)\n",
        "    t = re.sub(r\"[ \\t]+\", \" \", t)\n",
        "    t = re.sub(r\"\\n{3,}\", \"\\n\\n\", t)\n",
        "    return t.strip()\n",
        "\n",
        "def iqr_confidence(vals: List[float], max_iqr: float = 4.0) -> float:\n",
        "    if not vals: return 0.0\n",
        "    q1, q3 = np.percentile(vals, [25, 75])\n",
        "    iqr = float(q3 - q1)\n",
        "    return round(1.0 - min(iqr / max_iqr, 1.0), 3)\n",
        "\n",
        "def compute_overall_weighted(scores: Dict[str,int]) -> float:\n",
        "    return round(sum(WEIGHTS[m]*clamp_int(scores[m]) for m in METRICS), 3)\n",
        "\n",
        "def safe_json_parse(text: str) -> Dict[str, Any]:\n",
        "    try:\n",
        "        return json.loads(text)\n",
        "    except Exception:\n",
        "        try:\n",
        "            start = text.index(\"{\"); end = text.rindex(\"}\") + 1\n",
        "            return json.loads(text[start:end])\n",
        "        except Exception:\n",
        "            return {}\n"
      ],
      "metadata": {
        "id": "gmZa7nqHP97d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import whoami, HfApi\n",
        "print(whoami())  # Which account is the token tied to?\n",
        "\n",
        "api = HfApi()\n",
        "info = api.model_info(\"meta-llama/Llama-3.2-3B-Instruct\", use_auth_token=True)\n",
        "print(info.id, \"gated:\", info.gated)  # Will raise if you don't have access\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hml4JKIVLveD",
        "outputId": "6e9725a5-e87d-4eec-dabd-393c92ce4e3d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'type': 'user', 'id': '68f018da27c30b98c620061c', 'name': 'serviceagent', 'fullname': 'ServiceAgent', 'canPay': True, 'periodEnd': 1761955199, 'isPro': True, 'avatarUrl': '/avatars/c1d1a0eb60867c137fe668fb925748f7.svg', 'orgs': [], 'auth': {'type': 'access_token', 'accessToken': {'displayName': 'ensemble', 'role': 'fineGrained', 'createdAt': '2025-10-18T20:52:33.027Z', 'fineGrained': {'canReadGatedRepos': True, 'global': ['discussion.write', 'post.write'], 'scoped': [{'entity': {'_id': '66eaf084b3b3239188f66fa7', 'type': 'model', 'name': 'meta-llama/Llama-3.2-3B'}, 'permissions': ['repo.content.read', 'discussion.write', 'repo.write']}, {'entity': {'_id': '68f018da27c30b98c620061c', 'type': 'user', 'name': 'serviceagent'}, 'permissions': ['repo.content.read', 'repo.write', 'inference.serverless.write', 'inference.endpoints.infer.write', 'inference.endpoints.write', 'user.webhooks.read', 'user.webhooks.write', 'collection.read', 'collection.write', 'discussion.write', 'user.billing.read', 'job.write']}]}}}}\n",
            "meta-llama/Llama-3.2-3B-Instruct gated: manual\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Builders\n",
        "\n",
        "**Purpose**: Create plain-string prompts for three stages without messy nested triple quotes.\n",
        "\n",
        "**Functions**:\n",
        "\n",
        "- `build_generation_prompt`(role, question_set, persona)\n",
        "\n",
        "- `build_scoring_prompt`(qa_text) → returns JSON-only instruction (6 ints)\n",
        "\n",
        "- `build_rewrite_prompt_locked`(qa_text, scores) → locks numeric scores; asks for justifications, 3 strengths, 3 weaknesses, 3–4 sentence summary\n",
        "\n",
        "**Outputs**: Prompt strings on demand.\n"
      ],
      "metadata": {
        "id": "zGeQH05wDlbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Any, List\n",
        "\n",
        "def build_generation_prompt(role: str, question_set: List[str], persona: Dict[str, Any]) -> str:\n",
        "    q_block = \"\\n\".join([f\"Question {i+1}: {q}\" for i, q in enumerate(question_set)])\n",
        "    lines = [\n",
        "        f\"You are the candidate interviewing for the role: {role}.\",\n",
        "        f\"Persona hints: title={persona['persona_title']}; years_experience={persona['yrs_experience']}; \"\n",
        "        f\"keywords={persona['domain_keywords']}; reliability={persona['reliability_flags']}; notes={persona['notes']}.\",\n",
        "        \"\",\n",
        "        \"Answer each question clearly (2–4 sentences per answer).\",\n",
        "        \"\",\n",
        "        q_block,\n",
        "        \"\",\n",
        "        \"Return responses in this pattern:\",\n",
        "        \"Question 1: <repeat question>\",\n",
        "        \"Answer: <answer>\",\n",
        "        \"\",\n",
        "        \"Question 2: <repeat question>\",\n",
        "        \"Answer: <answer>\",\n",
        "    ]\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def build_scoring_prompt(qa_text: str) -> str:\n",
        "    metrics_def = \"\\n\".join([\n",
        "        \"- Cognitive Ability (35%): Structured thinking, planning, logic.\",\n",
        "        \"- Experience (35%): Relevant work (last 10 years), skills, accomplishments in similar service jobs.\",\n",
        "        \"- Problem Solving (15%): Resourcefulness, safe tradeoffs under constraints.\",\n",
        "        \"- Reliability (5%): Punctuality, follow-through, transport reliability.\",\n",
        "        \"- Professionalism (5%): Respect for clients/rules, composure under stress.\",\n",
        "        \"- Communication (5%): Clarity and tone; IGNORE filler words.\",\n",
        "    ])\n",
        "    # Keep INTERNAL keys the same so downstream stays unchanged.\n",
        "    lines = [\n",
        "        \"Analyze the candidate responses using the six metrics below.\",\n",
        "        \"Return ONLY a JSON object with keys: ca, exp, ps, rel, prof, comm (each 1–10).\",\n",
        "        \"\",\n",
        "        \"Definitions (approximate weighting):\",\n",
        "        metrics_def,\n",
        "        \"\",\n",
        "        \"Candidate Responses:\",\n",
        "        \"--- START RESPONSES ---\",\n",
        "        qa_text,\n",
        "        \"--- END RESPONSES ---\",\n",
        "        \"\",\n",
        "        'Output example: {\"ca\":8,\"exp\":7,\"ps\":7,\"rel\":7,\"prof\":6,\"comm\":6}',\n",
        "    ]\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "\n",
        "def build_rewrite_prompt_locked(qa_text: str, s: Dict[str,int]) -> str:\n",
        "    lines = [\n",
        "        \"Use FIXED scores; DO NOT change them. Generate justifications + bullets + summary.\",\n",
        "        \"\",\n",
        "        f\"- Cognitive Ability: {s['ca']}\",\n",
        "        f\"- Experience: {s['exp']}\",\n",
        "        f\"- Problem Solving: {s['ps']}\",\n",
        "        f\"- Reliability: {s['rel']}\",\n",
        "        f\"- Professionalism: {s['prof']}\",\n",
        "        f\"- Communication: {s['comm']}\",\n",
        "        \"\",\n",
        "        \"Return ONLY this JSON:\",\n",
        "        \"{\",\n",
        "        f'  \"cognitive_ability_score\": {s[\"ca\"]},',\n",
        "        '  \"cognitive_ability_justification\": \"...\",',\n",
        "        f'  \"experience_score\": {s[\"exp\"]},',\n",
        "        '  \"experience_justification\": \"...\",',\n",
        "        f'  \"reliability_score\": {s[\"rel\"]},',\n",
        "        '  \"reliability_justification\": \"...\",',\n",
        "        f'  \"professionalism_score\": {s[\"prof\"]},',\n",
        "        '  \"professionalism_justification\": \"...\",',\n",
        "        f'  \"problem_solving_score\": {s[\"ps\"]},',\n",
        "        '  \"problem_solving_justification\": \"...\",',\n",
        "        f'  \"communication_score\": {s[\"comm\"]},',\n",
        "        '  \"communication_justification\": \"...\",',\n",
        "        '  \"general_strengths\": \"- ...\\\\n- ...\\\\n- ...\",',\n",
        "        '  \"general_weaknesses\": \"- ...\\\\n- ...\\\\n- ...\",',\n",
        "        '  \"general_summary\": \"...\"',\n",
        "        \"}\",\n",
        "        \"\",\n",
        "        \"Candidate Responses:\",\n",
        "        \"--- START ---\",\n",
        "        qa_text,\n",
        "        \"--- END ---\",\n",
        "    ]\n",
        "    return \"\\n\".join(lines)\n"
      ],
      "metadata": {
        "id": "Xv-a1TzJQJE0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HF Client + Retry Wrapper"
      ],
      "metadata": {
        "id": "xkwPr-14D6qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "from huggingface_hub.utils import HfHubHTTPError\n",
        "import time\n",
        "\n",
        "def get_client(timeout_s: int = 60) -> InferenceClient:\n",
        "    # Neutral client; router picks a backend. We pass model_id per call.\n",
        "    return InferenceClient(timeout=timeout_s)\n",
        "\n",
        "def call_text_generation(client: InferenceClient, prompt: str,\n",
        "                         temperature=0.7, top_p=1.0, max_tokens=1024,\n",
        "                         model_id: str = None, retries: int = 1, backoff: float = 1.5):\n",
        "    assert model_id, \"model_id is required\"\n",
        "    last_err = None\n",
        "\n",
        "    def _go(c):\n",
        "        return c.text_generation(\n",
        "            prompt,\n",
        "            model=model_id,                 # <-- pass model here\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            max_new_tokens=max_tokens,\n",
        "            return_full_text=False,\n",
        "        )\n",
        "\n",
        "    for i in range(retries + 1):\n",
        "        try:\n",
        "            return _go(client)\n",
        "        except (ValueError, HfHubHTTPError) as e:\n",
        "            last_err = e\n",
        "            # retry once with a fresh neutral client (router may pick a different backend)\n",
        "            time.sleep(backoff * (i + 1))\n",
        "            client = InferenceClient(timeout=client.timeout)\n",
        "    raise last_err\n"
      ],
      "metadata": {
        "id": "G9ajkS8ERtrc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "hf_client = OpenAI(\n",
        "    base_url=\"https://router.huggingface.co/v1\",\n",
        "    api_key=os.environ[\"HF_TOKEN\"],\n",
        ")\n",
        "\n",
        "def hf_chat_once(prompt: str, model: str, temperature: float = 0.7, max_tokens: int = 512,\n",
        "                 json_mode: bool = False) -> str:\n",
        "    kwargs = dict(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "        top_p=1.0,\n",
        "    )\n",
        "    if json_mode:\n",
        "        # Enforce valid JSON responses when the provider supports this\n",
        "        kwargs[\"response_format\"] = {\"type\": \"json_object\"}\n",
        "    resp = hf_client.chat.completions.create(**kwargs)\n",
        "    return resp.choices[0].message.content\n",
        "\n",
        "def hf_chat_json(prompt: str, model: str, temperature: float, max_tokens: int = 512) -> tuple[dict, str]:\n",
        "    \"\"\"\n",
        "    Ask for JSON mode; if provider ignores it, fall back to brace-slice.\n",
        "    \"\"\"\n",
        "    txt = hf_chat_once(prompt, model=model, temperature=temperature, max_tokens=max_tokens, json_mode=True)\n",
        "    try:\n",
        "        return json.loads(txt), txt\n",
        "    except Exception:\n",
        "        try:\n",
        "            start = txt.index(\"{\"); end = txt.rindex(\"}\") + 1\n",
        "            return json.loads(txt[start:end]), txt\n",
        "        except Exception:\n",
        "            return {}, txt\n"
      ],
      "metadata": {
        "id": "nTNWUGNUhDxK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Synthetic Interviews\n",
        "\n"
      ],
      "metadata": {
        "id": "bhwNGlC0Dgv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(123)\n",
        "\n",
        "role = CONFIG[\"role_title\"]\n",
        "questions = CONFIG[\"question_set\"]\n",
        "N = CONFIG[\"num_candidates\"]\n",
        "\n",
        "interviews = []\n",
        "for i in range(N):\n",
        "    persona = {\n",
        "        \"candidate_id\": f\"cand_{i+1:04d}\",\n",
        "        \"persona_title\": random.choice([\"Veteran field tech\",\"Career switcher\",\"Recent grad\",\"Retail service rep\",\"HVAC junior\"]),\n",
        "        \"yrs_experience\": random.choice([0,1,2,3,5,7,10]),\n",
        "        \"domain_keywords\": random.choice([\n",
        "            \"preventive maintenance, HVAC, route planning\",\n",
        "            \"customer empathy, troubleshooting basics\",\n",
        "            \"inventory, parts ordering, safety protocols\",\n",
        "            \"ticket triage, escalation, SLA awareness\",\n",
        "        ]),\n",
        "        \"reliability_flags\": random.choice([\"has_car; weekend_ok\",\"public_transit\",\"night_shift_ok\"]),\n",
        "        \"notes\": random.choice([\"calm under pressure\",\"fast learner\",\"detail-oriented\"]),\n",
        "    }\n",
        "    prompt = build_generation_prompt(role, questions, persona)\n",
        "    out = hf_chat_once(prompt, model=MODEL_ID, temperature=CONFIG[\"generation_temperature\"], max_tokens=CONFIG[\"generation_max_tokens\"])\n",
        "    interviews.append({\n",
        "        \"interview_id\": f\"intv_{i+1:04d}\",\n",
        "        \"candidate_id\": persona[\"candidate_id\"],\n",
        "        \"role_title\": role,\n",
        "        \"question_set_id\": CONFIG[\"question_set_id\"],\n",
        "        \"num_questions\": len(questions),\n",
        "        \"qa_text\": canonicalize_qa_text(out),\n",
        "        \"source\": \"synthetic\",\n",
        "        \"gen_model\": MODEL_ID,\n",
        "        \"gen_prompt_version\": CONFIG[\"gen_prompt_version\"],\n",
        "        \"gen_temperature\": CONFIG[\"generation_temperature\"],\n",
        "        \"gen_top_p\": 1.0,\n",
        "        \"gen_seed\": 123,\n",
        "        \"created_at\": pd.Timestamp.utcnow().isoformat(),\n",
        "    })\n",
        "\n",
        "interviews_df = pd.DataFrame(interviews)\n",
        "display(interviews_df.head(2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "Smspz1V6RyTC",
        "outputId": "25ff8e02-cad5-4c09-b11a-0c5b883e7bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  interview_id candidate_id        role_title question_set_id  num_questions  \\\n",
              "0    intv_0001    cand_0001  Field Technician           qs_v1              8   \n",
              "1    intv_0002    cand_0002  Field Technician           qs_v1              8   \n",
              "\n",
              "                                             qa_text     source  \\\n",
              "0  Question 1: Tell me about a time you handled a...  synthetic   \n",
              "1  Question 1: Tell me about a time you handled a...  synthetic   \n",
              "\n",
              "                          gen_model gen_prompt_version  gen_temperature  \\\n",
              "0  meta-llama/Llama-3.2-3B-Instruct             gen_v1              0.8   \n",
              "1  meta-llama/Llama-3.2-3B-Instruct             gen_v1              0.8   \n",
              "\n",
              "   gen_top_p  gen_seed                        created_at  \n",
              "0        1.0       123  2025-10-09T23:35:59.950431+00:00  \n",
              "1        1.0       123  2025-10-09T23:36:06.946492+00:00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2ba49886-9b6e-43e6-b82d-8acd579be946\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>interview_id</th>\n",
              "      <th>candidate_id</th>\n",
              "      <th>role_title</th>\n",
              "      <th>question_set_id</th>\n",
              "      <th>num_questions</th>\n",
              "      <th>qa_text</th>\n",
              "      <th>source</th>\n",
              "      <th>gen_model</th>\n",
              "      <th>gen_prompt_version</th>\n",
              "      <th>gen_temperature</th>\n",
              "      <th>gen_top_p</th>\n",
              "      <th>gen_seed</th>\n",
              "      <th>created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>intv_0001</td>\n",
              "      <td>cand_0001</td>\n",
              "      <td>Field Technician</td>\n",
              "      <td>qs_v1</td>\n",
              "      <td>8</td>\n",
              "      <td>Question 1: Tell me about a time you handled a...</td>\n",
              "      <td>synthetic</td>\n",
              "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
              "      <td>gen_v1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>123</td>\n",
              "      <td>2025-10-09T23:35:59.950431+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>intv_0002</td>\n",
              "      <td>cand_0002</td>\n",
              "      <td>Field Technician</td>\n",
              "      <td>qs_v1</td>\n",
              "      <td>8</td>\n",
              "      <td>Question 1: Tell me about a time you handled a...</td>\n",
              "      <td>synthetic</td>\n",
              "      <td>meta-llama/Llama-3.2-3B-Instruct</td>\n",
              "      <td>gen_v1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>123</td>\n",
              "      <td>2025-10-09T23:36:06.946492+00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ba49886-9b6e-43e6-b82d-8acd579be946')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ba49886-9b6e-43e6-b82d-8acd579be946 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ba49886-9b6e-43e6-b82d-8acd579be946');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f0052717-4d4f-42a8-8007-b6e915819c93\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0052717-4d4f-42a8-8007-b6e915819c93')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f0052717-4d4f-42a8-8007-b6e915819c93 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(interviews_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"interview_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"intv_0002\",\n          \"intv_0001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"candidate_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"cand_0002\",\n          \"cand_0001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"role_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Field Technician\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_set_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"qs_v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_questions\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"qa_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Question 1: Tell me about a time you handled an urgent service call. What steps did you take?\\n\\nAnswer: I recall an instance where a customer reported a broken air conditioning unit in their home during a sweltering summer day. Upon arriving at the scene, I assessed the situation and determined that the issue was due to a faulty compressor. I quickly ordered replacement parts and completed the repair within a few hours, ensuring the customer's comfort and satisfaction. My attention to detail and ability to prioritize tasks under pressure helped me resolve the issue efficiently.\\n\\nQuestion 2: How do you plan your route and prioritize jobs when schedules change during the day?\\n\\nAnswer: As a seasoned field technician, I use a combination of route optimization software and my own experience to plan efficient routes and prioritize jobs. When schedules change, I adjust my route plan in real-time to minimize delays and ensure timely completion of all tasks. I also communicate proactively with my team and management to ensure we're aware of any changes and can adjust our schedule accordingly.\\n\\nQuestion 3: Describe a tricky diagnostic you solved. What tools or methods did you use?\\n\\nAnswer: One instance that stands out was when I had to diagnose a complex issue with a HVAC system that was experiencing frequent failures. I used a combination of multimeters, oscilloscopes, and thermal imaging cameras to troubleshoot the problem. After analyzing the data, I identified a faulty contactor that was causing the system to malfunction. I replaced the contactor and reconfigured the system, which resolved the issue and ensured the customer's heating and cooling system was functioning properly.\\n\\nQuestion 4: How do you keep customers calm when they are upset or stressed?\\n\\nAnswer: As a detail-oriented and patient field technician, I make it a point to listen attentively to customers' concerns and empathize with their frustration. I communicate clearly and concisely, explaining the steps I'll take to resolve the issue and provide a timeline for completion. By maintaining a calm and professional demeanor, I help to de-escalate the situation and ensure the customer feels heard and valued throughout the process.\\n\\nQuestion 5: Walk me through your process for documenting work and updating tickets.\\n\\nAnswer: When completing a service call, I follow a standardized process for documenting work and updating tickets. I make sure to note the issue, the steps taken to resolve it, and the results of any diagnostic tests. I also update the ticket with relevant data, such as parts used, labor hours, and any other relevant information. Finally, I review the documentation to ensure accuracy and complete any necessary follow-up actions to ensure a smooth handoff to the next technician or manager.\\n\\nQuestion 6: What does reliability at work mean to you, and how do you demonstrate it?\\n\\nAnswer: To me, reliability at work means being dependable, responsible, and consistent in one's actions. As a veteran field technician, I demonstrate reliability by showing up on time, following through on commitments, and taking ownership of my work. I also prioritize preventive maintenance and proactive troubleshooting, which helps to minimize downtime and ensure that our customers receive the highest level of service.\\n\\nQuestion 7: How do you stay safe on the job and follow site-specific rules?\\n\\nAnswer: As a seasoned field technician, I understand the importance of adhering to safety protocols and site-specific rules. I always wear personal protective equipment (PPE), such as gloves and safety glasses, and ensure that the area is clear of hazards before starting work. I also follow established procedures for handling hazardous materials, operating equipment, and using electrical tools. By prioritizing safety and following rules, I minimize the risk of injury and ensure a safe working environment for myself and others.\\n\\nQuestion 8: How do you collaborate with teammates or escalate when blocked?\\n\\nAnswer: When working with teammates or escalating issues, I prioritize clear communication and collaboration. I use standardized protocols and procedures to ensure that everyone is on the same page, and I provide regular updates on my progress and any challenges I'm facing. If I become blocked or encounter an issue that I'm unable to resolve, I escalate the issue to my supervisor or manager, providing them with all relevant details and information. By working together and communicating effectively, we can resolve issues efficiently and ensure the highest level of customer satisfaction.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"synthetic\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gen_model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"meta-llama/Llama-3.2-3B-Instruct\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gen_prompt_version\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"gen_v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gen_temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.8,\n        \"max\": 0.8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gen_top_p\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gen_seed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 123,\n        \"max\": 123,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          123\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"2025-10-09T23:36:06.946492+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interviews_df['qa_text'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "c-Hhi5KeR0qg",
        "outputId": "a637c87b-e4a4-4f9b-bc83-52a0bcbe5802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Question 1: Tell me about a time you handled an urgent service call. What steps did you take?\\n\\nAnswer: In my previous role, I handled an urgent service call on a public transit line during rush hour. The line was experiencing a major breakdown, and I had to assess the issue and provide a rapid solution to minimize disruptions. I took the initiative to inspect the system, diagnose the problem, and implement a temporary fix, ensuring the line could operate safely and efficiently. My priority was to restore service as quickly as possible while maintaining a high level of customer satisfaction.\\n\\nQuestion 2: How do you plan your route and prioritize jobs when schedules change during the day?\\n\\nAnswer: As a seasoned field technician, I use a combination of route optimization software and my own experience to plan efficient routes. I also rely on real-time data from the system to adjust my schedule and prioritize jobs based on urgency and location. This enables me to make the most of my time, minimize travel time, and provide timely service to our customers. Additionally, I'm able to adapt to changing schedules and make adjustments as needed, ensuring that I can deliver high-quality service to our customers.\\n\\nQuestion 3: Describe a tricky diagnostic you solved. What tools or methods did you use?\\n\\nAnswer: One particularly challenging diagnostic I solved involved a faulty HVAC unit with multiple symptoms, including unusual noises and reduced performance. To diagnose the issue, I used a combination of visual inspection, troubleshooting manuals, and advanced diagnostic tools, including thermal imaging and gas analyzers. I applied my knowledge of HVAC systems and troubleshooting techniques to identify the root cause of the problem, which turned out to be a faulty capacitor. By using a systematic approach and leveraging the right tools, I was able to resolve the issue efficiently and effectively.\\n\\nQuestion 4: How do you keep customers calm when they are upset or stressed?\\n\\nAnswer: As a field technician, I understand that dealing with frustrated customers can be challenging. To de-escalate situations, I listen attentively to their concerns, empathize with their frustrations, and provide clear explanations of the issue and resolution. I also make sure to keep them informed about the estimated time of arrival and provide regular updates on my progress. By maintaining a calm and professional demeanor, I'm able to reassure customers that I'm working to resolve the issue as quickly as possible.\\n\\nQuestion 5: Walk me through your process for documenting work and updating tickets.\\n\\nAnswer: My process for documenting work and updating tickets involves thoroughly documenting every step of the job, including the issue, diagnosis, and resolution. I use a standardized template to ensure that all necessary information is captured, including photos, notes, and specific details about the repair. I then update the ticket in a timely manner, ensuring that all stakeholders, including the customer and dispatch team, are informed of the status of the job. By maintaining accurate and concise records, I'm able to track my progress, identify areas for improvement, and provide quality service to our customers.\\n\\nQuestion 6: What does reliability at work mean to you, and how do you demonstrate it?\\n\\nAnswer: To me, reliability at work means being dependable, trustworthy, and committed to delivering high-quality results, even in challenging situations. I demonstrate reliability by being punctual, following through on commitments, and communicating effectively with customers and stakeholders. I also take ownership of my work, prioritize tasks effectively, and adapt to changing circumstances, ensuring that I can meet the needs of our customers in a timely and efficient manner.\\n\\nQuestion 7: How do you stay safe on the job and follow site-specific rules?\\n\\nAnswer: As a seasoned field technician, I prioritize my safety at all times, adhering to site-specific rules, regulations, and protocols. I conduct thorough risk assessments before entering a site, wear personal protective equipment (PPE) as required, and follow established procedures for handling hazardous materials or working at heights. I also stay alert and aware of my surroundings, reporting any concerns or hazards to my supervisor or dispatch team, ensuring a safe working environment for myself and others.\\n\\nQuestion 8: How do you collaborate with teammates or escalate when blocked?\\n\\nAnswer: I believe that effective communication and teamwork are essential to delivering high-quality service. When collaborating with teammates, I focus on clear and concise communication, ensuring that we're all on the same page and working towards a common goal. If I'm blocked or encounter a roadblock, I escalate the issue to my supervisor or dispatch team, providing them with accurate information and recommendations for resolving the issue. By working together, sharing knowledge and expertise, and escalating when necessary, I'm able to resolve complex issues efficiently and effectively.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interviews_df.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSA__M7vUr82",
        "outputId": "099b7508-f08c-4641-911b-1d4e73df5c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # follow the auth prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sqcHZL1WgXW",
        "outputId": "40feba6c-2b65-4f38-a6f8-10462833f73c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Choose a folder in your Drive\n",
        "save_dir = \"/content/drive/MyDrive/mvp\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
        "csv_path = f\"{save_dir}/synthInterviews{ts}.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpT0BFE2WuM9",
        "outputId": "cee989d8-7ba5-45bd-8e5c-56c55d190109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-606558349.py:8: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interviews_df.to_csv(csv_path, index=False)"
      ],
      "metadata": {
        "id": "CBTjZ-PbW_0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interviews_df = pd.read_csv('/content/drive/MyDrive/mvp/synthInterviews20251009-234435.csv')"
      ],
      "metadata": {
        "id": "UauXmlLTGinS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "m9d_GdxVGpmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K Scoring Runs (Self-Consistency @ 0.7)"
      ],
      "metadata": {
        "id": "EFD_ZcOEEJC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = CONFIG[\"k_samples\"]\n",
        "records = interviews_df[[\"interview_id\",\"qa_text\"]].to_dict(\"records\")\n",
        "\n",
        "samples = []\n",
        "for iv in records:\n",
        "    qa = iv[\"qa_text\"] or \"\"\n",
        "    sprompt = build_scoring_prompt(qa)\n",
        "    for k in range(K):\n",
        "        t0 = time.time()\n",
        "        js, raw = hf_chat_json(sprompt, model=MODEL_ID, temperature=0.7, max_tokens=256)\n",
        "        latency = int((time.time() - t0) * 1000)\n",
        "        row = {\n",
        "            \"interview_id\": iv[\"interview_id\"],\n",
        "            \"run_idx\": k,\n",
        "            \"model_name\": MODEL_ID,\n",
        "            \"prompt_version\": CONFIG[\"score_prompt_version\"],\n",
        "            \"temperature\": 0.7,\n",
        "            \"json_valid\": all(key in js for key in METRICS),\n",
        "            \"latency_ms\": latency,\n",
        "        }\n",
        "        for m in METRICS:\n",
        "            row[m] = clamp_int(js.get(m, 5))\n",
        "        samples.append(row)\n",
        "\n",
        "samples_df = pd.DataFrame(samples)\n",
        "display(samples_df.head(3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "kFMuYcNQXWVd",
        "outputId": "a273d061-d70c-4e23-a933-efd834529164"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Model mistralai/Mistral-7B-Instruct-v0.3 is not supported for task text-generation and provider together. Supported task: conversational.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1480353193.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         out = call_text_generation(\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mscore_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1781997630.py\u001b[0m in \u001b[0;36mcall_text_generation\u001b[0;34m(client, prompt, temperature, top_p, max_tokens, model_id, retries, backoff)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackoff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInferenceClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mlast_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1781997630.py\u001b[0m in \u001b[0;36mcall_text_generation\u001b[0;34m(client, prompt, temperature, top_p, max_tokens, model_id, retries, backoff)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretries\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_go\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mlast_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1781997630.py\u001b[0m in \u001b[0;36m_go\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_go\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         return c.text_generation(\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m                 \u001b[0;31m# <-- pass model here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/inference/_client.py\u001b[0m in \u001b[0;36mtext_generation\u001b[0;34m(self, prompt, details, stream, model, adapter_id, best_of, decoder_input_details, do_sample, frequency_penalty, grammar, max_new_tokens, repetition_penalty, return_full_text, seed, stop, stop_sequences, temperature, top_k, top_n_tokens, top_p, truncate, typical_p, watermark)\u001b[0m\n\u001b[1;32m   2370\u001b[0m         \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2371\u001b[0m         \u001b[0mprovider_helper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_provider_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovider\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-generation\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2372\u001b[0;31m         request_parameters = provider_helper.prepare_request(\n\u001b[0m\u001b[1;32m   2373\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2374\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/inference/_providers/_common.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, inputs, parameters, headers, model, api_key, extra_payload)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;31m# mapped model from HF model ID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mprovider_mapping_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_mapping_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;31m# default HF headers + user headers (to customize in subclasses)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/huggingface_hub/inference/_providers/_common.py\u001b[0m in \u001b[0;36m_prepare_mapping_info\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprovider_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;34mf\"Model {model} is not supported for task {self.task} and provider {self.provider}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;34mf\"Supported task: {provider_mapping.task}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Model mistralai/Mistral-7B-Instruct-v0.3 is not supported for task text-generation and provider together. Supported task: conversational."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Choose a folder in your Drive\n",
        "save_dir = \"/content/drive/MyDrive/mvp\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
        "csv_path = f\"{save_dir}/scoringdf{ts}.csv\""
      ],
      "metadata": {
        "id": "DnrgqtZ0YGCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4353ecfc-7dc6-4fdd-d71a-c2a1b8686cfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1272544642.py:8: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "samples_df.to_csv(csv_path, index=False)"
      ],
      "metadata": {
        "id": "DZ9OtIdQN6H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregate Medians"
      ],
      "metadata": {
        "id": "yYZHc8vQBBdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aggs = []\n",
        "for intv_id, g in samples_df.groupby(\"interview_id\"):\n",
        "    row = {\"interview_id\": intv_id}\n",
        "    latencies = g[\"latency_ms\"].tolist()\n",
        "    for m in METRICS:\n",
        "        vals = [int(v) for v in g[m].tolist()]\n",
        "        row[f\"{m}_score_agg\"] = clamp_int(stats.median(vals))\n",
        "        row[f\"{m}_confidence\"] = iqr_confidence(vals)\n",
        "    row[\"overall_weighted_agg\"] = compute_overall_weighted({m:row[f\"{m}_score_agg\"] for m in METRICS})\n",
        "    row[\"p95_latency_ms\"] = float(np.percentile(latencies, 95)) if latencies else 0.0\n",
        "    row[\"k_samples\"] = K\n",
        "    aggs.append(row)\n",
        "\n",
        "aggregated_df = pd.DataFrame(aggs)\n",
        "display(aggregated_df.head(3))\n"
      ],
      "metadata": {
        "id": "HqQ8eJKDX9Jq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "06617ac8-b621-4ff5-e7af-67213169ce0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  interview_id  ca_score_agg  ca_confidence  exp_score_agg  exp_confidence  \\\n",
              "0    intv_0001             9          1.000              8           1.000   \n",
              "1    intv_0002             9          0.875              8           0.875   \n",
              "2    intv_0003             9          1.000              8           0.875   \n",
              "\n",
              "   ps_score_agg  ps_confidence  rel_score_agg  rel_confidence  prof_score_agg  \\\n",
              "0             8          1.000              9           0.625               8   \n",
              "1             8          0.875              9           0.750               8   \n",
              "2             8          0.750              9           0.875               9   \n",
              "\n",
              "   prof_confidence  comm_score_agg  comm_confidence  overall_weighted_agg  \\\n",
              "0            0.875               9            0.875                  8.45   \n",
              "1            0.750               9            0.625                  8.45   \n",
              "2            0.875               8            0.500                  8.45   \n",
              "\n",
              "   p95_latency_ms  k_samples  \n",
              "0          1097.0          3  \n",
              "1          1181.0          3  \n",
              "2          1094.3          3  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ac64ec1-dffe-4df4-a389-433a2a5c08f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>interview_id</th>\n",
              "      <th>ca_score_agg</th>\n",
              "      <th>ca_confidence</th>\n",
              "      <th>exp_score_agg</th>\n",
              "      <th>exp_confidence</th>\n",
              "      <th>ps_score_agg</th>\n",
              "      <th>ps_confidence</th>\n",
              "      <th>rel_score_agg</th>\n",
              "      <th>rel_confidence</th>\n",
              "      <th>prof_score_agg</th>\n",
              "      <th>prof_confidence</th>\n",
              "      <th>comm_score_agg</th>\n",
              "      <th>comm_confidence</th>\n",
              "      <th>overall_weighted_agg</th>\n",
              "      <th>p95_latency_ms</th>\n",
              "      <th>k_samples</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>intv_0001</td>\n",
              "      <td>9</td>\n",
              "      <td>1.000</td>\n",
              "      <td>8</td>\n",
              "      <td>1.000</td>\n",
              "      <td>8</td>\n",
              "      <td>1.000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.625</td>\n",
              "      <td>8</td>\n",
              "      <td>0.875</td>\n",
              "      <td>9</td>\n",
              "      <td>0.875</td>\n",
              "      <td>8.45</td>\n",
              "      <td>1097.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>intv_0002</td>\n",
              "      <td>9</td>\n",
              "      <td>0.875</td>\n",
              "      <td>8</td>\n",
              "      <td>0.875</td>\n",
              "      <td>8</td>\n",
              "      <td>0.875</td>\n",
              "      <td>9</td>\n",
              "      <td>0.750</td>\n",
              "      <td>8</td>\n",
              "      <td>0.750</td>\n",
              "      <td>9</td>\n",
              "      <td>0.625</td>\n",
              "      <td>8.45</td>\n",
              "      <td>1181.0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intv_0003</td>\n",
              "      <td>9</td>\n",
              "      <td>1.000</td>\n",
              "      <td>8</td>\n",
              "      <td>0.875</td>\n",
              "      <td>8</td>\n",
              "      <td>0.750</td>\n",
              "      <td>9</td>\n",
              "      <td>0.875</td>\n",
              "      <td>9</td>\n",
              "      <td>0.875</td>\n",
              "      <td>8</td>\n",
              "      <td>0.500</td>\n",
              "      <td>8.45</td>\n",
              "      <td>1094.3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ac64ec1-dffe-4df4-a389-433a2a5c08f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ac64ec1-dffe-4df4-a389-433a2a5c08f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ac64ec1-dffe-4df4-a389-433a2a5c08f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-99e05213-69f0-426a-8ddf-fb76a5667f30\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99e05213-69f0-426a-8ddf-fb76a5667f30')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-99e05213-69f0-426a-8ddf-fb76a5667f30 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(aggregated_df\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"interview_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"intv_0001\",\n          \"intv_0002\",\n          \"intv_0003\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 9,\n        \"max\": 9,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca_confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07216878364870323,\n        \"min\": 0.875,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exp_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exp_confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07216878364870323,\n        \"min\": 0.875,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ps_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ps_confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.125,\n        \"min\": 0.75,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rel_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 9,\n        \"max\": 9,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rel_confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.125,\n        \"min\": 0.625,\n        \"max\": 0.875,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prof_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 9,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prof_confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07216878364870323,\n        \"min\": 0.75,\n        \"max\": 0.875,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comm_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 9,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comm_confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19094065395649332,\n        \"min\": 0.5,\n        \"max\": 0.875,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overall_weighted_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 8.45,\n        \"max\": 8.45,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8.45\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p95_latency_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.29533446483553,\n        \"min\": 1094.3,\n        \"max\": 1181.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1097.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"k_samples\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 3,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Choose a folder in your Drive\n",
        "save_dir = \"/content/drive/MyDrive/mvp\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
        "csv_path = f\"{save_dir}/aggScores{ts}.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daJrzMplOB1Y",
        "outputId": "ed69129e-922c-4865-86c7-398f2d65bc6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2656075673.py:8: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated_df.to_csv(csv_path, index=False)"
      ],
      "metadata": {
        "id": "y58qrWU1OGCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aggregated_df = pd.read_csv('/content/drive/MyDrive/mvp/aggScores20251018-212723.csv')"
      ],
      "metadata": {
        "id": "q1JRrv4_90v4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_df = pd.read_csv('/content/drive/MyDrive/mvp/scoringdf20251018-212633.csv')"
      ],
      "metadata": {
        "id": "GULHpW0-9037"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Deterministic Rewrite"
      ],
      "metadata": {
        "id": "7aHf2erJBPfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure qa_map resolves and no NaNs\n",
        "assert \"interview_id\" in interviews_df.columns and \"qa_text\" in interviews_df.columns\n",
        "assert aggregated_df[\"interview_id\"].isin(interviews_df[\"interview_id\"]).all(), \"Mismatched IDs\"\n",
        "assert interviews_df[\"qa_text\"].notna().all(), \"Some qa_text are NaN\"\n"
      ],
      "metadata": {
        "id": "mNJK35Ph9SFS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1TPlukx0CdD6"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_map = dict(zip(interviews_df[\"interview_id\"], interviews_df[\"qa_text\"]))\n",
        "\n",
        "def rewrite_once_chat(qa_text: str, scores_locked: Dict[str,int], model: str,\n",
        "                      max_tokens: int = 1200) -> tuple[dict, str]:\n",
        "    prompt = (\n",
        "        \"Respond with exactly ONE JSON object, no code fences, no prose, no markdown. \"\n",
        "        \"Do not include any keys that are not requested.\\n\\n\"\n",
        "        + build_rewrite_prompt_locked(qa_text, scores_locked)\n",
        "    )\n",
        "    # temp=0.0 for deterministic wording; big max_tokens to avoid truncation\n",
        "    return hf_chat_json(prompt, model=model, temperature=0.0, max_tokens=max_tokens)\n",
        "\n",
        "def rewrite_with_retry_chat(qa_text: str, scores_locked: Dict[str,int], model: str, retries: int = 2):\n",
        "    needed = [\n",
        "        \"cognitive_ability_justification\", \"experience_justification\",\n",
        "        \"problem_solving_justification\", \"reliability_justification\",\n",
        "        \"professionalism_justification\", \"communication_justification\",\n",
        "        \"general_strengths\", \"general_weaknesses\", \"general_summary\"\n",
        "    ]\n",
        "    last_raw = \"\"\n",
        "    for _ in range(retries + 1):\n",
        "        js, raw = rewrite_once_chat(qa_text, scores_locked, model=model, max_tokens=1200)\n",
        "        last_raw = raw\n",
        "        if js and all(k in js for k in needed):\n",
        "            return js, raw\n",
        "    return {}, last_raw\n",
        "\n",
        "final_rows, bad = [], []\n",
        "for _, r in aggregated_df.iterrows():\n",
        "    intv_id = r[\"interview_id\"]\n",
        "    qa_text = (qa_map.get(intv_id) or \"\").strip()\n",
        "    if not qa_text:\n",
        "        bad.append({\"interview_id\": intv_id, \"reason\": \"empty qa_text\"}); continue\n",
        "\n",
        "    scores_locked = {m: int(r[f\"{m}_score_agg\"]) for m in METRICS}\n",
        "\n",
        "    t0 = time.time()\n",
        "    js, raw = rewrite_with_retry_chat(qa_text, scores_locked, model=MODEL_ID, retries=2)\n",
        "    latency = int((time.time() - t0) * 1000)\n",
        "\n",
        "    if not js:\n",
        "        bad.append({\"interview_id\": intv_id, \"reason\": \"invalid JSON\", \"raw\": (raw or \"\")[:600]})\n",
        "        continue\n",
        "\n",
        "    final_rows.append({\n",
        "        \"interview_id\": intv_id,\n",
        "        \"cognitive_ability_score\": scores_locked[\"ca\"],\n",
        "        \"experience_score\": scores_locked[\"exp\"],\n",
        "        \"problem_solving_score\": scores_locked[\"ps\"],\n",
        "        \"reliability_score\": scores_locked[\"rel\"],\n",
        "        \"professionalism_score\": scores_locked[\"prof\"],\n",
        "        \"communication_score\": scores_locked[\"comm\"],\n",
        "        \"cognitive_ability_justification\": js.get(\"cognitive_ability_justification\",\"\"),\n",
        "        \"experience_justification\": js.get(\"experience_justification\",\"\"),\n",
        "        \"problem_solving_justification\": js.get(\"problem_solving_justification\",\"\"),\n",
        "        \"reliability_justification\": js.get(\"reliability_justification\",\"\"),\n",
        "        \"professionalism_justification\": js.get(\"professionalism_justification\",\"\"),\n",
        "        \"communication_justification\": js.get(\"communication_justification\",\"\"),\n",
        "        \"general_strengths\": js.get(\"general_strengths\",\"\"),\n",
        "        \"general_weaknesses\": js.get(\"general_weaknesses\",\"\"),\n",
        "        \"general_summary\": js.get(\"general_summary\",\"\"),\n",
        "        \"final_model_name\": MODEL_ID,\n",
        "        \"final_prompt_version\": CONFIG[\"rewrite_prompt_version\"],\n",
        "        \"final_temperature\": 0.0,\n",
        "        \"final_latency_ms\": latency,\n",
        "        \"created_at\": pd.Timestamp.utcnow().isoformat(),\n",
        "    })\n",
        "\n",
        "final_df = pd.DataFrame(final_rows)\n",
        "display(final_df.head(3))\n",
        "print(f\"Final rows: {len(final_df)} | Invalid rewrites: {len(bad)}\")\n",
        "if bad[:1]:\n",
        "    print(\"\\nExample invalid:\", bad[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "p1mfT0N3-OXM",
        "outputId": "b0b613ce-8525-4a5f-e55c-c8701ca5f4d0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  interview_id  cognitive_ability_score  experience_score  \\\n",
              "0    intv_0001                        9                 8   \n",
              "1    intv_0002                        9                 8   \n",
              "2    intv_0003                        9                 8   \n",
              "\n",
              "   problem_solving_score  reliability_score  professionalism_score  \\\n",
              "0                      8                  9                      8   \n",
              "1                      8                  9                      8   \n",
              "2                      8                  9                      9   \n",
              "\n",
              "   communication_score                    cognitive_ability_justification  \\\n",
              "0                    9  The candidate demonstrated exceptional cogniti...   \n",
              "1                    9  The candidate demonstrated exceptional cogniti...   \n",
              "2                    8  The candidate demonstrates strong cognitive ab...   \n",
              "\n",
              "                            experience_justification  \\\n",
              "0  The candidate has significant experience in th...   \n",
              "1  The candidate has extensive experience in the ...   \n",
              "2  The candidate has relevant experience in the f...   \n",
              "\n",
              "                       problem_solving_justification  ...  \\\n",
              "0  The candidate demonstrated effective problem-s...  ...   \n",
              "1  The candidate demonstrated strong problem-solv...  ...   \n",
              "2  The candidate demonstrates strong problem-solv...  ...   \n",
              "\n",
              "                       professionalism_justification  \\\n",
              "0  The candidate consistently demonstrated a prof...   \n",
              "1  The candidate consistently displayed a profess...   \n",
              "2  The candidate consistently demonstrates profes...   \n",
              "\n",
              "                         communication_justification  \\\n",
              "0  The candidate was an effective communicator, u...   \n",
              "1  The candidate consistently demonstrated excell...   \n",
              "2  The candidate demonstrates effective communica...   \n",
              "\n",
              "                                   general_strengths  \\\n",
              "0  - Exceptional cognitive abilities, with the ab...   \n",
              "1  - Strong critical thinking and problem-solving...   \n",
              "2  - Strong problem-solving skills - Effective co...   \n",
              "\n",
              "                                  general_weaknesses  \\\n",
              "0  - Limited information provided about their abi...   \n",
              "1  - Could benefit from refining their communicat...   \n",
              "2  - May lack depth in certain areas of experienc...   \n",
              "\n",
              "                                     general_summary  \\\n",
              "0  The candidate demonstrated exceptional cogniti...   \n",
              "1  The candidate demonstrated exceptional cogniti...   \n",
              "2  The candidate demonstrates strong cognitive ab...   \n",
              "\n",
              "                          final_model_name final_prompt_version  \\\n",
              "0  meta-llama/Llama-3.1-8B-Instruct:novita           rewrite_v1   \n",
              "1  meta-llama/Llama-3.1-8B-Instruct:novita           rewrite_v1   \n",
              "2  meta-llama/Llama-3.1-8B-Instruct:novita           rewrite_v1   \n",
              "\n",
              "  final_temperature  final_latency_ms                        created_at  \n",
              "0               0.0              9573  2025-10-24T00:02:19.186352+00:00  \n",
              "1               0.0              8013  2025-10-24T00:02:27.200074+00:00  \n",
              "2               0.0              6297  2025-10-24T00:02:33.497558+00:00  \n",
              "\n",
              "[3 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef13915e-f4d8-4e97-8ba7-63cc2889ad60\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>interview_id</th>\n",
              "      <th>cognitive_ability_score</th>\n",
              "      <th>experience_score</th>\n",
              "      <th>problem_solving_score</th>\n",
              "      <th>reliability_score</th>\n",
              "      <th>professionalism_score</th>\n",
              "      <th>communication_score</th>\n",
              "      <th>cognitive_ability_justification</th>\n",
              "      <th>experience_justification</th>\n",
              "      <th>problem_solving_justification</th>\n",
              "      <th>...</th>\n",
              "      <th>professionalism_justification</th>\n",
              "      <th>communication_justification</th>\n",
              "      <th>general_strengths</th>\n",
              "      <th>general_weaknesses</th>\n",
              "      <th>general_summary</th>\n",
              "      <th>final_model_name</th>\n",
              "      <th>final_prompt_version</th>\n",
              "      <th>final_temperature</th>\n",
              "      <th>final_latency_ms</th>\n",
              "      <th>created_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>intv_0001</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>The candidate demonstrated exceptional cogniti...</td>\n",
              "      <td>The candidate has significant experience in th...</td>\n",
              "      <td>The candidate demonstrated effective problem-s...</td>\n",
              "      <td>...</td>\n",
              "      <td>The candidate consistently demonstrated a prof...</td>\n",
              "      <td>The candidate was an effective communicator, u...</td>\n",
              "      <td>- Exceptional cognitive abilities, with the ab...</td>\n",
              "      <td>- Limited information provided about their abi...</td>\n",
              "      <td>The candidate demonstrated exceptional cogniti...</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "      <td>rewrite_v1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9573</td>\n",
              "      <td>2025-10-24T00:02:19.186352+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>intv_0002</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>The candidate demonstrated exceptional cogniti...</td>\n",
              "      <td>The candidate has extensive experience in the ...</td>\n",
              "      <td>The candidate demonstrated strong problem-solv...</td>\n",
              "      <td>...</td>\n",
              "      <td>The candidate consistently displayed a profess...</td>\n",
              "      <td>The candidate consistently demonstrated excell...</td>\n",
              "      <td>- Strong critical thinking and problem-solving...</td>\n",
              "      <td>- Could benefit from refining their communicat...</td>\n",
              "      <td>The candidate demonstrated exceptional cogniti...</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "      <td>rewrite_v1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8013</td>\n",
              "      <td>2025-10-24T00:02:27.200074+00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intv_0003</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate demonstrates strong cognitive ab...</td>\n",
              "      <td>The candidate has relevant experience in the f...</td>\n",
              "      <td>The candidate demonstrates strong problem-solv...</td>\n",
              "      <td>...</td>\n",
              "      <td>The candidate consistently demonstrates profes...</td>\n",
              "      <td>The candidate demonstrates effective communica...</td>\n",
              "      <td>- Strong problem-solving skills - Effective co...</td>\n",
              "      <td>- May lack depth in certain areas of experienc...</td>\n",
              "      <td>The candidate demonstrates strong cognitive ab...</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "      <td>rewrite_v1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6297</td>\n",
              "      <td>2025-10-24T00:02:33.497558+00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef13915e-f4d8-4e97-8ba7-63cc2889ad60')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef13915e-f4d8-4e97-8ba7-63cc2889ad60 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef13915e-f4d8-4e97-8ba7-63cc2889ad60');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c9b14057-2318-49a8-abe7-2d73cfb0c6aa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9b14057-2318-49a8-abe7-2d73cfb0c6aa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c9b14057-2318-49a8-abe7-2d73cfb0c6aa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final rows: 50 | Invalid rewrites: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Choose a folder in your Drive\n",
        "save_dir = \"/content/drive/MyDrive/mvp\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
        "csv_path = f\"{save_dir}/finalScores{ts}.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FIs031MOgSG",
        "outputId": "1dde2a8c-e189-477e-db43-ca2ce93fbd82"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-116179088.py:8: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_csv(csv_path, index=False)"
      ],
      "metadata": {
        "id": "_8m1_e4EOjqY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save All Results"
      ],
      "metadata": {
        "id": "4IiX7n-RBXpc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interviews_df.to_csv(\"synth_interviews.csv\", index=False)\n",
        "samples_df.to_csv(\"synth_k_samples.csv\", index=False)\n",
        "aggregated_df.to_csv(\"synth_aggregated.csv\", index=False)\n",
        "final_df.to_csv(\"synth_final_outputs.csv\", index=False)\n",
        "\n",
        "print(\"Saved CSVs:\",\n",
        "      \"synth_interviews.csv, synth_k_samples.csv, synth_aggregated.csv, synth_final_outputs.csv\", sep=\"\\n- \")\n"
      ],
      "metadata": {
        "id": "mM0nXmX7Bb-j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}