{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2934c3694c764ea08485168256376371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_39b71b86b7854320bae2d0fd46468ab4"
          }
        },
        "708b0f9cb4bc4aab892098ae337470ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b134081641704559823ae4bda78c77e4",
            "placeholder": "​",
            "style": "IPY_MODEL_fec2981cbf6444f59820055e68cd062b",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "3bf3f04a31ad4bbb9fa5b214f9dbf11c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_3416e00dc61545a18f83b0fb7200375c",
            "placeholder": "​",
            "style": "IPY_MODEL_bf9aaea5a8e6416d8667b02bbcbf8dda",
            "value": ""
          }
        },
        "53ef672b3d8b40009c12aad523116f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_872546058d5949b89bd9f4c7b1fe5669",
            "style": "IPY_MODEL_c4aeb9ef949e4ad4aaba43d5ce66b6bc",
            "value": true
          }
        },
        "3b8d3e52ec1649dabe5ba31c5a710006": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ec0b0e0c6d2e42f89eb5a6923e050192",
            "style": "IPY_MODEL_aa2f54c5c9e842dea206ba66a11a3ae6",
            "tooltip": ""
          }
        },
        "1276596d66764b6d9b79b35769f8af9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57d96b05ae2640659945282acef1d511",
            "placeholder": "​",
            "style": "IPY_MODEL_fe73065d91434a07aaa2ae09d466e54d",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "39b71b86b7854320bae2d0fd46468ab4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "b134081641704559823ae4bda78c77e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fec2981cbf6444f59820055e68cd062b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3416e00dc61545a18f83b0fb7200375c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf9aaea5a8e6416d8667b02bbcbf8dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "872546058d5949b89bd9f4c7b1fe5669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4aeb9ef949e4ad4aaba43d5ce66b6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec0b0e0c6d2e42f89eb5a6923e050192": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa2f54c5c9e842dea206ba66a11a3ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "57d96b05ae2640659945282acef1d511": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe73065d91434a07aaa2ae09d466e54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a89746c5e1d4b3bbb8cf1dcaf17840d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7a0e89ac9f84e24b711c9ebff9eeabb",
            "placeholder": "​",
            "style": "IPY_MODEL_b6198cf2df5341bc98acf6b3ff0fb16c",
            "value": "Connecting..."
          }
        },
        "b7a0e89ac9f84e24b711c9ebff9eeabb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6198cf2df5341bc98acf6b3ff0fb16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Self-Consistency Scoring with Llama Models\n",
        "This notebook runs self-consistency evaluation using Hugging Face's routed Llama models."
      ],
      "metadata": {
        "id": "header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install huggingface_hub pandas numpy pyyaml -q"
      ],
      "metadata": {
        "id": "install"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Set your Hugging Face API token\n",
        "if \"HF_TOKEN\" not in os.environ or not os.environ[\"HF_TOKEN\"]:\n",
        "    os.environ[\"HF_TOKEN\"] = getpass(\"Paste your Hugging Face token (starts with hf_...): \")"
      ],
      "metadata": {
        "id": "api_key",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4bdd8f2-a1ef-4a8a-c886-1ae78897d167"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your Hugging Face token (starts with hf_...): ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ubkRSzSMmML",
        "outputId": "649b439a-3214-4662-c4f1-a92c9859daf7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yaml\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import statistics as stats\n",
        "import re\n",
        "from typing import Dict, Any, List\n",
        "from datetime import datetime\n",
        "from huggingface_hub import login\n",
        "\n",
        "# Login to Hugging Face\n",
        "login()"
      ],
      "metadata": {
        "id": "imports",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73,
          "referenced_widgets": [
            "2934c3694c764ea08485168256376371",
            "708b0f9cb4bc4aab892098ae337470ff",
            "3bf3f04a31ad4bbb9fa5b214f9dbf11c",
            "53ef672b3d8b40009c12aad523116f96",
            "3b8d3e52ec1649dabe5ba31c5a710006",
            "1276596d66764b6d9b79b35769f8af9a",
            "39b71b86b7854320bae2d0fd46468ab4",
            "b134081641704559823ae4bda78c77e4",
            "fec2981cbf6444f59820055e68cd062b",
            "3416e00dc61545a18f83b0fb7200375c",
            "bf9aaea5a8e6416d8667b02bbcbf8dda",
            "872546058d5949b89bd9f4c7b1fe5669",
            "c4aeb9ef949e4ad4aaba43d5ce66b6bc",
            "ec0b0e0c6d2e42f89eb5a6923e050192",
            "aa2f54c5c9e842dea206ba66a11a3ae6",
            "57d96b05ae2640659945282acef1d511",
            "fe73065d91434a07aaa2ae09d466e54d",
            "8a89746c5e1d4b3bbb8cf1dcaf17840d",
            "b7a0e89ac9f84e24b711c9ebff9eeabb",
            "b6198cf2df5341bc98acf6b3ff0fb16c"
          ]
        },
        "outputId": "2594f535-722b-4507-81ad-620c592ee716"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2934c3694c764ea08485168256376371"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n",
            "WARNING:huggingface_hub._login:Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "id": "config_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    \"role_title\": \"Field Technician\",\n",
        "    \"question_set_id\": \"qs_v1\",\n",
        "    \"question_set\": [\n",
        "        \"Tell me about a time you handled an urgent service call. What steps did you take?\",\n",
        "        \"How do you plan your route and prioritize jobs when schedules change during the day?\",\n",
        "        \"Describe a tricky diagnostic you solved. What tools or methods did you use?\",\n",
        "        \"How do you keep customers calm when they are upset or stressed?\",\n",
        "        \"Walk me through your process for documenting work and updating tickets.\",\n",
        "        \"What does reliability at work mean to you, and how do you demonstrate it?\",\n",
        "        \"How do you stay safe on the job and follow site-specific rules?\",\n",
        "        \"How do you collaborate with teammates or escalate when blocked?\"\n",
        "    ],\n",
        "    \"num_candidates\": 50,\n",
        "    \"k_samples\": 3,  # self-consistency K\n",
        "    \"generation_temperature\": 0.8,\n",
        "    \"generation_max_tokens\": 1200,\n",
        "    \"timeout_s\": 60,\n",
        "    \"gen_prompt_version\": \"gen_v1\",\n",
        "    \"score_prompt_version\": \"score_v1\",\n",
        "    \"rewrite_prompt_version\": \"rewrite_v1\",\n",
        "}\n",
        "\n",
        "# Choose your Hugging Face routed model\n",
        "# Examples:\n",
        "# MODEL_ID = \"meta-llama/Llama-3.1-8B-Instruct:novita\"\n",
        "# MODEL_ID = \"meta-llama/Llama-3.2-3B-Instruct:novita\"\n",
        "# MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3:together\"\n",
        "# MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct:novita\"\n",
        "MODEL_ID = \"meta-llama/Llama-3.1-8B-Instruct:novita\"\n",
        "\n",
        "# Scoring weights and metrics\n",
        "WEIGHTS = {\"ca\":0.35, \"exp\":0.35, \"ps\":0.15, \"rel\":0.05, \"prof\":0.05, \"comm\":0.05}\n",
        "METRICS = [\"ca\", \"exp\", \"ps\", \"rel\", \"prof\", \"comm\"]\n",
        "FILLERS_RE = re.compile(r\"\\b(?:um+|uh+|erm|like|you know|sort of|kinda|i mean|ya know)\\b\", re.IGNORECASE)"
      ],
      "metadata": {
        "id": "config"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "helpers_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clamp_int(x, lo=1, hi=10):\n",
        "    try:\n",
        "        xi = int(round(float(x)))\n",
        "    except Exception:\n",
        "        xi = 5\n",
        "    return max(lo, min(hi, xi))\n",
        "\n",
        "def canonicalize_qa_text(text: str) -> str:\n",
        "    \"\"\"Clean and standardize QA text.\"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = text.strip()\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text\n",
        "\n",
        "def compute_overall_weighted(scores: Dict[str, int]) -> float:\n",
        "    \"\"\"Compute weighted overall score.\"\"\"\n",
        "    total = sum(WEIGHTS.get(m, 0) * scores.get(m, 5) for m in METRICS)\n",
        "    return round(total, 2)\n",
        "\n",
        "def iqr_confidence(vals: List[int]) -> str:\n",
        "    \"\"\"Calculate confidence based on IQR.\"\"\"\n",
        "    if len(vals) < 2:\n",
        "        return \"low\"\n",
        "    q1, q3 = np.percentile(vals, [25, 75])\n",
        "    iqr = q3 - q1\n",
        "    if iqr <= 1:\n",
        "        return \"high\"\n",
        "    elif iqr <= 2:\n",
        "        return \"medium\"\n",
        "    else:\n",
        "        return \"low\""
      ],
      "metadata": {
        "id": "helpers"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt Building Functions"
      ],
      "metadata": {
        "id": "prompts_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generation_prompt(role: str, question_set: List[str], persona: Dict[str, Any]) -> str:\n",
        "    \"\"\"Build prompt for generating candidate interview responses.\"\"\"\n",
        "    q_block = \"\\n\".join([f\"Question {i+1}: {q}\" for i, q in enumerate(question_set)])\n",
        "    lines = [\n",
        "        f\"You are the candidate interviewing for the role: {role}.\",\n",
        "        f\"Persona hints: title={persona['persona_title']}; years_experience={persona['yrs_experience']}; \"\n",
        "        f\"keywords={persona['domain_keywords']}; reliability={persona['reliability_flags']}; notes={persona['notes']}.\",\n",
        "        \"\",\n",
        "        \"Answer each question clearly (2–4 sentences per answer).\",\n",
        "        \"\",\n",
        "        q_block,\n",
        "        \"\",\n",
        "        \"Return responses in this pattern:\",\n",
        "        \"Question 1: <repeat question>\",\n",
        "        \"Answer: <answer>\",\n",
        "        \"\",\n",
        "        \"Question 2: <repeat question>\",\n",
        "        \"Answer: <answer>\",\n",
        "    ]\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def build_scoring_prompt(qa_text: str) -> str:\n",
        "    \"\"\"Build prompt for scoring candidate responses.\"\"\"\n",
        "    metrics_def = \"\\n\".join([\n",
        "        \"- Cognitive Ability (35%): Structured thinking, planning, logic.\",\n",
        "        \"- Experience (35%): Relevant work (last 10 years), skills, accomplishments in similar service jobs.\",\n",
        "        \"- Problem Solving (15%): Resourcefulness, safe tradeoffs under constraints.\",\n",
        "        \"- Reliability (5%): Punctuality, follow-through, transport reliability.\",\n",
        "        \"- Professionalism (5%): Respect for clients/rules, composure under stress.\",\n",
        "        \"- Communication (5%): Clarity and tone; IGNORE filler words.\",\n",
        "    ])\n",
        "    lines = [\n",
        "        \"Analyze the candidate responses using the six metrics below.\",\n",
        "        \"Return ONLY a JSON object with keys: ca, exp, ps, rel, prof, comm (each 1–10).\",\n",
        "        \"\",\n",
        "        \"Definitions (approximate weighting):\",\n",
        "        metrics_def,\n",
        "        \"\",\n",
        "        \"Candidate Responses:\",\n",
        "        \"--- START RESPONSES ---\",\n",
        "        qa_text,\n",
        "        \"--- END RESPONSES ---\",\n",
        "        \"\",\n",
        "        '{\"ca\":8,\"exp\":7,\"ps\":7,\"rel\":7,\"prof\":6,\"comm\":6}',\n",
        "    ]\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "def build_rewrite_prompt_locked(qa_text: str, s: Dict[str, int]) -> str:\n",
        "    \"\"\"Build prompt for generating justifications with locked scores.\"\"\"\n",
        "    lines = [\n",
        "        \"Use FIXED scores; DO NOT change them. Generate justifications + bullets + summary.\",\n",
        "        \"\",\n",
        "        f\"- Cognitive Ability: {s['ca']}\",\n",
        "        f\"- Experience: {s['exp']}\",\n",
        "        f\"- Problem Solving: {s['ps']}\",\n",
        "        f\"- Reliability: {s['rel']}\",\n",
        "        f\"- Professionalism: {s['prof']}\",\n",
        "        f\"- Communication: {s['comm']}\",\n",
        "        \"\",\n",
        "        \"Return ONLY this JSON:\",\n",
        "        \"{\",\n",
        "        f'  \"cognitive_ability_score\": {s[\"ca\"]},',\n",
        "        '  \"cognitive_ability_justification\": \"...\",',\n",
        "        f'  \"experience_score\": {s[\"exp\"]},',\n",
        "        '  \"experience_justification\": \"...\",',\n",
        "        f'  \"reliability_score\": {s[\"rel\"]},',\n",
        "        '  \"reliability_justification\": \"...\",',\n",
        "        f'  \"professionalism_score\": {s[\"prof\"]},',\n",
        "        '  \"professionalism_justification\": \"...\",',\n",
        "        f'  \"problem_solving_score\": {s[\"ps\"]},',\n",
        "        '  \"problem_solving_justification\": \"...\",',\n",
        "        f'  \"communication_score\": {s[\"comm\"]},',\n",
        "        '  \"communication_justification\": \"...\",',\n",
        "        '  \"general_strengths\": \"- ...\\\\n- ...\\\\n- ...\",',\n",
        "        '  \"general_weaknesses\": \"- ...\\\\n- ...\\\\n- ...\",',\n",
        "        '  \"general_summary\": \"...\"',\n",
        "        \"}\",\n",
        "        \"\",\n",
        "        \"Candidate Responses:\",\n",
        "        \"--- START ---\",\n",
        "        qa_text,\n",
        "        \"--- END ---\",\n",
        "    ]\n",
        "    return \"\\n\".join(lines)"
      ],
      "metadata": {
        "id": "prompt_builders"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hugging Face API Client Functions"
      ],
      "metadata": {
        "id": "api_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Initialize Hugging Face client using OpenAI-compatible interface\n",
        "hf_client = OpenAI(\n",
        "    base_url=\"https://router.huggingface.co/v1\",\n",
        "    api_key=os.environ[\"HF_TOKEN\"],\n",
        ")\n",
        "\n",
        "def hf_chat_once(prompt: str, model: str, temperature: float = 0.7,\n",
        "                 max_tokens: int = 512, json_mode: bool = False) -> str:\n",
        "    \"\"\"Call Hugging Face chat completion API.\"\"\"\n",
        "    kwargs = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": temperature,\n",
        "        \"max_tokens\": max_tokens,\n",
        "        \"top_p\": 1.0,\n",
        "    }\n",
        "\n",
        "    if json_mode:\n",
        "        # Enforce valid JSON responses when the provider supports this\n",
        "        kwargs[\"response_format\"] = {\"type\": \"json_object\"}\n",
        "\n",
        "    try:\n",
        "        resp = hf_client.chat.completions.create(**kwargs)\n",
        "        return resp.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"Error calling HF API: {e}\")\n",
        "        raise\n",
        "\n",
        "def hf_chat_json(prompt: str, model: str, temperature: float,\n",
        "                 max_tokens: int = 512) -> tuple:\n",
        "    \"\"\"Call Hugging Face API and parse JSON response.\"\"\"\n",
        "    txt = hf_chat_once(prompt, model=model, temperature=temperature,\n",
        "                       max_tokens=max_tokens, json_mode=True)\n",
        "    try:\n",
        "        return json.loads(txt), txt\n",
        "    except Exception:\n",
        "        # Fallback: try to extract JSON from text\n",
        "        try:\n",
        "            start = txt.index(\"{\")\n",
        "            end = txt.rindex(\"}\") + 1\n",
        "            return json.loads(txt[start:end]), txt\n",
        "        except Exception:\n",
        "            return {}, txt"
      ],
      "metadata": {
        "id": "api_functions"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify Model Access"
      ],
      "metadata": {
        "id": "verify_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import whoami, HfApi\n",
        "\n",
        "print(\"Account info:\")\n",
        "print(whoami())\n",
        "print()\n",
        "\n",
        "# Verify you have access to the model (especially important for gated models like Llama)\n",
        "api = HfApi()\n",
        "model_name = MODEL_ID.split(\":\")[0]  # Remove provider suffix\n",
        "try:\n",
        "    info = api.model_info(model_name, use_auth_token=True)\n",
        "    print(f\"Model: {info.id}\")\n",
        "    print(f\"Gated: {info.gated}\")\n",
        "    print(\"✓ You have access to this model!\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error accessing model: {e}\")\n",
        "    print(\"Make sure you've accepted the model's license agreement on Hugging Face.\")"
      ],
      "metadata": {
        "id": "verify_access",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c0892fd-54ab-4e79-c32c-05cd386937e3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Account info:\n",
            "{'type': 'user', 'id': '68f018da27c30b98c620061c', 'name': 'serviceagent', 'fullname': 'ServiceAgent', 'canPay': True, 'periodEnd': 1764547199, 'isPro': True, 'avatarUrl': '/avatars/c1d1a0eb60867c137fe668fb925748f7.svg', 'orgs': [], 'auth': {'type': 'access_token', 'accessToken': {'displayName': 'ensemble', 'role': 'fineGrained', 'createdAt': '2025-10-18T20:52:33.027Z', 'fineGrained': {'canReadGatedRepos': True, 'global': ['discussion.write', 'post.write'], 'scoped': [{'entity': {'_id': '66eaf084b3b3239188f66fa7', 'type': 'model', 'name': 'meta-llama/Llama-3.2-3B'}, 'permissions': ['repo.content.read', 'discussion.write', 'repo.write']}, {'entity': {'_id': '68f018da27c30b98c620061c', 'type': 'user', 'name': 'serviceagent'}, 'permissions': ['repo.content.read', 'repo.write', 'inference.serverless.write', 'inference.endpoints.infer.write', 'inference.endpoints.write', 'user.webhooks.read', 'user.webhooks.write', 'collection.read', 'collection.write', 'discussion.write', 'user.billing.read', 'job.write']}]}}}}\n",
            "\n",
            "Model: meta-llama/Llama-3.1-8B-Instruct\n",
            "Gated: manual\n",
            "✓ You have access to this model!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Generate Synthetic Interview Responses"
      ],
      "metadata": {
        "id": "step1_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(123)\n",
        "\n",
        "role = CONFIG[\"role_title\"]\n",
        "questions = CONFIG[\"question_set\"]\n",
        "N = CONFIG[\"num_candidates\"]\n",
        "\n",
        "print(f\"Generating {N} synthetic interviews...\")\n",
        "print(f\"Model: {MODEL_ID}\")\n",
        "print()\n",
        "\n",
        "interviews = []\n",
        "start_time = time.time()\n",
        "\n",
        "for i in range(N):\n",
        "    persona = {\n",
        "        \"candidate_id\": f\"cand_{i+1:04d}\",\n",
        "        \"persona_title\": random.choice([\n",
        "            \"Veteran field tech\", \"Career switcher\", \"Recent grad\",\n",
        "            \"Retail service rep\", \"HVAC junior\"\n",
        "        ]),\n",
        "        \"yrs_experience\": random.choice([0, 1, 2, 3, 5, 7, 10]),\n",
        "        \"domain_keywords\": random.choice([\n",
        "            \"preventive maintenance, HVAC, route planning\",\n",
        "            \"customer empathy, troubleshooting basics\",\n",
        "            \"inventory, parts ordering, safety protocols\",\n",
        "            \"ticket triage, escalation, SLA awareness\",\n",
        "        ]),\n",
        "        \"reliability_flags\": random.choice([\n",
        "            \"has_car; weekend_ok\", \"public_transit\", \"night_shift_ok\"\n",
        "        ]),\n",
        "        \"notes\": random.choice([\n",
        "            \"calm under pressure\", \"fast learner\", \"detail-oriented\"\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    prompt = build_generation_prompt(role, questions, persona)\n",
        "    out = hf_chat_once(\n",
        "        prompt,\n",
        "        model=MODEL_ID,\n",
        "        temperature=CONFIG[\"generation_temperature\"],\n",
        "        max_tokens=CONFIG[\"generation_max_tokens\"]\n",
        "    )\n",
        "\n",
        "    interviews.append({\n",
        "        \"interview_id\": f\"intv_{i+1:04d}\",\n",
        "        \"candidate_id\": persona[\"candidate_id\"],\n",
        "        \"role_title\": role,\n",
        "        \"question_set_id\": CONFIG[\"question_set_id\"],\n",
        "        \"num_questions\": len(questions),\n",
        "        \"qa_text\": canonicalize_qa_text(out),\n",
        "        \"source\": \"synthetic\",\n",
        "        \"gen_model\": MODEL_ID,\n",
        "        \"gen_prompt_version\": CONFIG[\"gen_prompt_version\"],\n",
        "        \"gen_temperature\": CONFIG[\"generation_temperature\"],\n",
        "        \"gen_top_p\": 1.0,\n",
        "        \"gen_seed\": 123,\n",
        "        \"created_at\": pd.Timestamp.utcnow().isoformat(),\n",
        "    })\n",
        "\n",
        "    if (i + 1) % 10 == 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        rate = (i + 1) / elapsed\n",
        "        remaining = (N - i - 1) / rate if rate > 0 else 0\n",
        "        print(f\"Generated {i + 1}/{N} interviews | \"\n",
        "              f\"Rate: {rate:.1f}/s | \"\n",
        "              f\"ETA: {remaining:.0f}s\")\n",
        "\n",
        "interviews_df = pd.DataFrame(interviews)\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n✓ Generated {len(interviews_df)} interviews in {total_time:.1f}s\")\n",
        "print(f\"  Average: {total_time/len(interviews_df):.2f}s per interview\")\n",
        "display(interviews_df.head(2))"
      ],
      "metadata": {
        "id": "generate_interviews"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interviews_df = pd.read_csv(\"/content/drive/MyDrive/mvp/synthInterviews20251009-234435.csv\")"
      ],
      "metadata": {
        "id": "0BnPzcVKM3mm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Generate K Self-Consistency Samples (Scoring)"
      ],
      "metadata": {
        "id": "step2_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = CONFIG[\"k_samples\"]\n",
        "records = interviews_df[[\"interview_id\", \"qa_text\"]].to_dict(\"records\")\n",
        "\n",
        "print(f\"Generating {K} scoring samples for {len(records)} interviews...\")\n",
        "print(f\"Total API calls: {K * len(records)}\")\n",
        "print()\n",
        "\n",
        "samples = []\n",
        "start_time = time.time()\n",
        "total_calls = K * len(records)\n",
        "call_count = 0\n",
        "\n",
        "for idx, iv in enumerate(records):\n",
        "    qa = iv[\"qa_text\"] or \"\"\n",
        "    sprompt = build_scoring_prompt(qa)\n",
        "\n",
        "    for k in range(K):\n",
        "        t0 = time.time()\n",
        "        js, raw = hf_chat_json(\n",
        "            sprompt,\n",
        "            model=MODEL_ID,\n",
        "            temperature=0.7,\n",
        "            max_tokens=256\n",
        "        )\n",
        "        latency = int((time.time() - t0) * 1000)\n",
        "        call_count += 1\n",
        "\n",
        "        row = {\n",
        "            \"interview_id\": iv[\"interview_id\"],\n",
        "            \"run_idx\": k,\n",
        "            \"model_name\": MODEL_ID,\n",
        "            \"latency_ms\": latency,\n",
        "        }\n",
        "        for m in METRICS:\n",
        "            row[m] = clamp_int(js.get(m, 5))\n",
        "        samples.append(row)\n",
        "\n",
        "    if (idx + 1) % 10 == 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        rate = call_count / elapsed\n",
        "        remaining_calls = total_calls - call_count\n",
        "        remaining_time = remaining_calls / rate if rate > 0 else 0\n",
        "        print(f\"Scored {idx + 1}/{len(records)} interviews | \"\n",
        "              f\"Calls: {call_count}/{total_calls} | \"\n",
        "              f\"Rate: {rate:.1f}/s | \"\n",
        "              f\"ETA: {remaining_time:.0f}s\")\n",
        "\n",
        "samples_df = pd.DataFrame(samples)\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n✓ Generated {len(samples_df)} scoring samples in {total_time:.1f}s\")\n",
        "print(f\"  Average: {total_time/len(samples_df):.3f}s per sample\")\n",
        "print(f\"  Median latency: {samples_df['latency_ms'].median():.0f}ms\")\n",
        "display(samples_df.head(9))  # Show 3 samples for 3 interviews"
      ],
      "metadata": {
        "id": "score_samples",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "6aa2c256-84ad-4562-b7f1-5508c5d5e634"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 3 scoring samples for 50 interviews...\n",
            "Total API calls: 150\n",
            "\n",
            "Scored 10/50 interviews | Calls: 30/150 | Rate: 0.6/s | ETA: 201s\n",
            "Scored 20/50 interviews | Calls: 60/150 | Rate: 0.6/s | ETA: 142s\n",
            "Scored 30/50 interviews | Calls: 90/150 | Rate: 0.6/s | ETA: 95s\n",
            "Scored 40/50 interviews | Calls: 120/150 | Rate: 0.6/s | ETA: 47s\n",
            "Scored 50/50 interviews | Calls: 150/150 | Rate: 0.6/s | ETA: 0s\n",
            "\n",
            "✓ Generated 150 scoring samples in 233.9s\n",
            "  Average: 1.559s per sample\n",
            "  Median latency: 1530ms\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  interview_id  run_idx                               model_name  latency_ms  \\\n",
              "0    intv_0001        0  meta-llama/Llama-3.1-8B-Instruct:novita        2147   \n",
              "1    intv_0001        1  meta-llama/Llama-3.1-8B-Instruct:novita        1598   \n",
              "2    intv_0001        2  meta-llama/Llama-3.1-8B-Instruct:novita        1430   \n",
              "3    intv_0002        0  meta-llama/Llama-3.1-8B-Instruct:novita        1537   \n",
              "4    intv_0002        1  meta-llama/Llama-3.1-8B-Instruct:novita        1524   \n",
              "5    intv_0002        2  meta-llama/Llama-3.1-8B-Instruct:novita        1330   \n",
              "6    intv_0003        0  meta-llama/Llama-3.1-8B-Instruct:novita        2572   \n",
              "7    intv_0003        1  meta-llama/Llama-3.1-8B-Instruct:novita        1702   \n",
              "8    intv_0003        2  meta-llama/Llama-3.1-8B-Instruct:novita        1736   \n",
              "\n",
              "   ca  exp  ps  rel  prof  comm  \n",
              "0   9    8   8    8     8     7  \n",
              "1   9    8   8    8     7     8  \n",
              "2   9    8   8    9     8     9  \n",
              "3   8    9   8    9     8     9  \n",
              "4   8    8   8    8     8     7  \n",
              "5   8    8   8    9     8     8  \n",
              "6   8    8   7    8     7     8  \n",
              "7   8    9   7    9     8     8  \n",
              "8   9    8   8    8     7     9  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff2c52d0-f634-4291-beb1-bb33b84e1f08\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>interview_id</th>\n",
              "      <th>run_idx</th>\n",
              "      <th>model_name</th>\n",
              "      <th>latency_ms</th>\n",
              "      <th>ca</th>\n",
              "      <th>exp</th>\n",
              "      <th>ps</th>\n",
              "      <th>rel</th>\n",
              "      <th>prof</th>\n",
              "      <th>comm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>intv_0001</td>\n",
              "      <td>0</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "      <td>2147</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>intv_0001</td>\n",
              "      <td>1</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "      <td>1598</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intv_0001</td>\n",
              "      <td>2</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "      <td>1430</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intv_0002</td>\n",
              "      <td>0</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "      <td>1537</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>intv_0002</td>\n",
              "      <td>1</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "      <td>1524</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>intv_0002</td>\n",
              "      <td>2</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "      <td>1330</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>intv_0003</td>\n",
              "      <td>0</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "      <td>2572</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>intv_0003</td>\n",
              "      <td>1</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "      <td>1702</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>intv_0003</td>\n",
              "      <td>2</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "      <td>1736</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff2c52d0-f634-4291-beb1-bb33b84e1f08')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff2c52d0-f634-4291-beb1-bb33b84e1f08 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff2c52d0-f634-4291-beb1-bb33b84e1f08');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d6b59eef-7e30-48b7-ac62-d5b989745c7c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d6b59eef-7e30-48b7-ac62-d5b989745c7c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d6b59eef-7e30-48b7-ac62-d5b989745c7c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(samples_df\",\n  \"rows\": 9,\n  \"fields\": [\n    {\n      \"column\": \"interview_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"intv_0001\",\n          \"intv_0002\",\n          \"intv_0003\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"run_idx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"model_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"meta-llama/Llama-3.1-8B-Instruct:novita\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"latency_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 392,\n        \"min\": 1330,\n        \"max\": 2572,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1702\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 9,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 9,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ps\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 8,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rel\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 9,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prof\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 8,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 9,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Aggregate Scores (Self-Consistency)"
      ],
      "metadata": {
        "id": "step3_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Aggregating scores using median (self-consistency)...\")\n",
        "\n",
        "aggs = []\n",
        "for intv_id, g in samples_df.groupby(\"interview_id\"):\n",
        "    row = {\"interview_id\": intv_id}\n",
        "    latencies = g[\"latency_ms\"].tolist()\n",
        "\n",
        "    for m in METRICS:\n",
        "        vals = [int(v) for v in g[m].tolist()]\n",
        "        row[f\"{m}_score_agg\"] = clamp_int(stats.median(vals))\n",
        "        row[f\"{m}_confidence\"] = iqr_confidence(vals)\n",
        "\n",
        "    row[\"overall_weighted_agg\"] = compute_overall_weighted(\n",
        "        {m: row[f\"{m}_score_agg\"] for m in METRICS}\n",
        "    )\n",
        "    row[\"p95_latency_ms\"] = float(np.percentile(latencies, 95)) if latencies else 0\n",
        "    aggs.append(row)\n",
        "\n",
        "aggregated_df = pd.DataFrame(aggs)\n",
        "\n",
        "print(f\"✓ Aggregated {len(aggregated_df)} interview scores\")\n",
        "print(f\"  Confidence distribution:\")\n",
        "for m in METRICS:\n",
        "    conf_col = f\"{m}_confidence\"\n",
        "    if conf_col in aggregated_df.columns:\n",
        "        high = (aggregated_df[conf_col] == \"high\").sum()\n",
        "        med = (aggregated_df[conf_col] == \"medium\").sum()\n",
        "        low = (aggregated_df[conf_col] == \"low\").sum()\n",
        "        print(f\"    {m.upper()}: High={high}, Medium={med}, Low={low}\")\n",
        "\n",
        "display(aggregated_df.head())"
      ],
      "metadata": {
        "id": "aggregate",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "bf2ef268-7fc1-43dc-bf18-5dd3e6339275"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregating scores using median (self-consistency)...\n",
            "✓ Aggregated 50 interview scores\n",
            "  Confidence distribution:\n",
            "    CA: High=49, Medium=1, Low=0\n",
            "    EXP: High=45, Medium=3, Low=2\n",
            "    PS: High=48, Medium=1, Low=1\n",
            "    REL: High=48, Medium=2, Low=0\n",
            "    PROF: High=50, Medium=0, Low=0\n",
            "    COMM: High=50, Medium=0, Low=0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  interview_id  ca_score_agg ca_confidence  exp_score_agg exp_confidence  \\\n",
              "0    intv_0001             9          high              8           high   \n",
              "1    intv_0002             8          high              8           high   \n",
              "2    intv_0003             8          high              8           high   \n",
              "3    intv_0004             8          high              8           high   \n",
              "4    intv_0005             6          high              5           high   \n",
              "\n",
              "   ps_score_agg ps_confidence  rel_score_agg rel_confidence  prof_score_agg  \\\n",
              "0             8          high              8           high               8   \n",
              "1             8          high              9           high               8   \n",
              "2             7          high              8           high               7   \n",
              "3             8          high              8           high               8   \n",
              "4             6          high              8           high               8   \n",
              "\n",
              "  prof_confidence  comm_score_agg comm_confidence  overall_weighted_agg  \\\n",
              "0            high               8            high                  8.35   \n",
              "1            high               8            high                  8.05   \n",
              "2            high               8            high                  7.80   \n",
              "3            high               8            high                  8.00   \n",
              "4            high               8            high                  5.95   \n",
              "\n",
              "   p95_latency_ms  \n",
              "0          2092.1  \n",
              "1          1535.7  \n",
              "2          2488.4  \n",
              "3          1786.3  \n",
              "4          1706.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84b2f17b-fef7-492a-9736-1761241fbc2e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>interview_id</th>\n",
              "      <th>ca_score_agg</th>\n",
              "      <th>ca_confidence</th>\n",
              "      <th>exp_score_agg</th>\n",
              "      <th>exp_confidence</th>\n",
              "      <th>ps_score_agg</th>\n",
              "      <th>ps_confidence</th>\n",
              "      <th>rel_score_agg</th>\n",
              "      <th>rel_confidence</th>\n",
              "      <th>prof_score_agg</th>\n",
              "      <th>prof_confidence</th>\n",
              "      <th>comm_score_agg</th>\n",
              "      <th>comm_confidence</th>\n",
              "      <th>overall_weighted_agg</th>\n",
              "      <th>p95_latency_ms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>intv_0001</td>\n",
              "      <td>9</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8.35</td>\n",
              "      <td>2092.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>intv_0002</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>9</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8.05</td>\n",
              "      <td>1535.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intv_0003</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>7</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>7.80</td>\n",
              "      <td>2488.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intv_0004</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1786.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>intv_0005</td>\n",
              "      <td>6</td>\n",
              "      <td>high</td>\n",
              "      <td>5</td>\n",
              "      <td>high</td>\n",
              "      <td>6</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>8</td>\n",
              "      <td>high</td>\n",
              "      <td>5.95</td>\n",
              "      <td>1706.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84b2f17b-fef7-492a-9736-1761241fbc2e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-84b2f17b-fef7-492a-9736-1761241fbc2e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-84b2f17b-fef7-492a-9736-1761241fbc2e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7b8214f7-666c-4954-ba29-5c6ce1e9f31f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7b8214f7-666c-4954-ba29-5c6ce1e9f31f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7b8214f7-666c-4954-ba29-5c6ce1e9f31f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(aggregated_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"interview_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"intv_0002\",\n          \"intv_0005\",\n          \"intv_0003\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 6,\n        \"max\": 9,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          9,\n          8,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ca_confidence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exp_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 5,\n        \"max\": 8,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"exp_confidence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ps_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ps_confidence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rel_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 9,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rel_confidence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prof_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 8,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prof_confidence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comm_score_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comm_confidence\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overall_weighted_agg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9595571895410924,\n        \"min\": 5.95,\n        \"max\": 8.35,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8.05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"p95_latency_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 375.5132154798284,\n        \"min\": 1535.7,\n        \"max\": 2488.4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1535.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Generate Final Outputs with Justifications"
      ],
      "metadata": {
        "id": "step4_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_map = dict(zip(interviews_df[\"interview_id\"], interviews_df[\"qa_text\"]))\n",
        "\n",
        "def rewrite_once_chat(qa_text: str, scores_locked: Dict[str, int],\n",
        "                     model: str, max_tokens: int = 1200) -> tuple:\n",
        "    \"\"\"Generate justifications for locked scores.\"\"\"\n",
        "    prompt = (\n",
        "        \"Respond with exactly ONE JSON object, no code fences, no prose, no markdown. \"\n",
        "        \"Do not include any keys that are not requested.\\n\\n\"\n",
        "        + build_rewrite_prompt_locked(qa_text, scores_locked)\n",
        "    )\n",
        "    t0 = time.time()\n",
        "    js, raw = hf_chat_json(prompt, model=model, temperature=0.0, max_tokens=max_tokens)\n",
        "    latency = int((time.time() - t0) * 1000)\n",
        "    return js, raw, latency\n",
        "\n",
        "print(f\"Generating justifications for {len(aggregated_df)} interviews...\")\n",
        "print()\n",
        "\n",
        "final_rows = []\n",
        "invalid_count = 0\n",
        "start_time = time.time()\n",
        "\n",
        "for idx, (_, agg_row) in enumerate(aggregated_df.iterrows()):\n",
        "    iid = agg_row[\"interview_id\"]\n",
        "    qa_text = qa_map.get(iid, \"\")\n",
        "    if not qa_text:\n",
        "        invalid_count += 1\n",
        "        continue\n",
        "\n",
        "    scores_locked = {m: agg_row[f\"{m}_score_agg\"] for m in METRICS}\n",
        "    js, raw_text, lat = rewrite_once_chat(qa_text, scores_locked, model=MODEL_ID)\n",
        "\n",
        "    # Validate scores match\n",
        "    score_keys = [\n",
        "        \"cognitive_ability_score\", \"experience_score\", \"reliability_score\",\n",
        "        \"professionalism_score\", \"problem_solving_score\", \"communication_score\"\n",
        "    ]\n",
        "    if all(k in js for k in score_keys):\n",
        "        out_row = {\n",
        "            \"interview_id\": iid,\n",
        "            \"cognitive_ability_score\": js.get(\"cognitive_ability_score\"),\n",
        "            \"cognitive_ability_justification\": js.get(\"cognitive_ability_justification\", \"\"),\n",
        "            \"experience_score\": js.get(\"experience_score\"),\n",
        "            \"experience_justification\": js.get(\"experience_justification\", \"\"),\n",
        "            \"reliability_score\": js.get(\"reliability_score\"),\n",
        "            \"reliability_justification\": js.get(\"reliability_justification\", \"\"),\n",
        "            \"professionalism_score\": js.get(\"professionalism_score\"),\n",
        "            \"professionalism_justification\": js.get(\"professionalism_justification\", \"\"),\n",
        "            \"problem_solving_score\": js.get(\"problem_solving_score\"),\n",
        "            \"problem_solving_justification\": js.get(\"problem_solving_justification\", \"\"),\n",
        "            \"communication_score\": js.get(\"communication_score\"),\n",
        "            \"communication_justification\": js.get(\"communication_justification\", \"\"),\n",
        "            \"general_strengths\": js.get(\"general_strengths\", \"\"),\n",
        "            \"general_weaknesses\": js.get(\"general_weaknesses\", \"\"),\n",
        "            \"general_summary\": js.get(\"general_summary\", \"\"),\n",
        "            \"overall_weighted_score\": agg_row[\"overall_weighted_agg\"],\n",
        "            \"rewrite_latency_ms\": lat,\n",
        "            \"rewrite_model\": MODEL_ID,\n",
        "        }\n",
        "        final_rows.append(out_row)\n",
        "    else:\n",
        "        invalid_count += 1\n",
        "\n",
        "    if (idx + 1) % 10 == 0:\n",
        "        elapsed = time.time() - start_time\n",
        "        rate = (idx + 1) / elapsed\n",
        "        remaining = (len(aggregated_df) - idx - 1) / rate if rate > 0 else 0\n",
        "        print(f\"Processed {idx + 1}/{len(aggregated_df)} | \"\n",
        "              f\"Rate: {rate:.1f}/s | \"\n",
        "              f\"ETA: {remaining:.0f}s\")\n",
        "\n",
        "final_df = pd.DataFrame(final_rows)\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n✓ Generated {len(final_df)} complete evaluations in {total_time:.1f}s\")\n",
        "print(f\"  Invalid/skipped: {invalid_count}\")\n",
        "display(final_df.head())"
      ],
      "metadata": {
        "id": "rewrite",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "outputId": "8a2cc61b-ec94-4f36-d4f5-fe039c7036b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating justifications for 50 interviews...\n",
            "\n",
            "Processed 10/50 | Rate: 0.1/s | ETA: 369s\n",
            "Processed 20/50 | Rate: 0.1/s | ETA: 250s\n",
            "Processed 30/50 | Rate: 0.1/s | ETA: 165s\n",
            "Processed 40/50 | Rate: 0.1/s | ETA: 80s\n",
            "Processed 50/50 | Rate: 0.1/s | ETA: 0s\n",
            "\n",
            "✓ Generated 49 complete evaluations in 394.3s\n",
            "  Invalid/skipped: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  interview_id  cognitive_ability_score  \\\n",
              "0    intv_0001                        9   \n",
              "1    intv_0002                        8   \n",
              "2    intv_0003                        8   \n",
              "3    intv_0004                        8   \n",
              "4    intv_0005                        6   \n",
              "\n",
              "                     cognitive_ability_justification  experience_score  \\\n",
              "0  The candidate demonstrated exceptional cogniti...                 8   \n",
              "1  The candidate demonstrated strong problem-solv...                 8   \n",
              "2  The candidate demonstrates strong cognitive ab...                 8   \n",
              "3  The candidate demonstrated strong cognitive ab...                 8   \n",
              "4  The candidate demonstrates average cognitive a...                 5   \n",
              "\n",
              "                            experience_justification  reliability_score  \\\n",
              "0  The candidate has significant experience in th...                  8   \n",
              "1  The candidate has extensive experience as a fi...                  9   \n",
              "2  The candidate has a significant amount of rele...                  8   \n",
              "3  The candidate has extensive experience as a Fi...                  8   \n",
              "4  The candidate has limited direct experience in...                  8   \n",
              "\n",
              "                           reliability_justification  professionalism_score  \\\n",
              "0  The candidate demonstrated a strong commitment...                      8   \n",
              "1  The candidate consistently demonstrated a stro...                      8   \n",
              "2  The candidate consistently demonstrates reliab...                      7   \n",
              "3  The candidate consistently demonstrated reliab...                      8   \n",
              "4  The candidate consistently demonstrates a stro...                      8   \n",
              "\n",
              "                       professionalism_justification  problem_solving_score  \\\n",
              "0  The candidate consistently demonstrated profes...                      8   \n",
              "1  The candidate consistently displayed a profess...                      8   \n",
              "2  The candidate generally demonstrates professio...                      7   \n",
              "3  The candidate consistently demonstrated profes...                      8   \n",
              "4  The candidate consistently demonstrates a high...                      6   \n",
              "\n",
              "                       problem_solving_justification  communication_score  \\\n",
              "0  The candidate demonstrated exceptional problem...                    8   \n",
              "1  The candidate demonstrated strong problem-solv...                    8   \n",
              "2  The candidate demonstrates strong problem-solv...                    8   \n",
              "3  The candidate effectively applied problem-solv...                    8   \n",
              "4  The candidate demonstrates average problem-sol...                    8   \n",
              "\n",
              "                         communication_justification  \\\n",
              "0  The candidate consistently demonstrated effect...   \n",
              "1  The candidate consistently demonstrated excell...   \n",
              "2  The candidate communicates effectively through...   \n",
              "3  The candidate consistently demonstrated strong...   \n",
              "4  The candidate consistently demonstrates strong...   \n",
              "\n",
              "                                   general_strengths  \\\n",
              "0  - Exceptional cognitive abilities and problem-...   \n",
              "1  - Strong problem-solving skills and critical t...   \n",
              "2  - Strong problem-solving skills and ability to...   \n",
              "3  - Strong cognitive abilities and problem-solvi...   \n",
              "4  - Strong commitment to reliability and profess...   \n",
              "\n",
              "                                  general_weaknesses  \\\n",
              "0  - Limited opportunities to showcase their abil...   \n",
              "1  - May benefit from additional training or deve...   \n",
              "2  - Occasionally uses informal language or phras...   \n",
              "3  - Limited discussion of long-term goals or car...   \n",
              "4  - Limited direct experience in the field - May...   \n",
              "\n",
              "                                     general_summary  overall_weighted_score  \\\n",
              "0  The candidate demonstrated exceptional cogniti...                    8.35   \n",
              "1  The candidate is a highly skilled and experien...                    8.05   \n",
              "2  The candidate demonstrates strong cognitive ab...                    7.80   \n",
              "3  The candidate demonstrated strong cognitive ab...                    8.00   \n",
              "4  The candidate demonstrates a strong commitment...                    5.95   \n",
              "\n",
              "   rewrite_latency_ms                            rewrite_model  \n",
              "0               10458  meta-llama/Llama-3.1-8B-Instruct:novita  \n",
              "1                8497  meta-llama/Llama-3.1-8B-Instruct:novita  \n",
              "2                6355  meta-llama/Llama-3.1-8B-Instruct:novita  \n",
              "3                9203  meta-llama/Llama-3.1-8B-Instruct:novita  \n",
              "4                8221  meta-llama/Llama-3.1-8B-Instruct:novita  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7bb23945-6c20-4099-bf91-d21561c0098c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>interview_id</th>\n",
              "      <th>cognitive_ability_score</th>\n",
              "      <th>cognitive_ability_justification</th>\n",
              "      <th>experience_score</th>\n",
              "      <th>experience_justification</th>\n",
              "      <th>reliability_score</th>\n",
              "      <th>reliability_justification</th>\n",
              "      <th>professionalism_score</th>\n",
              "      <th>professionalism_justification</th>\n",
              "      <th>problem_solving_score</th>\n",
              "      <th>problem_solving_justification</th>\n",
              "      <th>communication_score</th>\n",
              "      <th>communication_justification</th>\n",
              "      <th>general_strengths</th>\n",
              "      <th>general_weaknesses</th>\n",
              "      <th>general_summary</th>\n",
              "      <th>overall_weighted_score</th>\n",
              "      <th>rewrite_latency_ms</th>\n",
              "      <th>rewrite_model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>intv_0001</td>\n",
              "      <td>9</td>\n",
              "      <td>The candidate demonstrated exceptional cogniti...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate has significant experience in th...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate demonstrated a strong commitment...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate consistently demonstrated profes...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate demonstrated exceptional problem...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate consistently demonstrated effect...</td>\n",
              "      <td>- Exceptional cognitive abilities and problem-...</td>\n",
              "      <td>- Limited opportunities to showcase their abil...</td>\n",
              "      <td>The candidate demonstrated exceptional cogniti...</td>\n",
              "      <td>8.35</td>\n",
              "      <td>10458</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>intv_0002</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate demonstrated strong problem-solv...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate has extensive experience as a fi...</td>\n",
              "      <td>9</td>\n",
              "      <td>The candidate consistently demonstrated a stro...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate consistently displayed a profess...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate demonstrated strong problem-solv...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate consistently demonstrated excell...</td>\n",
              "      <td>- Strong problem-solving skills and critical t...</td>\n",
              "      <td>- May benefit from additional training or deve...</td>\n",
              "      <td>The candidate is a highly skilled and experien...</td>\n",
              "      <td>8.05</td>\n",
              "      <td>8497</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>intv_0003</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate demonstrates strong cognitive ab...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate has a significant amount of rele...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate consistently demonstrates reliab...</td>\n",
              "      <td>7</td>\n",
              "      <td>The candidate generally demonstrates professio...</td>\n",
              "      <td>7</td>\n",
              "      <td>The candidate demonstrates strong problem-solv...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate communicates effectively through...</td>\n",
              "      <td>- Strong problem-solving skills and ability to...</td>\n",
              "      <td>- Occasionally uses informal language or phras...</td>\n",
              "      <td>The candidate demonstrates strong cognitive ab...</td>\n",
              "      <td>7.80</td>\n",
              "      <td>6355</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>intv_0004</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate demonstrated strong cognitive ab...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate has extensive experience as a Fi...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate consistently demonstrated reliab...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate consistently demonstrated profes...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate effectively applied problem-solv...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate consistently demonstrated strong...</td>\n",
              "      <td>- Strong cognitive abilities and problem-solvi...</td>\n",
              "      <td>- Limited discussion of long-term goals or car...</td>\n",
              "      <td>The candidate demonstrated strong cognitive ab...</td>\n",
              "      <td>8.00</td>\n",
              "      <td>9203</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>intv_0005</td>\n",
              "      <td>6</td>\n",
              "      <td>The candidate demonstrates average cognitive a...</td>\n",
              "      <td>5</td>\n",
              "      <td>The candidate has limited direct experience in...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate consistently demonstrates a stro...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate consistently demonstrates a high...</td>\n",
              "      <td>6</td>\n",
              "      <td>The candidate demonstrates average problem-sol...</td>\n",
              "      <td>8</td>\n",
              "      <td>The candidate consistently demonstrates strong...</td>\n",
              "      <td>- Strong commitment to reliability and profess...</td>\n",
              "      <td>- Limited direct experience in the field - May...</td>\n",
              "      <td>The candidate demonstrates a strong commitment...</td>\n",
              "      <td>5.95</td>\n",
              "      <td>8221</td>\n",
              "      <td>meta-llama/Llama-3.1-8B-Instruct:novita</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bb23945-6c20-4099-bf91-d21561c0098c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7bb23945-6c20-4099-bf91-d21561c0098c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7bb23945-6c20-4099-bf91-d21561c0098c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a5eaef78-7d5d-4a6e-bedd-adfe25c2630a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5eaef78-7d5d-4a6e-bedd-adfe25c2630a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a5eaef78-7d5d-4a6e-bedd-adfe25c2630a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(final_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"interview_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"intv_0002\",\n          \"intv_0005\",\n          \"intv_0003\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cognitive_ability_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 6,\n        \"max\": 9,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          9,\n          8,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cognitive_ability_justification\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The candidate demonstrated strong problem-solving skills, critical thinking, and analytical abilities throughout the interview. They effectively assessed complex situations, identified key issues, and developed practical solutions.\",\n          \"The candidate demonstrates average cognitive ability, as they are able to understand and respond to questions, but may struggle with complex or abstract concepts. They show a systematic approach to problem-solving, but may not always consider all possible solutions.\",\n          \"The candidate demonstrates strong cognitive abilities through their ability to recall specific instances from their past experience, apply technical knowledge to complex problems, and think critically to resolve issues.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"experience_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 5,\n        \"max\": 8,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"experience_justification\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The candidate has extensive experience as a field technician, with a proven track record of resolving complex issues and providing excellent customer service. They have a deep understanding of the industry and its best practices.\",\n          \"The candidate has limited direct experience in the field, but has transferable skills from previous roles. They demonstrate a willingness to learn and adapt, but may require additional training or support to excel in the role.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reliability_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 9,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          9,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reliability_justification\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The candidate consistently demonstrated a strong commitment to reliability, dependability, and responsibility throughout the interview. They prioritized preventive maintenance, proactive troubleshooting, and safety protocols, showcasing a high level of reliability.\",\n          \"The candidate consistently demonstrates a strong commitment to reliability, emphasizing the importance of being dependable, responsible, and committed to delivering results. They provide specific examples of how they would maintain open communication and follow through on commitments.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"professionalism_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 7,\n        \"max\": 8,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          7,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"professionalism_justification\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The candidate consistently displayed a professional demeanor, excellent communication skills, and a customer-centric approach. They effectively managed customer expectations, de-escalated conflicts, and provided clear explanations of technical issues.\",\n          \"The candidate consistently demonstrates a high level of professionalism, using clear and concise language, and showing a patient and empathetic approach to customer interactions. They emphasize the importance of maintaining a professional attitude and adhering to company policies and procedures.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"problem_solving_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 6,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          8,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"problem_solving_justification\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The candidate demonstrated strong problem-solving skills, using a combination of technical expertise, critical thinking, and analytical abilities to resolve complex issues. They effectively identified root causes, developed practical solutions, and implemented them efficiently.\",\n          \"The candidate demonstrates average problem-solving skills, using a systematic approach to identify and address issues. However, they may not always consider all possible solutions or think critically about complex problems.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"communication_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 8,\n        \"max\": 8,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"communication_justification\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The candidate consistently demonstrated excellent communication skills, using clear and concise language to explain technical issues, provide updates, and manage customer expectations. They effectively listened to customers, empathized with their concerns, and provided solutions that met their needs.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"general_strengths\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"- Strong problem-solving skills and critical thinking abilities.\\\\- Excellent communication and interpersonal skills.\\\\- Proven track record of reliability, dependability, and responsibility.\\\\- Deep understanding of the industry and its best practices.\\\\- Ability to work effectively in a team environment.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"general_weaknesses\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"- May benefit from additional training or development in emerging technologies or industry trends.\\\\- Can be more assertive in advocating for themselves and their needs.\\\\- May need to improve time management and prioritization skills in high-pressure situations.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"general_summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The candidate is a highly skilled and experienced field technician with a strong track record of resolving complex issues and providing excellent customer service. They consistently demonstrated a commitment to reliability, dependability, and responsibility, as well as excellent communication and interpersonal skills. With some additional training or development, they have the potential to excel in a variety of roles and environments.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overall_weighted_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9595571895410924,\n        \"min\": 5.95,\n        \"max\": 8.35,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8.05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rewrite_latency_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1499,\n        \"min\": 6355,\n        \"max\": 10458,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          8497\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rewrite_model\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"meta-llama/Llama-3.1-8B-Instruct:novita\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Results"
      ],
      "metadata": {
        "id": "save_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save all dataframes\n",
        "ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
        "model_safe = MODEL_ID.replace(\"/\", \"_\").replace(\":\", \"_\")\n",
        "\n",
        "# interviews_df.to_csv(f\"interviews_{model_safe}_{ts}.csv\", index=False)\n",
        "# samples_df.to_csv(f\"samples_{model_safe}_{ts}.csv\", index=False)\n",
        "# aggregated_df.to_csv(f\"aggregated_{model_safe}_{ts}.csv\", index=False)\n",
        "final_df.to_csv(f\"final_{model_safe}_{ts}.csv\", index=False)\n",
        "\n",
        "print(f\"✓ Saved all results with timestamp: {ts}\")\n",
        "print(f\"  Model used: {MODEL_ID}\")\n",
        "print(f\"\\nFiles saved:\")\n",
        "print(f\"  - interviews_{model_safe}_{ts}.csv\")\n",
        "print(f\"  - samples_{model_safe}_{ts}.csv\")\n",
        "print(f\"  - aggregated_{model_safe}_{ts}.csv\")\n",
        "print(f\"  - final_{model_safe}_{ts}.csv\")"
      ],
      "metadata": {
        "id": "save",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d53bb3b3-5d37-4cd1-c717-d733f5e09411"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Saved all results with timestamp: 20251104-234821\n",
            "  Model used: meta-llama/Llama-3.1-8B-Instruct:novita\n",
            "\n",
            "Files saved:\n",
            "  - interviews_meta-llama_Llama-3.1-8B-Instruct_novita_20251104-234821.csv\n",
            "  - samples_meta-llama_Llama-3.1-8B-Instruct_novita_20251104-234821.csv\n",
            "  - aggregated_meta-llama_Llama-3.1-8B-Instruct_novita_20251104-234821.csv\n",
            "  - final_meta-llama_Llama-3.1-8B-Instruct_novita_20251104-234821.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4063269437.py:2: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary Statistics"
      ],
      "metadata": {
        "id": "summary_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 70)\n",
        "print(f\"SELF-CONSISTENCY SCORING SUMMARY\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\nModel: {MODEL_ID}\")\n",
        "print(f\"\\nDataset:\")\n",
        "print(f\"  Total Interviews: {len(interviews_df)}\")\n",
        "print(f\"  K Samples per Interview: {K}\")\n",
        "print(f\"  Total Scoring Samples: {len(samples_df)}\")\n",
        "print(f\"  Final Valid Outputs: {len(final_df)}\")\n",
        "\n",
        "print(f\"\\nScore Statistics:\")\n",
        "print(f\"  Overall Weighted Score:\")\n",
        "print(f\"    Mean:   {final_df['overall_weighted_score'].mean():.2f}\")\n",
        "print(f\"    Median: {final_df['overall_weighted_score'].median():.2f}\")\n",
        "print(f\"    Std:    {final_df['overall_weighted_score'].std():.2f}\")\n",
        "print(f\"    Min:    {final_df['overall_weighted_score'].min():.2f}\")\n",
        "print(f\"    Max:    {final_df['overall_weighted_score'].max():.2f}\")\n",
        "\n",
        "print(f\"\\nMetric Score Averages:\")\n",
        "for m in METRICS:\n",
        "    col = f\"{m}_score_agg\"\n",
        "    if col in aggregated_df.columns:\n",
        "        mean_score = aggregated_df[col].mean()\n",
        "        median_score = aggregated_df[col].median()\n",
        "        print(f\"  {m.upper():6s}: Mean={mean_score:.2f}, Median={median_score:.0f}\")\n",
        "\n",
        "print(f\"\\nConfidence Analysis:\")\n",
        "for m in METRICS:\n",
        "    conf_col = f\"{m}_confidence\"\n",
        "    if conf_col in aggregated_df.columns:\n",
        "        high = (aggregated_df[conf_col] == \"high\").sum()\n",
        "        med = (aggregated_df[conf_col] == \"medium\").sum()\n",
        "        low = (aggregated_df[conf_col] == \"low\").sum()\n",
        "        total = high + med + low\n",
        "        high_pct = 100 * high / total if total > 0 else 0\n",
        "        print(f\"  {m.upper():6s}: High={high} ({high_pct:.0f}%), Medium={med}, Low={low}\")\n",
        "\n",
        "print(f\"\\nLatency Statistics:\")\n",
        "print(f\"  Scoring (per sample):\")\n",
        "print(f\"    Median: {samples_df['latency_ms'].median():.0f}ms\")\n",
        "print(f\"    P95:    {samples_df['latency_ms'].quantile(0.95):.0f}ms\")\n",
        "print(f\"    P99:    {samples_df['latency_ms'].quantile(0.99):.0f}ms\")\n",
        "print(f\"  Rewrite (per interview):\")\n",
        "print(f\"    Median: {final_df['rewrite_latency_ms'].median():.0f}ms\")\n",
        "print(f\"    P95:    {final_df['rewrite_latency_ms'].quantile(0.95):.0f}ms\")\n",
        "print(f\"    P99:    {final_df['rewrite_latency_ms'].quantile(0.99):.0f}ms\")\n",
        "\n",
        "print(f\"\\nScore Distribution by Percentile:\")\n",
        "percentiles = [10, 25, 50, 75, 90]\n",
        "for p in percentiles:\n",
        "    val = final_df['overall_weighted_score'].quantile(p/100)\n",
        "    print(f\"  P{p:2d}: {val:.2f}\")\n",
        "\n",
        "print(\"=\" * 70)"
      ],
      "metadata": {
        "id": "summary",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e3e3ab7-facf-481c-90a7-77c48730882c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SELF-CONSISTENCY SCORING SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Model: meta-llama/Llama-3.1-8B-Instruct:novita\n",
            "\n",
            "Dataset:\n",
            "  Total Interviews: 50\n",
            "  K Samples per Interview: 3\n",
            "  Total Scoring Samples: 150\n",
            "  Final Valid Outputs: 49\n",
            "\n",
            "Score Statistics:\n",
            "  Overall Weighted Score:\n",
            "    Mean:   7.76\n",
            "    Median: 8.00\n",
            "    Std:    0.85\n",
            "    Min:    5.05\n",
            "    Max:    8.70\n",
            "\n",
            "Metric Score Averages:\n",
            "  CA    : Mean=7.84, Median=8\n",
            "  EXP   : Mean=7.60, Median=8\n",
            "  PS    : Mean=7.58, Median=8\n",
            "  REL   : Mean=8.08, Median=8\n",
            "  PROF  : Mean=7.80, Median=8\n",
            "  COMM  : Mean=8.10, Median=8\n",
            "\n",
            "Confidence Analysis:\n",
            "  CA    : High=49 (98%), Medium=1, Low=0\n",
            "  EXP   : High=45 (90%), Medium=3, Low=2\n",
            "  PS    : High=48 (96%), Medium=1, Low=1\n",
            "  REL   : High=48 (96%), Medium=2, Low=0\n",
            "  PROF  : High=50 (100%), Medium=0, Low=0\n",
            "  COMM  : High=50 (100%), Medium=0, Low=0\n",
            "\n",
            "Latency Statistics:\n",
            "  Scoring (per sample):\n",
            "    Median: 1530ms\n",
            "    P95:    1786ms\n",
            "    P99:    2056ms\n",
            "  Rewrite (per interview):\n",
            "    Median: 7649ms\n",
            "    P95:    9855ms\n",
            "    P99:    10893ms\n",
            "\n",
            "Score Distribution by Percentile:\n",
            "  P10: 6.64\n",
            "  P25: 8.00\n",
            "  P50: 8.00\n",
            "  P75: 8.05\n",
            "  P90: 8.35\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Mount Google Drive for Persistent Storage"
      ],
      "metadata": {
        "id": "drive_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Save to Drive\n",
        "save_dir = \"/content/drive/MyDrive/mvp\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
        "model_safe = MODEL_ID.replace(\"/\", \"_\").replace(\":\", \"_\")\n",
        "\n",
        "interviews_df.to_csv(f\"{save_dir}/interviews_{model_safe}_{ts}.csv\", index=False)\n",
        "samples_df.to_csv(f\"{save_dir}/samples_{model_safe}_{ts}.csv\", index=False)\n",
        "aggregated_df.to_csv(f\"{save_dir}/aggregated_{model_safe}_{ts}.csv\", index=False)\n",
        "final_df.to_csv(f\"{save_dir}/final_{model_safe}_{ts}.csv\", index=False)\n",
        "\n",
        "print(f\"✓ Saved to Google Drive: {save_dir}\")"
      ],
      "metadata": {
        "id": "drive_save"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}